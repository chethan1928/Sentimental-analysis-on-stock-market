import base64
import os
import re
import json
import uuid
import requests
import pdfplumber
from openai import AzureOpenAI
from docx import Document
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
from docx.shared import RGBColor, Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

from pdf2docx import Converter
from tqdm import tqdm
from fuzzywuzzy import fuzz
from utils.azure_client import client,llm
from config import settings



# ================================+
# Configuration (no settings.py)
# ================================+



# Base output directory (local)
BASE_OUTPUT_DIR = os.path.abspath("output")

HIGHLIGHT_DIR = os.path.join(BASE_OUTPUT_DIR, "questions_evaluation", "highlighted")
FINAL_DIR = os.path.join(BASE_OUTPUT_DIR, "questions_evaluation", "final")

RE_HIGHLIGHT_DIR = os.path.join(BASE_OUTPUT_DIR, "questions_re_evaluation", "highlighted")
RE_FINAL_DIR = os.path.join(BASE_OUTPUT_DIR, "questions_re_evaluation", "final")

# Ensure directories exist
for d in [HIGHLIGHT_DIR, FINAL_DIR, RE_HIGHLIGHT_DIR, RE_FINAL_DIR]:
    os.makedirs(d, exist_ok=True)


import unicodedata

def normalize_text(text):
    return unicodedata.normalize("NFC", text)

# Language font profiles (only these languages use special font-aware flow)
LANGUAGE_FONT_PROFILE = {
    "telugu": {"normal": "Gidugu", "math": "Cambria Math"},
    "tamil": {"normal": "Noto Sans Tamil", "math": "Cambria Math"},
    "hindi": {"normal": "Nirmala UI", "math": "Cambria Math"},
}
DEFAULT_FONT_PROFILE = {"normal": None, "math": "Cambria Math"}


def set_run_font(run, font_name):
    if not font_name:
        return
    run.font.name = font_name
    rpr = run._element.get_or_add_rPr()
    rfonts = rpr.get_or_add_rFonts()
    rfonts.set(qn("w:ascii"), font_name)
    rfonts.set(qn("w:hAnsi"), font_name)
    rfonts.set(qn("w:cs"), font_name)
    rfonts.set(qn("w:eastAsia"), font_name)


def is_math_symbol(ch):
    o = ord(ch)
    if ch in "+-*/=<>^%()[]{}|~√ó√∑¬±‚àì‚àö‚àû‚àë‚àè‚à´‚àÜ‚àÇ‚àá‚âà‚â†‚â§‚â•‚àù":
        return True
    if unicodedata.category(ch) == "Sm":
        return True
    if 0x2200 <= o <= 0x22FF:
        return True
    if 0x2070 <= o <= 0x209F:
        return True
    return False


def _font_profile_for_language(language):
    key = normalize_flow_language(language)
    return LANGUAGE_FONT_PROFILE.get(key)


def add_mixed_font_text(para, text, language=None):
    if not text:
        return []

    profile = _font_profile_for_language(language) or DEFAULT_FONT_PROFILE

    normal_font = profile.get("normal")
    math_font = profile.get("math")

    runs = []
    start = 0
    current_math = is_math_symbol(text[0])

    for i in range(1, len(text)):
        this_math = is_math_symbol(text[i])
        if this_math != current_math:
            chunk = text[start:i]
            run = para.add_run(chunk)
            set_run_font(run, math_font if current_math else normal_font)
            runs.append(run)
            start = i
            current_math = this_math

    chunk = text[start:]
    run = para.add_run(chunk)
    set_run_font(run, math_font if current_math else normal_font)
    runs.append(run)
    return runs

def is_text_corrupted(text, threshold=0.3):
    """
    Detects font-mapped garbage text.
    Returns True if corrupted.
    """

    if not text.strip():
        return True

    weird_chars = sum(
        1 for c in text
        if ord(c) > 127 and not c.isalpha()
    )

    ratio = weird_chars / len(text)

    return ratio > threshold


def convert_pdf_to_docx(pdf_path):
    """Convert PDF to DOCX while preserving layout."""
    output_path = pdf_path.replace(".pdf", "_converted.docx")
    try:
        cv = Converter(pdf_path)
        cv.convert(output_path, start=0, end=None)
        cv.close()
        print(f"‚úÖ PDF converted to DOCX: {output_path}")
    except Exception as e:
        print(f"‚ùå Error converting PDF to DOCX: {e}")
        raise
    return output_path

# def extract_pages(pdf_path):
#     """Extract text from each PDF page using pdfplumber."""
#     try:
#         pages = []
#         with pdfplumber.open(pdf_path) as pdf:
#             for page in pdf.pages:
#                 text = page.extract_text() or ""
#                 # Normalize text: remove extra whitespace, non-breaking spaces, etc.
#                 text = re.sub(r'\s+', ' ', text.replace('\xa0', ' ').strip())
#                 pages.append(text)
#         return pages
#     except Exception as e:
#         print(f"‚ùå Error extracting text from PDF: {e}")
#         return []


import fitz  # PyMuPDF
# def extract_pages(pdf_path):
#     """Extract text using PyMuPDF (better for Indian languages)."""
#     try:
#         pages = []
#         doc = fitz.open(pdf_path)

#         for page in doc:
#             text = page.get_text("text")

#             text = re.sub(r'\s+', ' ', text.replace('\xa0', ' ').strip())

#             pages.append(text)

#         return pages

#     except Exception as e:
#         print(f"‚ùå PyMuPDF extraction error: {e}")
#         return []

import pytesseract
from pdf2image import convert_from_path

def extract_pages_ocr(pdf_path):
    pages = []
    images = convert_from_path(pdf_path, dpi=300)

    for img in images:
        text = pytesseract.image_to_string(
            img,
            lang="eng+hin+tel+tam+ben+mar"
        )
        pages.append(text)

    return pages



def extract_pages(pdf_path):
    try:
        pages = []
        doc = fitz.open(pdf_path)

        for page in doc:
            text = page.get_text("text")

            if is_text_corrupted(text):
                print("‚ö†Ô∏è Detected corrupted extraction. Switching to OCR...")
                return extract_pages_ocr(pdf_path)

            pages.append(text)

        return pages

    except Exception as e:
        print(f"‚ùå Extraction error: {e}")
        return extract_pages_ocr(pdf_path)

# ============================================================
# Azure OCR flow for complex-script PDFs (dict-controlled)
# ============================================================
SPECIAL_AZURE_OCR_LANGUAGES = set(LANGUAGE_FONT_PROFILE.keys())


def normalize_flow_language(language):
    if not language:
        return ""
    language = str(language).strip().lower()
    aliases = {
        "hi": "hindi",
        "te": "telugu",
        "ta": "tamil",
    }
    return aliases.get(language, language)


def should_use_special_azure_flow(language):
    return normalize_flow_language(language) in SPECIAL_AZURE_OCR_LANGUAGES


def _get_azure_vision_config():
    endpoint = (
        getattr(settings, "AZURE_OPENAI_ENDPOINT", None)
        or getattr(settings, "AZURE_ENDPOINT", None)
        or os.getenv("AZURE_OPENAI_ENDPOINT")
        or os.getenv("AZURE_ENDPOINT")
    )
    api_key = (
        getattr(settings, "AZURE_OPENAI_API_KEY", None)
        or getattr(settings, "AZURE_API_KEY", None)
        or os.getenv("AZURE_OPENAI_API_KEY")
        or os.getenv("AZURE_API_KEY")
    )
    deployment = (
        getattr(settings, "AZURE_DEPLOYMENT_NAME", None)
        or os.getenv("AZURE_DEPLOYMENT_NAME")
    )
    api_version = (
        getattr(settings, "AZURE_OPENAI_API_VERSION", None)
        or getattr(settings, "AZURE_API_VERSION", None)
        or os.getenv("AZURE_OPENAI_API_VERSION")
        or os.getenv("AZURE_API_VERSION")
        or "2025-01-01-preview"
    )

    missing = []
    if not endpoint:
        missing.append("AZURE_OPENAI_ENDPOINT/AZURE_ENDPOINT")
    if not api_key:
        missing.append("AZURE_OPENAI_API_KEY/AZURE_API_KEY")
    if not deployment:
        missing.append("AZURE_DEPLOYMENT_NAME")
    if missing:
        raise RuntimeError(f"Missing Azure Vision config: {', '.join(missing)}")

    return endpoint, api_key, deployment, api_version


def _pixmap_to_base64(pix):
    return base64.b64encode(pix.tobytes("png")).decode("utf-8")


def call_azure_vision_ocr(b64_image, page_no=None, language=None):
    endpoint, api_key, deployment, api_version = _get_azure_vision_config()
    url = (
        f"{endpoint.rstrip('/')}/openai/deployments/{deployment}"
        f"/chat/completions?api-version={api_version}"
    )
    headers = {"Content-Type": "application/json", "api-key": api_key}

    page_tag_hint = f"[PAGE:{page_no}]" if page_no is not None else "[PAGE:n]"
    lang_name = (language or "Telugu").capitalize()
    script_map = {
        "telugu": "Telugu script",
        "tamil": "Tamil script",
        "hindi": "Devanagari script",
    }
    script_hint = script_map.get((language or "telugu").lower(), f"{lang_name} script")

    user_prompt = (
        f"Task: OCR this {lang_name} exam/question paper page. "
        f"The text is primarily in {script_hint}. Extract ALL visible text exactly as it appears.\n\n"
        "Rules:\n"
        f"1) Preserve all {script_hint} characters exactly.\n"
        "2) Do NOT translate, correct, summarize, or rewrite.\n"
        "3) Preserve line breaks, reading order, and paragraph spacing.\n"
        "4) Keep all numbers, punctuation, and formulas exactly as shown.\n"
        "5) Preserve question numbers and section headers exactly.\n"
        "6) Preserve marks like (2M), (5 Marks), etc.\n"
        "7) For centered headings, wrap text as [CENTER]heading[/CENTER].\n"
        "8) For indented lines, prefix with [INDENT:n] where n is leading spaces.\n"
        "9) For tables, wrap with [TABLE_START] and [TABLE_END], and output rows as | Cell1 | Cell2 |.\n"
        "10) For unreadable text, use [UNCLEAR] in the exact position.\n"
        f"11) First non-empty line must be {page_tag_hint}.\n"
        "12) Return plain text only (no markdown, no code fences)."
    )

    last_error = None
    for attempt in range(1, 4):
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": (
                        f"You are a strict OCR layout transcriber for {lang_name} exam papers "
                        f"in {script_hint}. Extract text faithfully without changes. "
                        "Use [INDENT:n], [CENTER]...[/CENTER], [TABLE_START]/[TABLE_END] markers exactly as requested."
                    ),
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{b64_image}",
                                "detail": "high",
                            },
                        },
                    ],
                },
            ],
            "max_tokens": 4096,
            "temperature": 0.0,
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=150)
            response.raise_for_status()
            content = response.json()["choices"][0]["message"]["content"].strip()
            if content:
                return content
        except Exception as e:
            last_error = e
            print(f"‚ö†Ô∏è Azure OCR attempt {attempt} failed: {e}")

    raise RuntimeError(f"Azure OCR failed after retries: {last_error}")


def extract_pages_ocr_azure_special(pdf_path, language=None):
    pages = []
    doc = fitz.open(pdf_path)
    try:
        for page_no, page in enumerate(doc, start=1):
            print(f"[*] Azure OCR page {page_no}...")
            pix = page.get_pixmap(dpi=300)
            b64_image = _pixmap_to_base64(pix)
            try:
                content = call_azure_vision_ocr(b64_image, page_no=page_no, language=language)
                expected_tag = f"[PAGE:{page_no}]"
                if expected_tag not in content:
                    content = f"{expected_tag}\n{content}"
                pages.append(content)
            except Exception as e:
                print(f"‚ùå Azure OCR failed on page {page_no}: {e}")
                pages.append("")
    finally:
        doc.close()
    return pages


def _is_special_table_separator_line(line):
    cleaned = line.replace("|", "").replace("-", "").replace(":", "").strip()
    return cleaned == ""


def _special_table_cells_from_line(line):
    row = line.strip()
    if row.startswith("|"):
        row = row[1:]
    if row.endswith("|"):
        row = row[:-1]
    return [c.strip() for c in row.split("|")]


def _add_special_table(doc, table_rows, language=None):
    if not table_rows:
        return
    col_count = max(len(r) for r in table_rows)
    table = doc.add_table(rows=len(table_rows), cols=col_count)
    table.style = "Table Grid"
    for r_idx, row in enumerate(table_rows):
        for c_idx in range(col_count):
            value = row[c_idx] if c_idx < len(row) else ""
            para = table.cell(r_idx, c_idx).paragraphs[0]
            add_mixed_font_text(para, value, language=language)


def convert_pdf_to_docx_special_ocr(pdf_path, extracted_pages_list, language=None):
    output_path = pdf_path.replace(".pdf", "_converted.docx")
    try:
        doc = Document()
        section = doc.sections[0]
        section.left_margin = section.right_margin = Inches(0.5)

        total_pages = len(extracted_pages_list)
        for page_idx, page_text in enumerate(extracted_pages_list):
            table_rows = []
            in_table_block = False

            def flush_table():
                nonlocal table_rows
                if table_rows:
                    _add_special_table(doc, table_rows, language=language)
                    table_rows = []

            for line in (page_text or "").splitlines():
                raw_line = line.rstrip()
                leading_spaces = len(raw_line) - len(raw_line.lstrip(" "))
                clean_line = raw_line.strip()

                if not clean_line or clean_line == "[BLANK]":
                    flush_table()
                    doc.add_paragraph()
                    continue

                if re.match(r"^\[PAGE:\s*\d+\s*\]$", clean_line):
                    continue

                if clean_line == "[TABLE_START]":
                    flush_table()
                    in_table_block = True
                    continue

                if clean_line == "[TABLE_END]":
                    flush_table()
                    in_table_block = False
                    continue

                if in_table_block:
                    if "|" in clean_line and clean_line.count("|") > 1 and not _is_special_table_separator_line(clean_line):
                        table_rows.append(_special_table_cells_from_line(clean_line))
                    continue

                if "|" in clean_line and clean_line.count("|") > 1:
                    if _is_special_table_separator_line(clean_line):
                        continue
                    table_rows.append(_special_table_cells_from_line(clean_line))
                    continue

                flush_table()

                indent_match = re.match(r"^\[INDENT:(\d+)\]\s*(.*)$", raw_line)
                if indent_match:
                    indent_spaces = int(indent_match.group(1))
                    text_value = indent_match.group(2)
                    para = doc.add_paragraph()
                    para.paragraph_format.left_indent = Inches(min(indent_spaces * 0.06, 3.0))
                    add_mixed_font_text(para, text_value, language=language)
                elif "[CENTER]" in clean_line or "[/CENTER]" in clean_line:
                    para = doc.add_paragraph()
                    para.alignment = WD_ALIGN_PARAGRAPH.CENTER
                    text_value = clean_line.replace("[CENTER]", "").replace("[/CENTER]", "").strip()
                    add_mixed_font_text(para, text_value, language=language)
                else:
                    para = doc.add_paragraph()
                    if leading_spaces >= 2:
                        para.paragraph_format.left_indent = Inches(min(leading_spaces * 0.03, 3.0))
                    if clean_line[0:1].isdigit():
                        para.paragraph_format.left_indent = Inches(0.2)
                        para.paragraph_format.first_line_indent = Inches(-0.2)
                    add_mixed_font_text(para, clean_line, language=language)

            flush_table()
            if page_idx < total_pages - 1:
                doc.add_page_break()

        doc.save(output_path)
        print(f"‚úÖ OCR DOCX created: {output_path}")
        return output_path
    except Exception as e:
        print(f"‚ùå Error building OCR DOCX: {e}")
        raise


def evaluate_document_special_azure(input_path: str, save_json=False, language=None):
    try:
        if input_path.endswith(".pdf"):
            pages = extract_pages_ocr_azure_special(input_path, language=language)
            docx_path = convert_pdf_to_docx_special_ocr(input_path, pages, language=language)
        else:
            docx_path = input_path
            pages = extract_pages_from_docx(docx_path)

        if not pages:
            print(f"‚ùå No pages extracted from {input_path}")
            return None, None, None, None

        all_results = []
        for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
            result = primary_student_answersheet_evaluation(page_content, i)
            all_results.append(result)

        json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
        if save_json:
            with open(json_output, "w", encoding="utf-8") as f:
                json.dump(all_results, f, ensure_ascii=False, indent=4)

        highlighted_docx = os.path.join(
            RE_HIGHLIGHT_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx"),
        )
        highlight_and_summarize(docx_path, all_results, highlighted_docx, language=language)

        final_docx = os.path.join(
            RE_FINAL_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx"),
        )
        generate_final_corrected_document(docx_path, all_results, final_docx, language=language)

        markdown = generate_markdown_report(all_results)
        return highlighted_docx, final_docx, markdown, all_results
    except Exception as e:
        print(f"‚ùå Error in evaluate_document_special_azure: {e}")
        return None, None, None, None


def extract_pages_from_docx(docx_path, words_per_page=1500):
    """Split DOCX into pseudo-pages if no real pages exist."""
    try:
        doc = Document(docx_path)
        text = "\n".join(p.text for p in doc.paragraphs)
        # Normalize text
        #text = re.sub(r'\s+', ' ', text.replace('\xa0', ' ').strip())
        words = text.split()
        pages = [" ".join(words[i:i+words_per_page]) for i in range(0, len(words), words_per_page)]
        return pages
    except Exception as e:
        print(f"‚ùå Error extracting text from DOCX: {e}")
        return []
    

def primary_student_answersheet_evaluation(
    page_content,
    page_num,
    raw_output_dir="raw_llm_outputs"
):
    """Call AzureOpenAI and return parsed JSON result for a single page.

    IMPORTANT: api_key and azure_endpoint should be provided via environment variables
    or function arguments to avoid hardcoding secrets in source.
    """
    try:
        if not page_content.strip():
            return {
                "page": page_num,
                "grammar_spelling": [],
                "worksheet_format": [],
                "answer_key": [],
                "logical_flow": [],
                "british_english": [],
                "paragraph_corrections": [],
                "question_relevance": [],
                "question_answers": [],
                "summary": "Empty page, skipped."
            }

        # prompt = f"""
        # You are an experienced language teacher and worksheet editor.

        # Carefully check the worksheet line by line. Evaluate ONLY the text provided.

        # ### Identify ALL errors in:
        # - Spelling
        # - Grammar
        # - Punctuation
        # - Capitalisation
        # - Sentence structure
        # - Word usage (tense, articles, prepositions, subject‚Äìverb agreement)

        # ### Check questions and instructions for:
        # - Clarity
        # - Correct grammar
        # - Appropriate vocabulary for the stated grade level

        # ### Verify the answer key:
        # - Answers are accurate
        # - Answers align with the questions
        # - Flag ambiguous, incomplete, or incorrect answers

        # ### Check for:
        # - Repetition of questions
        # - Mismatch between questions and answers
        # - Inconsistent numbering or formatting

        # ### STRICT RULES:
        # - Quote the incorrect part EXACTLY as it appears.
        # - Do NOT rewrite correct text.
        # - Do NOT infer missing content.
        # - Avoid duplicate or redundant errors.
        # - Use British English conventions only.
        # - Be strict but fair (teacher standard).

        # ### Output format (JSON ONLY):
        # For every issue, include:
        # - incorrect: quoted incorrect text
        # - correct: corrected version
        # - comment: brief, clear reason
        # - category: one of
        # [spelling, grammar, punctuation, capitalisation,
        # sentence_structure, word_usage, clarity,
        # answer_key, repetition, formatting]

        # Text to evaluate:
        # ---
        # {page_content}
        # ---

        # Return ONLY valid JSON in this schema:
        # {{
        # "grammar_spelling": [],
        # "worksheet_format": [],
        # "answer_key": [],
        # "logical_flow": [],
        # "british_english": [],
        # "paragraph_corrections": [],
        # "question_relevance": [],
        # "question_answers": [],
        # "summary": ""
        # }}
        # """

        prompt = f"""
        You are a strict academic worksheet evaluator skilled in language and subject accuracy. Evaluate only the question sheet provided in `page_content`. Do not provide answers for questions unless explicitly provided in the text. Conduct a strict, thorough review of the given page content to ensure clarity and accuracy with the passage.
        
        First, detect the primary language of the text.
        Apply grammar rules of that language
        Evaluate the text strictly according to the grammatical, spelling,
        and punctuation rules of THAT language.
        Do NOT apply English grammar rules to non-English languages.
        Do NOT translate the text.

        You must evaluate BOTH:

        1. Language quality
        2. Subject content accuracy (Science, general knowledge, academic facts if present)

        Carefully check the worksheet line by line. Evaluate ONLY the text provided.

        --------------------------------------------------
        ### PART 1: Language Evaluation
        --------------------------------------------------

        Identify ALL errors applicable to the detected language, such as:
        - Spelling (for that language)
        - Grammar (language-specific rules)
        - Punctuation (language-specific usage)
        - Sentence structure (if applicable)
        - Script consistency (e.g., Devanagari, Telugu script)
        - Incorrect mixing of languages (unless intentional)
        
        For Indian languages (e.g., Hindi, Telugu, Bengali, Tamil):

        - Ensure correct script usage
        - Check matras, conjuncts, and diacritics
        - Do not flag absence of articles or tense markers
        - Respect free word order where applicable
        - Flag incorrect transliteration only if inconsistent



        --------------------------------------------------
        ### PART 2: Academic / Science Evaluation (Apply ONLY if relevant content exists)
        --------------------------------------------------

        If the worksheet contains scientific, factual, or subject knowledge content, verify:

        - Scientific facts, laws, definitions, and explanations are correct
        - Units, formulas, symbols, subscripts, superscripts are accurate
        - No outdated or incorrect scientific concepts
        - No repetition of questions or concepts
        - Internal choices are meaningfully different
        - Ensure each question has an answer key

        --------------------------------------------------
        ### PART 3: Worksheet Quality Checks
        --------------------------------------------------

        Check for:

        - Question repetition
        - Logical flow between questions
        - Instruction clarity
        - Formatting consistency
        - Alignment between questions and answers
        - Vocabulary is appropriate for the stated grade level
        - Each question has a corresponding answer key
        - Question numbering is sequential and consistent
        - Diagrams (if present) follow scientific conventions and are accurate
        - Avoid testing the same concept multiple times unless intentionally progressive

        --------------------------------------------------
        ### STRICT RULES
        --------------------------------------------------

        - Quote incorrect text EXACTLY as it appears
        - Do NOT rewrite correct text
        - Do NOT invent missing information
        - Avoid duplicate corrections
        - If the language is English, use British English conventions.
        - Be strict but fair (teacher standard)
        - If content is correct ‚Üí DO NOT flag it
        - Sentence must start with capital letter
        - Proper nouns capitalised

        
        If the text contains mixed languages (e.g., English instructions with Hindi questions):
        - Evaluate each segment using its respective language rules
        - Do NOT force consistency across languages


        --------------------------------------------------
        ### Output format (JSON ONLY)

        For every issue include:

        - incorrect
        - correct
        - comment
        - category

        Allowed categories:

        [spelling, grammar, punctuation, capitalisation,
        sentence_structure, word_usage, clarity,
        science_fact, formula, unit, symbol,
        answer_key, repetition, formatting, logical_flow, 
        diagram, vocabulary_grade_level, numbering_consistency
        concept_duplication, missing_answer_key]

        --------------------------------------------------
        Text to evaluate:
        --------------------------------------------------
        {page_content}
        --------------------------------------------------

        Return ONLY valid JSON in this schema:

        {{
        "grammar_spelling": [],
        "worksheet_format": [],
        "answer_key": [],
        "logical_flow": [],
        "british_english": [],
        "paragraph_corrections": [],
        "question_relevance": [],
        "question_answers": [],
        "summary": ""
        }}
        """


        # response = client.chat.completions.create(
        #     model=settings.AZURE_DEPLOYMENT_NAME,
        response = client.chat.completions.create(
            model=settings.AZURE_DEPLOYMENT_NAME,

            temperature=0,
            messages=[
                {"role": "system", "content": "You are a strict primary student answer sheet evaluator."},
                {"role": "user", "content": prompt},
            ],
            stream=False,
        )

        raw_output = response.choices[0].message.content.strip()

        os.makedirs(raw_output_dir, exist_ok=True)
        raw_path = os.path.join(raw_output_dir, f"page_{page_num}_raw.txt")
        with open(raw_path, "w", encoding="utf-8") as f:
            f.write(raw_output)

        # Try to find JSON object inside raw_output
        json_start = raw_output.find("{")
        json_end = raw_output.rfind("}")
        if json_start != -1 and json_end != -1:
            cleaned = raw_output[json_start:json_end+1]
            try:
                parsed_json = json.loads(cleaned)
            except json.JSONDecodeError:
                parsed_json = {
                    "page": page_num,
                    
                    "worksheet_format": [],
                    "answer_key": [],
                    "logical_flow": [],
                    "british_english": [],
                    "paragraph_corrections": [],
                    "question_relevance": [],
                    "question_answers": [],
                    "summary": "Invalid JSON or no output"
                }
        else:
            parsed_json = {
                "page": page_num,
                "grammar_spelling": [],
                "worksheet_format": [],
                "answer_key": [],
                "logical_flow": [],
                "british_english": [],
                "paragraph_corrections": [],
                "question_relevance": [],
                "question_answers": [],
                "summary": "Invalid JSON or no output"
            }

        # Validate and filter out invalid corrections
        for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
            valid_items = []
            for item in parsed_json.get(key, []):
                incorrect = item.get("incorrect", "").strip()
                correct = item.get("correct", "").strip()
                comment = item.get("comment", "").strip()
                if incorrect and correct and comment and incorrect != correct:
                    valid_items.append(item)
                else:
                    # keep entries that might be part of other structures (e.g., one-word spelling entries)
                    # but avoid noisy empty items
                    if incorrect and correct and incorrect != correct:
                        valid_items.append(item)
                    else:
                        print(f"‚ö†Ô∏è Skipped invalid {key} correction: {item}")
            parsed_json[key] = valid_items

        # Ensure required keys exist
        for key in ["paragraph_corrections", "question_relevance", "question_answers"]:
            if key not in parsed_json:
                parsed_json[key] = []

        parsed_json["page"] = page_num

        # Enhanced logging
        print(f"\nüìò PAGE {page_num} SUMMARY üìò")
        for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
            if not parsed_json.get(key, []):
                print(f"  ‚úÖ No {key.replace('_', ' ').title()} issues detected.")
            else:
                for err in parsed_json.get(key, []):
                    print(f"  ‚ùå {err.get('incorrect')} ‚Üí ‚úÖ {err.get('correct')} ({err.get('comment','')})")
        print(f"üìù Summary: {parsed_json.get('summary', '')}")

        return parsed_json

    except Exception as e:
        print(f"‚ùå Error analyzing page {page_num}: {e}")
        return {
            "page": page_num,
            "grammar_spelling": [],
            "worksheet_format": [],
            "answer_key": [],
            "logical_flow": [],
            "british_english": [],
            "paragraph_corrections": [],
            "question_relevance": [],
            "question_answers": [],
            "summary": f"Error: {e}"
        }
    
def apply_color(run, color):
    """Apply red or green color to text."""
    if color == "red":
        run.font.color.rgb = RGBColor(255, 0, 0)
    elif color == "green":
        run.font.color.rgb = RGBColor(0, 128, 0)
    run.font.bold = True
    
def highlight_errors_in_doc(doc, errors, language=None):
    """Highlight incorrect words/sentences inline with color, correction, and small-font comment."""
    highlights_applied = False
    for para in doc.paragraphs:
        #para_text = para.text
        para_text = normalize_text(para.text)
        if not para_text.strip():
            continue
        matches = []
        for err in errors:
            #wrong = err.get("incorrect", "").strip()
            wrong = normalize_text(err.get("incorrect", ""))
            if not wrong:
                continue
            # Use exact matching with re.finditer
            pattern = re.escape(wrong)  # Escape special characters in the error text
            for match in re.finditer(pattern, para_text, re.IGNORECASE):
                start, end = match.start(), match.end()
                matches.append((start, end, err))
            if not matches:
                print(f"‚ö†Ô∏è No exact match for '{wrong}' in paragraph: {para_text[:50]}...")
        if not matches:
            continue
        # Sort matches by start position
        matches.sort(key=lambda x: x[0])
        # Remove overlapping matches (keep first, skip overlaps) extra pa
        # filtered = []
        # prev_end = 0
        # for start, end, err in matches:
        #     if start >= prev_end:
        #         filtered.append((start, end, err))
        #         prev_end = end
        # matches = filtered
        # if not matches:
        #     continue
        # Rebuild paragraph runs
        para.clear()
        last_end = 0
        for start, end, err in matches:
            if start > last_end:
                add_mixed_font_text(para, para_text[last_end:start], language=language)
            # Check if it's a spelling error
            is_spelling = err.get("comment", "").lower() in [
                "american spelling detected", "spelling error", "incorrect spelling",
                "british spelling required", "contraction not allowed"
            ] or err.get("category", "") in ["grammar_spelling", "british_english"]
            wrong_text = para_text[start:end]
            if is_spelling:
                red_runs = add_mixed_font_text(para, wrong_text, language=language)
                for red_run in red_runs:
                    apply_color(red_run, "red")
            else:
                red_runs = add_mixed_font_text(para, wrong_text, language=language)
                for red_run in red_runs:
                    apply_color(red_run, "red")
            # Add green correction
            right = err.get("correct", "").strip()
            if right:
                green_runs = add_mixed_font_text(para, f" ({right})", language=language)
                for green_run in green_runs:
                    apply_color(green_run, "green")
            # Add small-font comment
            if comment := err.get("comment", ""):
                comment_run = para.add_run(f" [{comment}]")
                comment_run.font.size = Pt(8)
                comment_run.font.color.rgb = RGBColor(128, 128, 128)
            last_end = end
            highlights_applied = True
            print(f"‚úÖ Highlighted '{wrong_text}' ‚Üí '{right}' ({comment}) at position {start}-{end}")
        if last_end < len(para_text):
            add_mixed_font_text(para, para_text[last_end:], language=language)
    return highlights_applied

def gray_box_paragraph(doc, text):
    """Add shaded paragraph for page summary."""
    p = doc.add_paragraph()
    run = p.add_run(text)
    run.bold = True
    p_format = p.paragraph_format
    p_format.space_before = Pt(12) 
    p_format.space_after = Pt(12)
    shading_elm = OxmlElement("w:shd")
    shading_elm.set(qn("w:fill"), "D9D9D9")
    p._element.get_or_add_pPr().append(shading_elm)
    return p

def add_page_summary(doc, page_result):
    """Add detailed summary at the end of the current page. Also appends question answers."""
    summary_text = f"üìò Page {page_result['page']} Summary üìò\n"
    summary_text += f"üìù {page_result.get('summary','')}\n\n"
    for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
        items = page_result.get(key, [])
        if items:
            summary_text += f"--- {key.replace('_',' ').title()} ---\n"
            for err in items:
                summary_text += f"{err.get('incorrect')} ‚Üí {err.get('correct')} ({err.get('comment','')})\n"

    # Append question answers if present
    if page_result.get("question_answers"):
        summary_text += "\nüìö Answers for Questions\n"
        for ans in page_result.get("question_answers", []):
            qno = ans.get("question_no") or ans.get("question_no", "")
            question_text = ans.get("question", "")
            answer_text = ans.get("answer", "")
            explanation = ans.get("explanation", "")
            summary_text += f"Q{qno}: {question_text}\nAnswer: {answer_text}\nExplanation: {explanation}\n\n"

    gray_box_paragraph(doc, summary_text)

def highlight_and_summarize(docx_path, analysis, output_docx, language=None):
    """Apply highlights and add summary for each page."""
    try:
        doc = Document(docx_path)
        highlights_applied = False
        for page_result in analysis:
            all_errors = []
            for key in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
                for err in page_result.get(key, []):
                    err["category"] = key  # Add category for spelling check
                    all_errors.append(err)
            print(f"üìÑ Processing page {page_result['page']} with {len(all_errors)} errors to highlight")
            if highlight_errors_in_doc(doc, all_errors, language=language):
                highlights_applied = True
            add_page_summary(doc, page_result)
        if not highlights_applied:
            print("‚ö†Ô∏è Warning: No highlights applied to any paragraph. Check text extraction or PDF conversion.")
        doc.save(output_docx)
        print(f"‚úÖ Highlighted DOCX saved to: {output_docx}")
    except Exception as e:
        print(f"‚ùå Error in highlight_and_summarize: {e}")

# --- NEW VERSION: highlight_and_summarize (combined errors, single pass) ---
# Collects ALL errors from ALL pages first, then calls highlight_errors_in_doc ONCE.
# This prevents para.clear() from wiping previously rebuilt paragraphs on subsequent page iterations.
# To use: comment old highlight_and_summarize above and uncomment this one.
#
# def highlight_and_summarize(docx_path, analysis, output_docx, language=None):
#     """Apply highlights and add summary for each page. (Single-pass version)"""
#     try:
#         doc = Document(docx_path)
#         highlights_applied = False
#
#         # Collect ALL errors from ALL pages first, then highlight ONCE
#         combined_errors = []
#         for page_result in analysis:
#             for key in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
#                 for err in page_result.get(key, []):
#                     err["category"] = key
#                     combined_errors.append(err)
#
#         print(f"üìÑ Total errors to highlight across all pages: {len(combined_errors)}")
#         if combined_errors:
#             if highlight_errors_in_doc(doc, combined_errors, language=language):
#                 highlights_applied = True
#
#         # Add per-page summaries (still per-page)
#         for page_result in analysis:
#             add_page_summary(doc, page_result)
#
#         if not highlights_applied:
#             print("‚ö†Ô∏è Warning: No highlights applied to any paragraph. Check text extraction or PDF conversion.")
#         doc.save(output_docx)
#         print(f"‚úÖ Highlighted DOCX saved to: {output_docx}")
#     except Exception as e:
#         print(f"‚ùå Error in highlight_and_summarize: {e}")

def generate_markdown_report(final_json):
    lines = ["# Evaluation Report", ""]

    for page in final_json:
        lines.append(f"## Page {page.get('page')}")
        lines.append(f"**Summary:** {page.get('summary','')}\n")

        for section in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
            items = page.get(section, [])
            if items:
                lines.append(f"### {section.replace('_',' ').title()}")
                for err in items:
                    lines.append(f"- **{err.get('incorrect')}** ‚Üí {err.get('correct')} ({err.get('comment','')})")
                lines.append("")

        if page.get("question_answers"):
            lines.append("### Question Answers")
            for ans in page.get("question_answers", []):
                qno = ans.get("question_no", "")
                lines.append(f"**Q{qno}: {ans.get('question','')}** \n")
                lines.append(f"- **Answer:** {ans.get('answer','')} \n")
                lines.append(f"- **Explanation:** {ans.get('explanation','')}\n")
                lines.append(f"------------------------------------\n")

        lines.append("---")

    content = "\n".join(lines)
    return content

def generate_final_corrected_document(input_docx_path, final_json, output_docx_path, language=None):
    """Generates a clean corrected DOCX without highlights, applying all final corrections from final_json."""
    doc = Document(input_docx_path)

    # Build replacement map (longer incorrect strings first to avoid partial overlap)
    replacements = []
    for page in final_json:
        for key in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
            for err in page.get(key, []):
                incorrect = err.get("incorrect", "")
                correct = err.get("correct", "")
                if incorrect and correct and incorrect != correct:
                    replacements.append((incorrect, correct))

    # Sort replacements by length of incorrect desc (desc) to reduce partial matches
    replacements.sort(key=lambda x: len(x[0]), reverse=True)

    for para in doc.paragraphs:
        original = para.text
        corrected = original
        for inc, cor in replacements:
            # Use word-boundary replace when possible
            try:
                corrected = re.sub(r"\b" + re.escape(inc) + r"\b", cor, corrected)
            except re.error:
                corrected = corrected.replace(inc, cor)
        if corrected != original:
            para.clear()
            add_mixed_font_text(para, corrected, language=language)

    doc.save(output_docx_path)
    print(f"‚úÖ Final corrected DOCX generated: {output_docx_path}")
    return output_docx_path

# def evaluate_document(input_path: str, save_json=False):
#     try:
#         if input_path.endswith(".pdf"):
#             pages = extract_pages(input_path)
#             docx_path = convert_pdf_to_docx(input_path)
#         else:
#             docx_path = input_path
#             pages = extract_pages_from_docx(docx_path)

#         if not pages:
#             print(f"‚ùå No pages extracted from {input_path}")
#             return None, None, None   # <-- fixed

#         all_results = []
#         for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
#             result = primary_student_answersheet_evaluation(page_content, i)
#             all_results.append(result)

#         json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
#         if save_json:
#             with open(json_output, "w", encoding="utf-8") as f:
#                 json.dump(all_results, f, ensure_ascii=False, indent=4)

#         output_docx = docx_path.replace(".docx", "_evaluated.docx")
#         highlight_and_summarize(docx_path, all_results, output_docx)

#         markdown = generate_markdown_report(all_results)

#         return output_docx, markdown, all_results

#     except Exception as e:
#         print(f"‚ùå Error in evaluate_document: {e}")
#         return None, None, None



def evaluate_document(input_path: str, save_json=False, language=None):
    try:
        normalized_language = normalize_flow_language(language)
        if should_use_special_azure_flow(normalized_language):
            return evaluate_document_special_azure(
                input_path=input_path,
                save_json=save_json,
                language=normalized_language,
            )

        if input_path.endswith(".pdf"):
            pages = extract_pages(input_path)
            docx_path = convert_pdf_to_docx(input_path)
        else:
            docx_path = input_path
            pages = extract_pages_from_docx(docx_path)

        if not pages:
            print(f"‚ùå No pages extracted from {input_path}")
            return None, None, None, None

        all_results = []
        for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
            result = primary_student_answersheet_evaluation(page_content, i)
            all_results.append(result)

        # Optional JSON save
        json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
        if save_json:
            with open(json_output, "w", encoding="utf-8") as f:
                json.dump(all_results, f, ensure_ascii=False, indent=4)

        # # Highlighted DOCX
        # highlighted_docx = docx_path.replace(".docx", "_evaluated_highlighted.docx")
        # highlight_and_summarize(docx_path, all_results, highlighted_docx)

        # Highlighted DOCX
        # highlighted_docx = os.path.join(
        #     settings.UPLOAD_DIR, "questions_evaluation", "highlighted",
        #     os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
        # )
        highlighted_docx = os.path.join(
            RE_HIGHLIGHT_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
        )
        highlight_and_summarize(docx_path, all_results, highlighted_docx, language=normalized_language)

        # Final corrected DOCX
        # final_docx = os.path.join(
        #     settings.UPLOAD_DIR, "questions_evaluation", "final",
        #     os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
        # )
        
        final_docx = os.path.join(
            RE_FINAL_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
        )
        generate_final_corrected_document(docx_path, all_results, final_docx, language=normalized_language)



        # # Final corrected DOCX
        # final_docx = docx_path.replace(".docx", "_evaluated_final.docx")
        # generate_final_corrected_document(docx_path, all_results, final_docx)

        # Markdown report
        markdown = generate_markdown_report(all_results)

        return highlighted_docx, final_docx, markdown, all_results

    except Exception as e:
        print(f"‚ùå Error in evaluate_document: {e}")
        return None, None, None, None



# def evaluate_document(input_path:str, save_json=False):
#     try:
#         if input_path.endswith(".pdf"):
#             pages = extract_pages(input_path)
#             docx_path = convert_pdf_to_docx(input_path)
#         else:
#             docx_path = input_path
#             pages = extract_pages_from_docx(docx_path)

#         if not pages:
#             print(f"‚ùå No pages extracted from {input_path}")
#             return None, None

#         all_results = []
#         for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
#             result = primary_student_answersheet_evaluation(
#                 page_content, i
#             )
#             all_results.append(result)

#         # Save JSON
#         json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
#         if save_json:
#             with open(json_output, "w", encoding="utf-8") as f:
#                 json.dump(all_results, f, ensure_ascii=False, indent=4)

#         # Save highlighted DOCX
#         output_docx = docx_path.replace(".docx", "_evaluated.docx")
#         highlight_and_summarize(docx_path, all_results, output_docx)

#         # Log summary of issues
#         print(f"\n‚úÖ Evaluation Complete for {input_path}")
#         if save_json:
#             print(f"üíæ JSON saved to: {json_output}")
#         print(f"üìÑ Highlighted DOCX saved to: {output_docx}")
#         for result in all_results:
#             print(f"\nüìò Page {result['page']} Issues:")
#             for key in ["british_english",  "worksheet_format", "answer_key", "logical_flow"]:
#                 if result.get(key, []):
#                     print(f"  {key.replace('_', ' ').title()}:")
#                     for err in result.get(key, []):
#                         print(f"    ‚ùå {err.get('incorrect')} ‚Üí ‚úÖ {err.get('correct')} ({err.get('comment','')})")
#                 else:
#                     print(f"  ‚úÖ No {key.replace('_', ' ').title()} issues.")

#         markdown = generate_markdown_report(all_results)
        
#         return output_docx, markdown, all_results

#     except Exception as e:
#         print(f"‚ùå Error in evaluate_document: {e}")
#         return None, None




def re_evaluate_with_user_feedback(
    user_feedback_text: str,
    original_results,
    input_path: str,
    language: str = None
):
    """Re-evaluate or revise the LLM analysis using user feedback."""
    normalized_language = normalize_flow_language(language)

    if input_path.endswith(".pdf"):
        docx_path = convert_pdf_to_docx(input_path)
    else:
        docx_path = input_path

    feedback_prompt = (
        "You are provided with a previously generated evaluation JSON for a document. "
        "Apply the user feedback exactly and produce a revised JSON array of page evaluations. "
        "Do not add new keys outside the existing schema. Return ONLY valid JSON.\n\n"
        f"User feedback:\n{user_feedback_text}\n\n"
        f"Original evaluation JSON:\n{json.dumps(original_results, ensure_ascii=False)}\n\n"
        "Return the revised JSON only."
    )

    # response = client.chat.completions.create(
    #     model=settings.settings.AZURE_DEPLOYMENT_NAME,
    response = client.chat.completions.create(
        model=settings.AZURE_DEPLOYMENT_NAME,

        temperature=0,
        messages=[
            {"role": "system", "content": "You are a JSON editor specialized in educational assessment outputs."},
            {"role": "user", "content": feedback_prompt}
        ],
        stream=False
    )

    raw = response.choices[0].message.content.strip()
    json_start = raw.find("{")
    json_end = raw.rfind("}")

    if json_start != -1 and json_end != -1:
        cleaned = raw[json_start:json_end+1]
        try:
            updated = json.loads(cleaned)
        except json.JSONDecodeError:
            try:
                updated = json.loads(raw)
            except Exception as e:
                raise ValueError(f"Unable to parse LLM re-evaluation output: {e}\nRaw output:\n{raw}")

        filename = os.path.basename(input_path).split(".")[0]

        # # Highlighted DOCX
        # highlighted_docx = f"{settings.UPLOAD_DIR}/{filename}_{uuid.uuid4().hex[:6]}_reevaluated_highlighted.docx"
        # highlight_and_summarize(docx_path, updated, highlighted_docx)

        # # Final corrected DOCX
        # final_docx = f"{settings.UPLOAD_DIR}/{filename}_{uuid.uuid4().hex[:6]}_reevaluated_final.docx"
        # generate_final_corrected_document(docx_path, updated, final_docx)

        # highlighted_docx = os.path.join(
        #     settings.UPLOAD_DIR, "questions_re_evaluation", "highlighted",
        #     os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
        # )
        
        highlighted_docx = os.path.join(
            HIGHLIGHT_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
        )

        highlight_and_summarize(docx_path, updated, highlighted_docx, language=normalized_language)

        # Final corrected DOCX
        # final_docx = os.path.join(
        #     settings.UPLOAD_DIR, "questions_re_evaluation", "final",
        #     os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
        # )
        
        final_docx = os.path.join(
            FINAL_DIR,
            os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
        )

        generate_final_corrected_document(docx_path, updated, final_docx, language=normalized_language)



        # Markdown report
        markdown = generate_markdown_report(updated)

        return highlighted_docx, final_docx, markdown, updated

    else:
        raise ValueError(f"No JSON object detected in LLM response. Raw output:\n{raw}")




# def re_evaluate_with_user_feedback(
#     user_feedback_text: str,
#     original_results,
#     input_path: str
# ):
#     """Re-evaluate or revise the LLM analysis using user feedback.

#     original_results can be a Python list (parsed JSON) or path to a JSON file.
#     Returns the updated JSON (Python list/dict).
#     """
#     # if isinstance(original_results, str) and os.path.exists(original_results):
#     #     with open(original_results, "r", encoding="utf-8") as f:
#     #         original = json.load(f)
#     # else:
#     #     original = original_results

#     if input_path.endswith(".pdf"):
#         docx_path = convert_pdf_to_docx(input_path)
#     else:
#         docx_path = input_path


#     feedback_prompt = (
#         "You are provided with a previously generated evaluation JSON for a document. "
#         "Apply the user feedback exactly and produce a revised JSON array of page evaluations. "
#         "Do not add new keys outside the existing schema. Return ONLY valid JSON.\n\n"
#         f"User feedback:\n{user_feedback_text}\n\n"
#         f"Original evaluation JSON:\n{json.dumps(original_results, ensure_ascii=False)}\n\n"
#         "Return the revised JSON only."
#     )

#     response = client.chat.completions.create(
#         model=settings.AZURE_DEPLOYMENT_NAME,
#         temperature=0,
#         messages=[{"role": "system", "content": "You are a JSON editor specialized in educational assessment outputs."},
#                   {"role": "user", "content": feedback_prompt}],
#         stream=False
#     )

#     raw = response.choices[0].message.content.strip()
#     json_start = raw.find("{")
#     json_end = raw.rfind("}")
#     if json_start != -1 and json_end != -1:
#         cleaned = raw[json_start:json_end+1]
#         try:
#             updated = json.loads(cleaned)
#         except json.JSONDecodeError:
#             # If LLM returned an array
#             try:
#                 updated = json.loads(raw)
#             except Exception as e:
#                 raise ValueError(f"Unable to parse LLM re-evaluation output: {e}\nRaw output:\n{raw}")
            
#         filename = os.path.basename(input_path).split(".")[0]
#         output_docx_path = f"{settings.UPLOAD_DIR}/{filename}_{uuid.uuid4().hex[:6]}.docx"
#         generate_final_corrected_document(docx_path, updated, output_docx_path)
#         markdown = generate_markdown_report(updated)
#         return output_docx_path, markdown, updated
#     else:
#         raise ValueError(f"No JSON object detected in LLM response. Raw output:\n{raw}")


def main():
    input_path = r"C:\Users\arpichau\Downloads\Question_evaluation\Input_files\Tel_VI_question_paper_c37ae6..pdf"
    save_json = True
    language = "telugu"  # set None to use existing normal flow

    if not os.path.exists(input_path):
        print(f"File not found: {input_path}")
        return

    print(f"Evaluating file: {input_path}")

    highlighted_docx, final_docx, markdown, results = evaluate_document(
        input_path=input_path,
        save_json=save_json,
        language=language,
    )

    if not results:
        print("Evaluation failed.")
        return

    print("Evaluation completed successfully!")
    print(f"Highlighted DOCX: {highlighted_docx}")
    print(f"Final Corrected DOCX: {final_docx}")

    if save_json:
        json_path = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
        print(f"JSON saved at: {json_path}")


if __name__ == "__main__":
    main()



















# import os
# import re
# import json
# import uuid
# import pdfplumber
# from docx import Document
# from docx.oxml import OxmlElement
# from docx.oxml.ns import qn
# from docx.shared import RGBColor, Pt, Inches

# from pdf2docx import Converter
# from tqdm import tqdm
# from fuzzywuzzy import fuzz

# from config import settings
# from utils.azure_client import client

# def convert_pdf_to_docx(pdf_path):
#     """Convert PDF to DOCX while preserving layout."""
#     output_path = pdf_path.replace(".pdf", "_converted.docx")
#     try:
#         cv = Converter(pdf_path)
#         cv.convert(output_path, start=0, end=None)
#         cv.close()
#         print(f"‚úÖ PDF converted to DOCX: {output_path}")
#     except Exception as e:
#         print(f"‚ùå Error converting PDF to DOCX: {e}")
#         raise
#     return output_path

# def extract_pages(pdf_path):
#     """Extract text from each PDF page using pdfplumber."""
#     try:
#         pages = []
#         with pdfplumber.open(pdf_path) as pdf:
#             for page in pdf.pages:
#                 text = page.extract_text() or ""
#                 # Normalize text: remove extra whitespace, non-breaking spaces, etc.
#                 text = re.sub(r'\s+', ' ', text.replace('\xa0', ' ').strip())
#                 pages.append(text)
#         return pages
#     except Exception as e:
#         print(f"‚ùå Error extracting text from PDF: {e}")
#         return []


# def extract_pages_from_docx(docx_path, words_per_page=1500):
#     """Split DOCX into pseudo-pages if no real pages exist."""
#     try:
#         doc = Document(docx_path)
#         text = "\n".join(p.text for p in doc.paragraphs)
#         # Normalize text
#         text = re.sub(r'\s+', ' ', text.replace('\xa0', ' ').strip())
#         words = text.split()
#         pages = [" ".join(words[i:i+words_per_page]) for i in range(0, len(words), words_per_page)]
#         return pages
#     except Exception as e:
#         print(f"‚ùå Error extracting text from DOCX: {e}")
#         return []


# def extract_questions(text):
#     """
#     Extract numbered questions like:
#     1. , 1) , Q1 , Q1. , (a) etc.
#     """
#     pattern = re.compile(
#         r'(?:^|\n)\s*(Q?\d+[\.\)]|\(\w+\))\s+(.*?)(?=\n\s*(?:Q?\d+[\.\)]|\(\w+\))|\Z)',
#         re.IGNORECASE | re.DOTALL
#     )
#     return [(m.group(1).strip(), m.group(2).strip()) for m in pattern.finditer(text)]


# def detect_repeated_questions(page_content, threshold=90):
#     questions = extract_questions(page_content)
#     repeats = []

#     for i in range(len(questions)):
#         qno1, q1 = questions[i]
#         for j in range(i + 1, len(questions)):
#             qno2, q2 = questions[j]
#             similarity = fuzz.token_set_ratio(q1, q2)
#             if similarity >= threshold:
#                 repeats.append({
#                     "incorrect": q1[:120],
#                     "correct": q1[:120],
#                     "comment": f"Repeated question detected (similar to {qno2})"
#                 })
#     return repeats


# def detect_numbering_issues(page_content):
#     numbers = re.findall(r'\bQ?(\d+)[\.\)]', page_content)
#     numbers = list(map(int, numbers))

#     issues = []
#     if numbers:
#         expected = list(range(min(numbers), max(numbers) + 1))
#         missing = set(expected) - set(numbers)
#         if missing:
#             issues.append({
#                 "incorrect": f"Missing question numbers: {sorted(missing)}",
#                 "correct": "Ensure continuous question numbering",
#                 "comment": "Inconsistent question numbering detected"
#             })
#     return issues


# def detect_complex_vocabulary(page_content):
#     complex_words = []
#     for word in re.findall(r'\b[a-zA-Z]{9,}\b', page_content):
#         if word.lower() not in {"information", "education", "government"}:
#             complex_words.append(word)

#     return [{
#         "incorrect": w,
#         "correct": "",
#         "comment": "Vocabulary may be too advanced for primary-grade students"
#     } for w in set(complex_words)]



# def detect_basic_punctuation_caps(text):
#     issues = []
#     sentences = re.split(r'(?<=[.!?])\s+', text)

#     for s in sentences:
#         if s and s[0].islower():
#             issues.append({
#                 "incorrect": s[:50],
#                 "correct": s[:50].capitalize(),
#                 "comment": "Sentence should start with a capital letter"
#             })

#         if s.endswith(','):
#             issues.append({
#                 "incorrect": s[-20:],
#                 "correct": s.rstrip(',') + '.',
#                 "comment": "Incorrect punctuation at sentence end"
#             })
#     return issues


# def detect_science_notation_issues(text):
#     issues = []

#     # Missing superscripts like m2 instead of m¬≤
#     if re.search(r'\bm2\b|\bcm2\b|\bm3\b', text):
#         issues.append({
#             "incorrect": "m2 / cm2 / m3",
#             "correct": "m¬≤ / cm¬≤ / m¬≥",
#             "comment": "Scientific units should use superscripts"
#         })

#     # Wrong unit casing (e.g., watt instead of W)
#     if re.search(r'\b(watt|joule|newton)\b', text):
#         issues.append({
#             "incorrect": "Incorrect unit casing",
#             "correct": "W / J / N",
#             "comment": "Scientific units must use standard symbols"
#         })

#     return issues


# def detect_similar_internal_choices(page_content, threshold=85):
#     choices = re.findall(r'\([a-dA-D]\)\s*(.*)', page_content)
#     issues = []

#     for i in range(len(choices)):
#         for j in range(i + 1, len(choices)):
#             score = fuzz.token_set_ratio(choices[i], choices[j])
#             if score >= threshold:
#                 issues.append({
#                     "incorrect": choices[i][:100],
#                     "correct": choices[i][:100],
#                     "comment": "Internal choices are too similar and may confuse students"
#                 })
#     return issues



# def detect_missing_answer_keys(page_content, parsed_json):
#     question_numbers = re.findall(r'\bQ?(\d+)[\.\)]', page_content)
#     answered = {
#         str(ans.get("question_no"))
#         for ans in parsed_json.get("question_answers", [])
#         if ans.get("question_no") is not None
#     }

#     issues = []
#     for q in set(question_numbers):
#         if q not in answered:
#             issues.append({
#                 "incorrect": f"Question {q}",
#                 "correct": "",
#                 "comment": "Answer key missing for this question"
#             })
#     return issues



# def primary_student_answersheet_evaluation(
#     page_content,
#     page_num,
#     raw_output_dir="raw_llm_outputs"
# ):
#     """Call AzureOpenAI and return parsed JSON result for a single page.

#     IMPORTANT: api_key and azure_endpoint should be provided via environment variables
#     or function arguments to avoid hardcoding secrets in source.
#     """
#     try:
#         if not page_content.strip():
#             return {
#                 "page": page_num,
#                 "grammar_spelling": [],
#                 "worksheet_format": [],
#                 "answer_key": [],
#                 "logical_flow": [],
#                 "british_english": [],
#                 "paragraph_corrections": [],
#                 "question_relevance": [],
#                 "question_answers": [],
#                 "summary": "Empty page, skipped."
#             }

#         prompt = f"""
#             You are an expert in analyzing primary student question papers. Evaluate only the question sheet provided in `page_content`. Do not provide answers for questions unless explicitly provided in the text. Conduct a strict, thorough review of the given page content to ensure clarity and accuracy with the passage.

#             ### Important Rules:
#             - If the page content is empty, return an empty dictionary (`{{}}`) with only the summary: "Empty page, skipped."
#             - Only evaluate text explicitly present in `page_content`. Do not infer, modify, or add details beyond it.
#             - Do not flag correct sentences or single letters as incorrect.
#             - Ensure corrections maintain the original meaning of the sentence or answer.
#             - Be strict: only report errors explicitly present in `page_content`.
#             - Avoid redundant or repeated corrections (e.g., do not include if `incorrect` equals `correct`).
#             - Provide specific, actionable comments for each correction (e.g., "American spelling detected" for British English issues).
#             - Do not include evaluation criteria, examples, or any text not in `page_content` in the output.
#             - Use British English conventions for all corrections.
#             - For spelling errors (in `grammar_spelling` or `british_english`), only return the incorrect word, not the full sentence, unless sentence structure is involved.
#             - Explicitly check punctuation errors (missing or incorrect commas, full stops, question marks, quotation marks).
#             - Explicitly check capitalisation errors (sentence starts, proper nouns, headings).
#             - Check word usage carefully, including tense, articles, prepositions, and subject‚Äìverb agreement.
#             - Check for repetition of questions within the page.
#             - Check for inconsistent numbering or formatting of questions.
#             - Flag vocabulary that is not appropriate for a primary-grade student.
#             - For science questions, verify that facts, laws, formulas, units, and symbols are correct.
#             - Flag outdated scientific theories or incorrect data.
#             - Ensure diagrams (if referenced) follow standard scientific conventions.
#             - Ensure symbols, subscripts, and superscripts are scientifically accurate.
#             - Check that the same scientific concept is not tested multiple times unintentionally.


#             Text to evaluate:
#             ---
#             {page_content}
#             ---

#             Return ONLY JSON, no markdown, no extra details. The JSON schema expected is:
#             {{
#             "grammar_spelling": [],
#             "worksheet_format": [],
#             "answer_key": [],
#             "logical_flow": [],
#             "british_english": [],
#             "paragraph_corrections": [],
#             "question_relevance": [],
#             "question_answers": [],
#             "summary": ""
#             }}
#         """

#         response = client.chat.completions.create(
#             model=settings.AZURE_DEPLOYMENT_NAME,
#             temperature=0,
#             messages=[
#                 {"role": "system", "content": "You are a strict primary student answer sheet evaluator."},
#                 {"role": "user", "content": prompt},
#             ],
#             stream=False,
#         )

#         raw_output = response.choices[0].message.content.strip()

#         os.makedirs(raw_output_dir, exist_ok=True)
#         raw_path = os.path.join(raw_output_dir, f"page_{page_num}_raw.txt")
#         with open(raw_path, "w", encoding="utf-8") as f:
#             f.write(raw_output)

#         # Try to find JSON object inside raw_output
#         json_start = raw_output.find("{")
#         json_end = raw_output.rfind("}")
#         if json_start != -1 and json_end != -1:
#             cleaned = raw_output[json_start:json_end+1]
#             try:
#                 parsed_json = json.loads(cleaned)
#                 # -----------------------------
#                 # Deterministic enrichments
#                 # -----------------------------

#                 # Repeated questions
#                 parsed_json["worksheet_format"].extend(
#                     detect_repeated_questions(page_content)
#                 )

#                 # Numbering consistency
#                 parsed_json["worksheet_format"].extend(
#                     detect_numbering_issues(page_content)
#                 )

#                 # Vocabulary level (primary-grade)
#                 parsed_json["grammar_spelling"].extend(
#                     detect_complex_vocabulary(page_content)
#                 )

#                 # Capitalisation & punctuation
#                 parsed_json["grammar_spelling"].extend(
#                     detect_basic_punctuation_caps(page_content)
#                 )

                
                
#                 # -----------------------------
#                 # Science-specific checks
#                 # -----------------------------

#                 # Scientific notation & units
#                 parsed_json["grammar_spelling"].extend(
#                     detect_science_notation_issues(page_content)
#                 )

#                 # Similar internal choices
#                 parsed_json["worksheet_format"].extend(
#                     detect_similar_internal_choices(page_content)
#                 )

#                 # Answer key completeness
#                 parsed_json["answer_key"].extend(
#                     detect_missing_answer_keys(page_content, parsed_json)
#                 )


#             except json.JSONDecodeError:
#                 parsed_json = {
#                     "page": page_num,
#                     "grammar_spelling": [],
#                     "worksheet_format": [],
#                     "answer_key": [],
#                     "logical_flow": [],
#                     "british_english": [],
#                     "paragraph_corrections": [],
#                     "question_relevance": [],
#                     "question_answers": [],
#                     "summary": "Invalid JSON or no output"
#                 }
#         else:
#             parsed_json = {
#                 "page": page_num,
#                 "grammar_spelling": [],
#                 "worksheet_format": [],
#                 "answer_key": [],
#                 "logical_flow": [],
#                 "british_english": [],
#                 "paragraph_corrections": [],
#                 "question_relevance": [],
#                 "question_answers": [],
#                 "summary": "Invalid JSON or no output"
#             }

#         # Validate and filter out invalid corrections
#         for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
#             valid_items = []
#             for item in parsed_json.get(key, []):
#                 incorrect = item.get("incorrect", "").strip()
#                 correct = item.get("correct", "").strip()
#                 comment = item.get("comment", "").strip()
#                 # if incorrect and correct and comment and incorrect != correct:
#                 #     valid_items.append(item)
#                 # else:
#                 #     # keep entries that might be part of other structures (e.g., one-word spelling entries)
#                 #     # but avoid noisy empty items
#                 #     if incorrect and correct and incorrect != correct:
#                 #         valid_items.append(item)
#                 #     else:
#                 #         print(f"‚ö†Ô∏è Skipped invalid {key} correction: {item}")
                
#                 if incorrect and comment and incorrect != correct:
#                     valid_items.append(item)
#                 else:
#                     print(f"‚ö†Ô∏è Skipped invalid {key} correction: {item}")

#             parsed_json[key] = valid_items

#         # Ensure required keys exist
#         for key in ["paragraph_corrections", "question_relevance", "question_answers"]:
#             if key not in parsed_json:
#                 parsed_json[key] = []

#         parsed_json["page"] = page_num

#         # Enhanced logging
#         print(f"\nüìò PAGE {page_num} SUMMARY üìò")
#         for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
#             if not parsed_json.get(key, []):
#                 print(f"  ‚úÖ No {key.replace('_', ' ').title()} issues detected.")
#             else:
#                 for err in parsed_json.get(key, []):
#                     print(f"  ‚ùå {err.get('incorrect')} ‚Üí ‚úÖ {err.get('correct')} ({err.get('comment','')})")
#         print(f"üìù Summary: {parsed_json.get('summary', '')}")

#         return parsed_json

#     except Exception as e:
#         print(f"‚ùå Error analyzing page {page_num}: {e}")
#         return {
#             "page": page_num,
#             "grammar_spelling": [],
#             "worksheet_format": [],
#             "answer_key": [],
#             "logical_flow": [],
#             "british_english": [],
#             "paragraph_corrections": [],
#             "question_relevance": [],
#             "question_answers": [],
#             "summary": f"Error: {e}"
#         }
    
# def apply_color(run, color):
#     """Apply red or green color to text."""
#     if color == "red":
#         run.font.color.rgb = RGBColor(255, 0, 0)
#     elif color == "green":
#         run.font.color.rgb = RGBColor(0, 128, 0)
#     run.font.bold = True
    
# def highlight_errors_in_doc(doc, errors):
#     """Highlight incorrect words/sentences inline with color, correction, and small-font comment."""
#     highlights_applied = False
#     for para in doc.paragraphs:
#         para_text = para.text
#         if not para_text.strip():
#             continue
#         matches = []
#         for err in errors:
#             wrong = err.get("incorrect", "").strip()
#             if not wrong:
#                 continue
#             # Use exact matching with re.finditer
#             pattern = re.escape(wrong)  # Escape special characters in the error text
#             for match in re.finditer(pattern, para_text, re.IGNORECASE):
#                 start, end = match.start(), match.end()
#                 matches.append((start, end, err))
#             if not matches:
#                 print(f"‚ö†Ô∏è No exact match for '{wrong}' in paragraph: {para_text[:50]}...")
#         if not matches:
#             continue
#         # Sort matches by start position
#         matches.sort(key=lambda x: x[0])
#         # Rebuild paragraph runs
#         para.clear()
#         last_end = 0
#         for start, end, err in matches:
#             if start > last_end:
#                 para.add_run(para_text[last_end:start])
#             # Check if it's a spelling error
#             is_spelling = err.get("comment", "").lower() in [
#                 "american spelling detected", "spelling error", "incorrect spelling",
#                 "british spelling required", "contraction not allowed"
#             ] or err.get("category", "") in ["grammar_spelling", "british_english"]
#             wrong_text = para_text[start:end]
#             if is_spelling:
#                 red_run = para.add_run(wrong_text)
#                 apply_color(red_run, "red")
#             else:
#                 red_run = para.add_run(wrong_text)
#                 apply_color(red_run, "red")
#             # Add green correction
#             right = err.get("correct", "").strip()
#             if right:
#                 green_run = para.add_run(f" ({right})")
#                 apply_color(green_run, "green")
#             # Add small-font comment
#             if comment := err.get("comment", ""):
#                 comment_run = para.add_run(f" [{comment}]")
#                 comment_run.font.size = Pt(8)
#                 comment_run.font.color.rgb = RGBColor(128, 128, 128)
#             last_end = end
#             highlights_applied = True
#             print(f"‚úÖ Highlighted '{wrong_text}' ‚Üí '{right}' ({comment}) at position {start}-{end}")
#         if last_end < len(para_text):
#             para.add_run(para_text[last_end:])
#     return highlights_applied

# def gray_box_paragraph(doc, text):
#     """Add shaded paragraph for page summary."""
#     p = doc.add_paragraph()
#     run = p.add_run(text)
#     run.bold = True
#     p_format = p.paragraph_format
#     p_format.space_before = Pt(12)
#     p_format.space_after = Pt(12)
#     shading_elm = OxmlElement("w:shd")
#     shading_elm.set(qn("w:fill"), "D9D9D9")
#     p._element.get_or_add_pPr().append(shading_elm)
#     return p

# def add_page_summary(doc, page_result):
#     """Add detailed summary at the end of the current page. Also appends question answers."""
#     summary_text = f"üìò Page {page_result['page']} Summary üìò\n"
#     summary_text += f"üìù {page_result.get('summary','')}\n\n"
#     for key in ["grammar_spelling", "worksheet_format",  "answer_key", "logical_flow", "british_english"]:
#         items = page_result.get(key, [])
#         if items:
#             summary_text += f"--- {key.replace('_',' ').title()} ---\n"
#             for err in items:
#                 summary_text += f"{err.get('incorrect')} ‚Üí {err.get('correct')} ({err.get('comment','')})\n"

#     # Append question answers if present
#     if page_result.get("question_answers"):
#         summary_text += "\nüìö Answers for Questions\n"
#         for ans in page_result.get("question_answers", []):
#             qno = ans.get("question_no") or ans.get("question_no", "")
#             question_text = ans.get("question", "")
#             answer_text = ans.get("answer", "")
#             explanation = ans.get("explanation", "")
#             summary_text += f"Q{qno}: {question_text}\nAnswer: {answer_text}\nExplanation: {explanation}\n\n"

#     gray_box_paragraph(doc, summary_text)

# def highlight_and_summarize(docx_path, analysis, output_docx):
#     """Apply highlights and add summary for each page."""
#     try:
#         doc = Document(docx_path)
#         highlights_applied = False
#         for page_result in analysis:
#             all_errors = []
#             for key in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
#                 for err in page_result.get(key, []):
#                     err["category"] = key  # Add category for spelling check
#                     all_errors.append(err)
#             print(f"üìÑ Processing page {page_result['page']} with {len(all_errors)} errors to highlight")
#             if highlight_errors_in_doc(doc, all_errors):
#                 highlights_applied = True
#             add_page_summary(doc, page_result)
#         if not highlights_applied:
#             print("‚ö†Ô∏è Warning: No highlights applied to any paragraph. Check text extraction or PDF conversion.")
#         doc.save(output_docx)
#         print(f"‚úÖ Highlighted DOCX saved to: {output_docx}")
#     except Exception as e:
#         print(f"‚ùå Error in highlight_and_summarize: {e}")

# def generate_markdown_report(final_json):
#     lines = ["# Evaluation Report", ""]

#     for page in final_json:
#         lines.append(f"## Page {page.get('page')}")
#         lines.append(f"**Summary:** {page.get('summary','')}\n")

#         for section in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
#             items = page.get(section, [])
#             if items:
#                 lines.append(f"### {section.replace('_',' ').title()}")
#                 for err in items:
#                     lines.append(f"- **{err.get('incorrect')}** ‚Üí {err.get('correct')} ({err.get('comment','')})")
#                 lines.append("")

#         if page.get("question_answers"):
#             lines.append("### Question Answers")
#             for ans in page.get("question_answers", []):
#                 qno = ans.get("question_no", "")
#                 lines.append(f"**Q{qno}: {ans.get('question','')}** \n")
#                 lines.append(f"- **Answer:** {ans.get('answer','')} \n")
#                 lines.append(f"- **Explanation:** {ans.get('explanation','')}\n")
#                 lines.append(f"------------------------------------\n")

#         lines.append("---")

#     content = "\n".join(lines)
#     return content

# def generate_final_corrected_document(input_docx_path, final_json, output_docx_path):
#     """Generates a clean corrected DOCX without highlights, applying all final corrections from final_json."""
#     doc = Document(input_docx_path)

#     # Build replacement map (longer incorrect strings first to avoid partial overlap)
#     replacements = []
#     for page in final_json:
#         for key in ["grammar_spelling", "worksheet_format", "answer_key", "logical_flow", "british_english"]:
#             for err in page.get(key, []):
#                 incorrect = err.get("incorrect", "")
#                 correct = err.get("correct", "")
#                 if incorrect and correct and incorrect != correct:
#                     replacements.append((incorrect, correct))

#     # Sort replacements by length of incorrect desc (desc) to reduce partial matches
#     replacements.sort(key=lambda x: len(x[0]), reverse=True)

#     for para in doc.paragraphs:
#         original = para.text
#         corrected = original
#         for inc, cor in replacements:
#             # Use word-boundary replace when possible
#             try:
#                 corrected = re.sub(r"\b" + re.escape(inc) + r"\b", cor, corrected)
#             except re.error:
#                 corrected = corrected.replace(inc, cor)
#         if corrected != original:
#             para.clear()
#             para.add_run(corrected)

#     doc.save(output_docx_path)
#     print(f"‚úÖ Final corrected DOCX generated: {output_docx_path}")
#     return output_docx_path

# # def evaluate_document(input_path: str, save_json=False):
# #     try:
# #         if input_path.endswith(".pdf"):
# #             pages = extract_pages(input_path)
# #             docx_path = convert_pdf_to_docx(input_path)
# #         else:
# #             docx_path = input_path
# #             pages = extract_pages_from_docx(docx_path)

# #         if not pages:
# #             print(f"‚ùå No pages extracted from {input_path}")
# #             return None, None, None   # <-- fixed

# #         all_results = []
# #         for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
# #             result = primary_student_answersheet_evaluation(page_content, i)
# #             all_results.append(result)

# #         json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
# #         if save_json:
# #             with open(json_output, "w", encoding="utf-8") as f:
# #                 json.dump(all_results, f, ensure_ascii=False, indent=4)

# #         output_docx = docx_path.replace(".docx", "_evaluated.docx")
# #         highlight_and_summarize(docx_path, all_results, output_docx)

# #         markdown = generate_markdown_report(all_results)

# #         return output_docx, markdown, all_results

# #     except Exception as e:
# #         print(f"‚ùå Error in evaluate_document: {e}")
# #         return None, None, None



# def evaluate_document(input_path: str, save_json=False):
#     try:
#         if input_path.endswith(".pdf"):
#             pages = extract_pages(input_path)
#             docx_path = convert_pdf_to_docx(input_path)
#         else:
#             docx_path = input_path
#             pages = extract_pages_from_docx(docx_path)

#         if not pages:
#             print(f"‚ùå No pages extracted from {input_path}")
#             return None, None, None, None

#         all_results = []
#         for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
#             result = primary_student_answersheet_evaluation(page_content, i)
#             all_results.append(result)

#         # Optional JSON save
#         json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
#         if save_json:
#             with open(json_output, "w", encoding="utf-8") as f:
#                 json.dump(all_results, f, ensure_ascii=False, indent=4)

#         # # Highlighted DOCX
#         # highlighted_docx = docx_path.replace(".docx", "_evaluated_highlighted.docx")
#         # highlight_and_summarize(docx_path, all_results, highlighted_docx)

#         # Highlighted DOCX
#         highlighted_docx = os.path.join(
#             settings.UPLOAD_DIR, "questions_evaluation", "highlighted",
#             os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
#         )
#         highlight_and_summarize(docx_path, all_results, highlighted_docx)

#         # Final corrected DOCX
#         final_docx = os.path.join(
#             settings.UPLOAD_DIR, "questions_evaluation", "final",
#             os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
#         )
#         generate_final_corrected_document(docx_path, all_results, final_docx)



#         # # Final corrected DOCX
#         # final_docx = docx_path.replace(".docx", "_evaluated_final.docx")
#         # generate_final_corrected_document(docx_path, all_results, final_docx)

#         # Markdown report
#         markdown = generate_markdown_report(all_results)

#         return highlighted_docx, final_docx, markdown, all_results

#     except Exception as e:
#         print(f"‚ùå Error in evaluate_document: {e}")
#         return None, None, None, None



# # def evaluate_document(input_path:str, save_json=False):
# #     try:
# #         if input_path.endswith(".pdf"):
# #             pages = extract_pages(input_path)
# #             docx_path = convert_pdf_to_docx(input_path)
# #         else:
# #             docx_path = input_path
# #             pages = extract_pages_from_docx(docx_path)

# #         if not pages:
# #             print(f"‚ùå No pages extracted from {input_path}")
# #             return None, None

# #         all_results = []
# #         for i, page_content in enumerate(tqdm(pages, desc="Analyzing Pages"), start=1):
# #             result = primary_student_answersheet_evaluation(
# #                 page_content, i
# #             )
# #             all_results.append(result)

# #         # Save JSON
# #         json_output = input_path.replace(".pdf", "_analysis.json").replace(".docx", "_analysis.json")
# #         if save_json:
# #             with open(json_output, "w", encoding="utf-8") as f:
# #                 json.dump(all_results, f, ensure_ascii=False, indent=4)

# #         # Save highlighted DOCX
# #         output_docx = docx_path.replace(".docx", "_evaluated.docx")
# #         highlight_and_summarize(docx_path, all_results, output_docx)

# #         # Log summary of issues
# #         print(f"\n‚úÖ Evaluation Complete for {input_path}")
# #         if save_json:
# #             print(f"üíæ JSON saved to: {json_output}")
# #         print(f"üìÑ Highlighted DOCX saved to: {output_docx}")
# #         for result in all_results:
# #             print(f"\nüìò Page {result['page']} Issues:")
# #             for key in ["british_english",  "worksheet_format", "answer_key", "logical_flow"]:
# #                 if result.get(key, []):
# #                     print(f"  {key.replace('_', ' ').title()}:")
# #                     for err in result.get(key, []):
# #                         print(f"    ‚ùå {err.get('incorrect')} ‚Üí ‚úÖ {err.get('correct')} ({err.get('comment','')})")
# #                 else:
# #                     print(f"  ‚úÖ No {key.replace('_', ' ').title()} issues.")

# #         markdown = generate_markdown_report(all_results)
        
# #         return output_docx, markdown, all_results

# #     except Exception as e:
# #         print(f"‚ùå Error in evaluate_document: {e}")
# #         return None, None




# def re_evaluate_with_user_feedback(
#     user_feedback_text: str,
#     original_results,
#     input_path: str
# ):
#     """Re-evaluate or revise the LLM analysis using user feedback."""

#     if input_path.endswith(".pdf"):
#         docx_path = convert_pdf_to_docx(input_path)
#     else:
#         docx_path = input_path

#     feedback_prompt = (
#         "You are provided with a previously generated evaluation JSON for a document. "
#         "Apply the user feedback exactly and produce a revised JSON array of page evaluations. "
#         "Do not add new keys outside the existing schema. Return ONLY valid JSON.\n\n"
#         f"User feedback:\n{user_feedback_text}\n\n"
#         f"Original evaluation JSON:\n{json.dumps(original_results, ensure_ascii=False)}\n\n"
#         "Return the revised JSON only."
#     )

#     response = client.chat.completions.create(
#         model=settings.AZURE_DEPLOYMENT_NAME,
#         temperature=0,
#         messages=[
#             {"role": "system", "content": "You are a JSON editor specialized in educational assessment outputs."},
#             {"role": "user", "content": feedback_prompt}
#         ],
#         stream=False
#     )

#     raw = response.choices[0].message.content.strip()
#     json_start = raw.find("{")
#     json_end = raw.rfind("}")

#     if json_start != -1 and json_end != -1:
#         cleaned = raw[json_start:json_end+1]
#         try:
#             updated = json.loads(cleaned)
#         except json.JSONDecodeError:
#             try:
#                 updated = json.loads(raw)
#             except Exception as e:
#                 raise ValueError(f"Unable to parse LLM re-evaluation output: {e}\nRaw output:\n{raw}")

#         filename = os.path.basename(input_path).split(".")[0]

#         # # Highlighted DOCX
#         # highlighted_docx = f"{settings.UPLOAD_DIR}/{filename}_{uuid.uuid4().hex[:6]}_reevaluated_highlighted.docx"
#         # highlight_and_summarize(docx_path, updated, highlighted_docx)

#         # # Final corrected DOCX
#         # final_docx = f"{settings.UPLOAD_DIR}/{filename}_{uuid.uuid4().hex[:6]}_reevaluated_final.docx"
#         # generate_final_corrected_document(docx_path, updated, final_docx)

#         highlighted_docx = os.path.join(
#             settings.UPLOAD_DIR, "questions_re_evaluation", "highlighted",
#             os.path.basename(docx_path).replace(".docx", "_evaluated_highlighted.docx")
#         )
#         highlight_and_summarize(docx_path, updated, highlighted_docx)

#         # Final corrected DOCX
#         final_docx = os.path.join(
#             settings.UPLOAD_DIR, "questions_re_evaluation", "final",
#             os.path.basename(docx_path).replace(".docx", "_evaluated_final.docx")
#         )
#         generate_final_corrected_document(docx_path, updated, final_docx)



#         # Markdown report
#         markdown = generate_markdown_report(updated)

#         return highlighted_docx, final_docx, markdown, updated

#     else:
#         raise ValueError(f"No JSON object detected in LLM response. Raw output:\n{raw}")

