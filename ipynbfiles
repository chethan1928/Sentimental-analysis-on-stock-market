
import asyncio
import json
import os
import random
import re
import shutil
import tempfile
import uuid
from difflib import SequenceMatcher
from typing import Dict, Optional
from pydub import AudioSegment

import pandas as pd
import io
from sqlalchemy import text

from deep_translator import GoogleTranslator
from fastapi import APIRouter, File, Form, UploadFile, HTTPException, Depends, Request
from faster_whisper import WhisperModel
from jiwer import wer
from openai import AzureOpenAI
from logger_setup import logger

import pandas as pd
import io
    
from sqlalchemy import text

from models import User
from db.agents_db import chat_session_db as db, async_session
from utils.agents_utils import load_language_mapping
from utils.tts_utils import generate_tts_url
from utils.user_details import get_current_user
 
router = APIRouter()




llm_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)




QWEN_ENABLED = False
qwen_client = None  
QWEN_MODEL_NAME = "Qwen/Qwen3-0.6B"  


_whisper_model = WhisperModel("large-v3", device="cpu", compute_type="int8")


 
PASSING_SCORE = 50
MAX_ATTEMPTS = 3  
SENTENCES_PER_WORD_NORMAL = 3   
SENTENCES_PER_WORD_STRICT = 5   
DEFAULT_NUM_WORDS = 5           

# import asyncio
# from transformers import AutoModelForCausalLM, AutoTokenizer

# MODEL_NAME = "Qwen/Qwen3-0.6B"

# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
# model = AutoModelForCausalLM.from_pretrained(
#     MODEL_NAME,
#     torch_dtype="auto",
#     device_map="auto"
# )
# import asyncio
# import torch

# async def call_llm(prompt: str, mode: str = "chat", timeout: int = 30) -> str:
#     system_prompts = {
#         "chat": f"You are {BOT_NAME}, a warm and helpful FAQ practice coach.",
#         "analysis": "You are an expert language and interview evaluator. Analyze objectively.",
#         "strict_json": "You are a structured evaluator. Respond ONLY in valid JSON. No extra text."
#     }

#     def run():
#         messages = [
#             {"role": "system", "content": system_prompts.get(mode, system_prompts["chat"])},
#             {"role": "user", "content": prompt}
#         ]

#         text = tokenizer.apply_chat_template(
#             messages,
#             tokenize=False,
#             add_generation_prompt=True
#         )

#         inputs = tokenizer(text, return_tensors="pt").to(model.device)

#         with torch.no_grad():
#             output = model.generate(
#                 **inputs,
#                 max_new_tokens=1000,
#                 temperature=0.7 if mode == "chat" else 0.3
#             )

#         # Decode only new tokens
#         return tokenizer.decode(
#             output[0][inputs.input_ids.shape[1]:],
#             skip_special_tokens=True
#         ).strip()

#     try:
#         return await asyncio.wait_for(asyncio.to_thread(run), timeout)
#     except Exception as e:
#         logger.error(f"LLM call failed: {e}")
#         return ""

# ===============================

def calculate_fluency(word_count: int, audio_duration: float) -> dict:
    """calculate fluency metrics"""
    if audio_duration <= 0:
        return {
            "score": 0,
            "wpm": 0,
            "speed_status": "unknown",
            "audio_duration_seconds": round(audio_duration, 1),
            "feedback": "Could not measure speaking speed because audio duration was unavailable."
        }

    wpm = int((word_count / audio_duration) * 60)
    
    if wpm < 80:
        score = max(55, 75 - ((80 - wpm) * 0.5))
        speed_status = "too_slow"
    elif wpm < 110:
        score = 75 + ((wpm - 80) * (20 / 30))
        speed_status = "slow"
    elif wpm <= 160:
        score = 95 + ((wpm - 110) * (5 / 50))
        speed_status = "normal"
    elif wpm <= 180:
        score = 100 - ((wpm - 160) * (5 / 20))
        speed_status = "fast"
    else:
        score = max(70, 95 - ((wpm - 180) * 0.3))
        speed_status = "too_fast"
    
    return {
        "score": int(max(0, min(100, round(score)))),
        "wpm": wpm,
        "speed_status": speed_status,
        "audio_duration_seconds": round(audio_duration, 1),
        "feedback": f"Your speaking speed is {speed_status.replace('_', ' ')} ({wpm} WPM)."
    }


async def analyze_fluency_metrics(user_text: str, audio_duration: float) -> dict:
    """async wrapper for fluency metrics from text and duration"""
    
    word_count = len(re.findall(r"\b\w+\b", user_text or ""))
    return calculate_fluency(word_count, audio_duration)






def call_gpt_sync(prompt: str, system_prompt: str = None, model: str = "gpt") -> str:
    """sync gpt call - will be run in thread pool. Supports gpt (default) or qwen."""
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    else:
        messages.append({"role": "system", "content": "You are a friendly language tutor. Return only valid JSON when asked."})
    messages.append({"role": "user", "content": prompt})
    
    
    if model.lower() == "qwen" and QWEN_ENABLED and qwen_client is not None:
        try:
            response = qwen_client.chat.completions.create(
                model=QWEN_MODEL_NAME,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.warning(f"Qwen call failed, falling back to GPT: {e}")
            
    
    
    response = llm_client.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT,
        messages=messages,
        temperature=0.7,
        max_tokens=1000
    )
    return response.choices[0].message.content.strip()


async def call_llm(prompt: str, system_prompt: str = None, timeout: int = 30, model: str = "gpt") -> str:
    """async llm call with timeout. Supports gpt (default) or qwen."""
    try:
        result = await asyncio.wait_for(
            asyncio.to_thread(call_gpt_sync, prompt, system_prompt, model),
            timeout=timeout
        )
        return result
    except asyncio.TimeoutError as e:
        logger.error(f"llm timeout: {e}")
        raise
    except Exception as e:
        logger.error(f"llm error: {e}")
        raise






def safe_json_loads(text: str) -> dict:
    """extract and parse json from llm response"""
    if not text:
        raise ValueError("empty response")
    
    
    text = text.strip()
    text = text.replace("```json", "").replace("```", "").strip()
    
    
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        return json.loads(match.group())
    
    
    match = re.search(r"\[.*\]", text, re.DOTALL)
    if match:
        return json.loads(match.group())
    
    raise ValueError(f"no json found in: {text[:100]}")


def extract_json_array(text: str) -> list:
    """extract json array from llm response"""
    if not text:
        return []
    
    text = text.strip().replace("```json", "").replace("```", "").strip()
    
    match = re.search(r"\[.*\]", text, re.DOTALL)
    if match:
        return json.loads(match.group())
    
    return []






async def transcribe_audio(audio_path: str, target_lang: str = "en") -> str:
    """transcribe audio using whisper (pre-loaded model)"""
    try:
        # Normalize language code (e.g., "hindi" -> "hi")
        target_lang = target_lang.lower().strip()
        languages_data = load_language_mapping()
        if target_lang in languages_data:
            target_lang = languages_data.get(target_lang, "en")
        
        segments, info = await asyncio.to_thread(_whisper_model.transcribe, audio_path, language=target_lang)
        text = " ".join([seg.text for seg in segments])
        return text.lower().strip()
    except Exception as e:
        logger.error(f"transcription error: {e}")
        return ""


async def transcribe_audio_with_words(audio_path: str, target_lang: str = "en") -> dict:
    """transcribe with word-level timestamps and confidence (pre-loaded model)"""
    try:
        # Normalize language code (e.g., "hindi" -> "hi")
        target_lang = target_lang.lower().strip()
        languages_data = load_language_mapping()
        if target_lang in languages_data:
            target_lang = languages_data.get(target_lang, "en")
        
        segments, info = await asyncio.to_thread(
            _whisper_model.transcribe, 
            audio_path,
            language=target_lang,
            word_timestamps=True
        )
        
        words = []
        full_text = []
        
        for segment in segments:
            full_text.append(segment.text)
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    words.append({
                        "word": word.word.strip(),
                        "start": word.start,
                        "end": word.end,
                        "probability": word.probability
                    })
        
        return {
            "text": " ".join(full_text).lower().strip(),
            "words": words,
            "duration": info.duration if info else 0
        }
    except Exception as e:
        logger.error(f"transcription with words error: {e}")
        return {"text": "", "words": [], "duration": 0}






def pronunciation_score_wer(expected: str, spoken: str) -> int:
    """WER-based pronunciation score for SENTENCES - compares full text match"""
    try:
        error = wer(expected.lower().strip(), spoken.lower().strip())
        return max(0, 100 - int(error * 100))
    except Exception as e:
        logger.error(f"WER scoring error: {e}")
        return 0


def pronunciation_score_word(expected_word: str, transcription: str) -> dict:
    """
    Word-based pronunciation score - STRICT matching.
    Returns 0 for total mismatch, score only if word is detected or very close.
    Note: All return values are native Python types for JSON serialization.
    """
    expected_tokens = re.findall(r"\b[\w']+\b", (expected_word or "").lower().strip())
    spoken_tokens = re.findall(r"\b[\w']+\b", (transcription or "").lower().strip())

    if not expected_tokens or not spoken_tokens:
        return {"score": 0, "detected": False, "match_type": "none"}

    expected_lower = expected_tokens[0]

    # Exact token match only (prevents substring false positives like "he" in "the")
    if expected_lower in spoken_tokens:
        return {"score": 100, "detected": True, "match_type": "exact"}

    # Near match with moderate leniency on full tokens only.
    best_ratio = 0.0
    for spoken_word in spoken_tokens:
        length_ratio = min(len(spoken_word), len(expected_lower)) / max(len(spoken_word), len(expected_lower))
        ratio = SequenceMatcher(None, expected_lower, spoken_word).ratio()
        if length_ratio >= 0.6 and ratio > best_ratio:
            best_ratio = ratio

    if best_ratio >= 0.72:
        partial_score = int(60 + ((best_ratio - 0.72) / 0.28) * 35)
        return {"score": max(60, min(95, partial_score)), "detected": True, "match_type": "partial"}

    return {"score": 0, "detected": False, "match_type": "none"}


async def analyze_word_pronunciation(audio_path: str, expected_word: str, target_lang: str = "en") -> dict:
    """
    Analyze single word pronunciation using Whisper confidence.
    Returns confidence score and syllable guide if needed.
    """
    try:
        
        transcription_data = await transcribe_audio_with_words(audio_path, target_lang)
        
        words = transcription_data.get("words", [])
        full_transcription = transcription_data.get("text", "").strip()
        
        
        word_match = pronunciation_score_word(expected_word, full_transcription)
        
        
        word_confidence = 0.0
        matched_word = None
        expected_tokens = re.findall(r"\b[\w']+\b", (expected_word or "").lower().strip())
        expected_token = expected_tokens[0] if expected_tokens else ""
        best_ratio = 0.0
        best_confidence = 0.0
        best_word = None

        for wd in words:
            raw_word = str(wd.get("word", ""))
            token_match = re.findall(r"\b[\w']+\b", raw_word.lower().strip())
            if not token_match or not expected_token:
                continue
            spoken_token = token_match[0]
            confidence = float(wd.get("probability", 0.0) or 0.0)

            if spoken_token == expected_token:
                word_confidence = confidence
                matched_word = raw_word
                best_ratio = 1.0
                break

            length_ratio = min(len(spoken_token), len(expected_token)) / max(len(spoken_token), len(expected_token))
            ratio = SequenceMatcher(None, expected_token, spoken_token).ratio()
            if length_ratio >= 0.6 and ratio > best_ratio:
                best_ratio = ratio
                best_confidence = confidence
                best_word = raw_word

        if not matched_word and best_ratio >= 0.72:
            word_confidence = best_confidence
            matched_word = best_word
        
        
        confidence_score = int(word_confidence * 100)
        
        
        if word_match["detected"]:
            final_score = max(confidence_score, word_match["score"])
        else:
            final_score = 0  # Wrong word = zero score
        
        return {
            "score": int(final_score),
            "confidence": float(round(word_confidence * 100, 1)),
            "transcription": full_transcription,
            "expected": expected_word,
            "detected": bool(word_match["detected"]),
            "match_type": word_match["match_type"],
            "words_data": words,
            "needs_practice": bool(final_score < PASSING_SCORE or word_confidence < 0.70)
        }
        
    except Exception as e:
        logger.error(f"Word pronunciation analysis error: {e}")
        return {
            "score": 0,
            "confidence": 0,
            "transcription": "",
            "expected": expected_word,
            "detected": False,
            "match_type": "error",
            "words_data": [],
            "needs_practice": True
        }


async def generate_syllable_guide(word: str, model: str = "gpt") -> dict:
    """Generate detailed pronunciation guide with phoneme-level breakdown"""
    prompt = f"""You are an expert pronunciation coach. Provide a DETAILED pronunciation guide for the word: "{word}"

Return STRICTLY valid JSON:
{{
    "word": "{word}",
    "syllables": "break-down with hy-phens (e.g., break-fast)",
    "syllable_count": <number of syllables>,
    "phonetic_ipa": "IPA transcription (e.g., /ËˆbrekfÉ™st/)",
    "phonetic_simple": "simple phonetic guide (e.g., BREK-fuhst)",
    "stress_pattern": "which syllable to stress (e.g., FIRST syllable)",
    
    "phoneme_breakdown": [
        {{
            "syllable": "break",
            "sounds": [
                {{"letter": "b", "sound": "/b/", "how_to_say": "Press lips together, release with voice"}},
                {{"letter": "r", "sound": "/r/", "how_to_say": "Curl tongue back slightly"}},
                {{"letter": "ea", "sound": "/e/", "how_to_say": "Short 'e' as in 'bed'"}},
                {{"letter": "k", "sound": "/k/", "how_to_say": "Back of tongue touches soft palate"}}
            ]
        }},
        {{
            "syllable": "fast",
            "sounds": [
                {{"letter": "f", "sound": "/f/", "how_to_say": "Upper teeth on lower lip, blow air"}},
                {{"letter": "a", "sound": "/É™/", "how_to_say": "Unstressed 'uh' sound"}},
                {{"letter": "st", "sound": "/st/", "how_to_say": "'s' followed by 't'"}}
            ]
        }}
    ],
    
    "mouth_position": "Describe how to position mouth/tongue for key sounds",
    "common_mistakes": ["list", "of", "common", "mistakes"],
    "practice_tip": "One specific tip for practicing this word",
    "similar_words": ["words", "with", "similar", "sounds"]
}}"""
    
    try:
        raw = await call_llm(prompt, timeout=15, model=model)
        data = safe_json_loads(raw)
        
        data.setdefault("word", word)
        data.setdefault("syllables", word)
        data.setdefault("phoneme_breakdown", [])
        return data
    except Exception as e:
        logger.error(f"Syllable guide generation error: {e}")
        return {
            "word": word,
            "syllables": word,
            "syllable_count": 1,
            "phonetic_ipa": f"/{word}/",
            "phonetic_simple": word.upper(),
            "stress_pattern": "first syllable",
            "phoneme_breakdown": [],
            "mouth_position": "Speak slowly and clearly",
            "common_mistakes": [],
            "practice_tip": "Break the word into smaller parts",
            "similar_words": []
        }


async def analyze_sentence_pronunciation(audio_path: str, expected_sentence: str, spoken_text: str, target_lang: str = "en") -> dict:
    """
    Analyze sentence pronunciation using WER and word-level analysis.
    Returns WER score, mismatches, and improvement suggestions.
    """
    try:
        
        transcription_data = await transcribe_audio_with_words(audio_path, target_lang)
        words_data = transcription_data.get("words", [])
        duration = transcription_data.get("duration", 5)
        
        
        wer_score = pronunciation_score_wer(expected_sentence, spoken_text)
        
        
        expected_words = expected_sentence.lower().strip().split()
        spoken_words = spoken_text.lower().strip().split()
        
        mismatches = []
        mispronounced = []
        well_pronounced = []
        
        
        for i, expected_word in enumerate(expected_words):
            if i < len(spoken_words):
                spoken_word = spoken_words[i]
                if expected_word != spoken_word:
                    mismatches.append({
                        "position": i + 1,
                        "expected": expected_word,
                        "spoken": spoken_word,
                        "issue": "word mismatch"
                    })
            else:
                mismatches.append({
                    "position": i + 1,
                    "expected": expected_word,
                    "spoken": "(missing)",
                    "issue": "word missing"
                })
        
        
        if len(spoken_words) > len(expected_words):
            for i in range(len(expected_words), len(spoken_words)):
                mismatches.append({
                    "position": i + 1,
                    "expected": "(none)",
                    "spoken": spoken_words[i],
                    "issue": "extra word"
                })
        
        
        for wd in words_data:
            word = wd.get("word", "").strip().lower()
            confidence = wd.get("probability", 1.0)
            
            if confidence < 0.7:
                mispronounced.append({
                    "word": word,
                    "confidence": round(confidence * 100, 1),
                    "issue": "unclear pronunciation" if confidence < 0.5 else "needs improvement"
                })
            else:
                well_pronounced.append(word)
        
        
        fluency = await analyze_fluency_metrics(spoken_text, duration)
        
        return {
            "score": wer_score,
            "transcription": spoken_text,
            "expected": expected_sentence,
            "mismatches": mismatches,
            "mismatch_count": len(mismatches),
            "mispronounced_words": mispronounced,
            "well_pronounced_words": well_pronounced[:10],
            "fluency": fluency,
            "accuracy_percentage": wer_score
        }
        
    except Exception as e:
        logger.error(f"Sentence pronunciation analysis error: {e}")
        return {
            "score": 0,
            "transcription": spoken_text,
            "expected": expected_sentence,
            "mismatches": [],
            "mismatch_count": 0,
            "mispronounced_words": [],
            "well_pronounced_words": [],
            "fluency": {"wpm": 0, "speed_status": "unknown", "duration": 0},
            "accuracy_percentage": 0
        }






async def translate_text(text: str, source: str, target: str) -> str:
    """translate text between languages - handles full names like 'hindi' to 'hi'"""
    if not text or not isinstance(text, str):
        return text if isinstance(text, str) else ""
    
    # Convert full language names to codes using JSON mapping
    source = source.lower().strip()
    target = target.lower().strip()
    
    languages_data = load_language_mapping()
    if source in languages_data:
        source = languages_data.get(source, source)
    if target in languages_data:
        target = languages_data.get(target, target)

    if source == target:
        return text
        
    try:
        translated = await asyncio.to_thread(
            GoogleTranslator(source=source, target=target).translate,
            text
        )
        return translated
    except Exception as e:
        logger.error(f"translation error: {e}")
        return text







async def generate_lesson_llm(topic: str, num_words: int, target_lang: str, model: str = "gpt") -> list:
    """Generate lesson using LLM for normal mode - creates 3 sentences per word"""
    
    
    lang_names = {
        "hi": "Hindi", "es": "Spanish", "fr": "French", "de": "German",
        "zh": "Chinese", "ja": "Japanese", "ko": "Korean", "ar": "Arabic",
        "pt": "Portuguese", "ru": "Russian", "it": "Italian", "en": "English"
    }
    target_lang_name = lang_names.get(target_lang, target_lang)
    
    prompt = f"""You are a language tutor. Create exactly {num_words} {target_lang_name} vocabulary items for a lesson on '{topic}'.

IMPORTANT RULES:
- The 'word' must be in {target_lang_name}
- 'meaning_en' must be the DEFINITION IN ENGLISH that explains what the word means (example: for "breakfast", meaning_en should be "the first meal of the day, eaten in the morning")
- NEVER use the word itself as meaning_en - always explain what it means!
- 'meaning_{target_lang}' must be the meaning/definition in {target_lang_name}
- All sentences must be in {target_lang_name} with English translations

For EACH word, provide:
- word: the {target_lang_name} vocabulary word
- meaning_en: English definition (NOT the word itself, but a clear explanation of what it means)
- meaning_{target_lang}: meaning/definition in {target_lang_name}
- sentences: array of {SENTENCES_PER_WORD_NORMAL} sentences containing the word

Each sentence must have:
- {target_lang}: {target_lang_name} sentence (MUST contain the word)
- en: English translation

Return ONLY valid JSON array:
[{{"word": "<target word>", "meaning_en": "English meaning", "meaning_{target_lang}": "<target meaning>", "sentences": [{{"{target_lang}": "<target sentence>", "en": "<English translation>"}}]}}]

NO markdown. NO code fences.
"""
    
    try:
        raw = await call_llm(prompt, model=model)
        lesson = extract_json_array(raw)
        
        if not lesson:
            logger.warning("lesson generation returned empty, using fallback")
            return await generate_fallback_lesson(topic, num_words, target_lang)
        
        
        valid_items = []
        
        for item in lesson:
            word = item.get("word", "").lower()
            
            
            if "sentences" not in item or not item["sentences"]:
                
                if "sentence" in item:
                    item["sentences"] = [
                        {"en": item["sentence"], target_lang: item.get(f"sentence_{target_lang}", item["sentence"])}
                    ]
                else:
                    item["sentences"] = []
            
            
            valid_sentences = []
            for sent in item.get("sentences", []):
                if isinstance(sent, str):
                    sent = {"en": sent}
                en_sent = sent.get("en", "")
                target_sent = sent.get(target_lang, "")
                if not target_sent and en_sent:
                    target_sent = en_sent if target_lang == "en" else await translate_text(en_sent, "en", target_lang)
                    sent[target_lang] = target_sent
                if not en_sent and target_sent:
                    en_sent = target_sent if target_lang == "en" else await translate_text(target_sent, target_lang, "en")
                    sent["en"] = en_sent
                if word and target_sent and word in target_sent.lower():
                    valid_sentences.append(sent)
                else:
                    if target_sent:
                        sent[target_lang] = f"{target_sent.rstrip('.')}. {word}"
                    else:
                        sent[target_lang] = word
                    if not sent.get("en"):
                        sent["en"] = f"I use the word {word}."
                    valid_sentences.append(sent)
            
            
            while len(valid_sentences) < SENTENCES_PER_WORD_NORMAL:
                en_fallback = f"I use the word {word} often."
                target_fallback = en_fallback if target_lang == "en" else await translate_text(en_fallback, "en", target_lang)
                valid_sentences.append({
                    "en": en_fallback,
                    target_lang: target_fallback
                })
            
            item["sentences"] = valid_sentences[:SENTENCES_PER_WORD_NORMAL]
            item["meaning_en"] = item.get("meaning_en") or f"a word meaning {word}"
            if not item.get(f"meaning_{target_lang}"):
                if target_lang == "en":
                    item[f"meaning_{target_lang}"] = item["meaning_en"]
                else:
                    item[f"meaning_{target_lang}"] = await translate_text(item["meaning_en"], "en", target_lang)
            
            valid_items.append(item)
        
        return valid_items if valid_items else await generate_fallback_lesson(topic, num_words, target_lang)
        
    except Exception as e:
        logger.error(f"lesson generation error: {e}")
        return await generate_fallback_lesson(topic, num_words, target_lang)


async def generate_fallback_lesson(topic: str, num_words: int, target_lang: str) -> list:
    """Fallback lesson when LLM fails - creates 3 sentences per word"""
    basic_words = ["hello", "good", "learn", "speak", "practice", "today", "happy", "work", "friend", "time"][:num_words]
    lesson = []
    for word in basic_words:
        word_target = word if target_lang == "en" else await translate_text(word, "en", target_lang)
        meaning_en = "a common word"
        meaning_target = meaning_en if target_lang == "en" else await translate_text(meaning_en, "en", target_lang)
        sentence_templates = [
            f"I want to say {word_target}.",
            f"Let me practice {word_target} with you.",
            f"We should use {word_target} together."
        ]
        sentences = []
        for en_sent in sentence_templates:
            target_sent = en_sent if target_lang == "en" else await translate_text(en_sent, "en", target_lang)
            sentences.append({"en": en_sent, target_lang: target_sent})
        lesson.append({
            "word": word_target,
            "meaning_en": meaning_en,
            f"meaning_{target_lang}": meaning_target,
            "sentences": sentences
        })
    return lesson
async def make_bilingual(value, source: str, target: str):
    """Convert value to {target, native} structure"""
    if source == target:
        return value
    if isinstance(value, str):
        if not value.strip():
            return {"target": value, "native": value}
        native = await translate_text(value, source, target)
        return {"target": value, "native": native}
    elif isinstance(value, list):
        return await asyncio.gather(*[make_bilingual(item, source, target) for item in value])
    elif isinstance(value, dict):
        keys = list(value.keys())
        translated_values = await asyncio.gather(*[make_bilingual(value[k], source, target) for k in keys])
        return dict(zip(keys, translated_values))
    return value







async def load_vocab_file(set_number: int = None) -> list:
    """load vocabulary from database, optionally filtered by set"""
    return await db.get_pronunciation_vocab(set_number=set_number)



def sample_vocab(vocab: list, k: int) -> list:
    """randomly sample k words from vocab"""
    if len(vocab) < k:
        return vocab.copy()
    return random.sample(vocab, k)


async def generate_sentences_llm(word: str, target_lang: str, num_sentences: int = 3, model: str = "gpt") -> list:
    """generate sentences for a word using llm"""
    lang_names = {
        "hi": "Hindi", "es": "Spanish", "fr": "French", "de": "German",
        "zh": "Chinese", "ja": "Japanese", "ko": "Korean", "ar": "Arabic",
        "pt": "Portuguese", "ru": "Russian", "it": "Italian", "en": "English"
    }
    target_lang_name = lang_names.get(target_lang, target_lang)
    prompt = f"""
Generate exactly {num_sentences} short spoken {target_lang_name} sentences using the word "{word}".
The {target_lang_name} sentence MUST contain the word exactly.
Provide an English translation for each sentence.

Return ONLY strict JSON in this format:
{{
  "sentences": [
    {{"{target_lang}": "...", "en": "..."}},
    {{"{target_lang}": "...", "en": "..."}},
    {{"{target_lang}": "...", "en": "..."}}
  ]
}}
"""
    
    retries = 2
    for attempt in range(retries + 1):
        try:
            raw = await call_llm(prompt, model=model)
            parsed = safe_json_loads(raw)
            
            if "sentences" in parsed and len(parsed["sentences"]) >= num_sentences:
                return parsed["sentences"][:num_sentences]
            
        except Exception as e:
            logger.error(f"sentence generation error for '{word}' (attempt {attempt+1}): {e}")
    
    
    fallback_en = [
        f"I use the word {word}.",
        f"This is an example with {word}.",
        f"{word} is easy to remember."
    ]
    sentences = []
    for en_sent in fallback_en:
        target_sent = en_sent if target_lang == "en" else await translate_text(en_sent, "en", target_lang)
        sentences.append({"en": en_sent, target_lang: target_sent})
    return sentences


def safe_get_sentence_text(sentence, key: str, fallback: str = "") -> str:
    """Safely get text from a sentence that could be a string or dict.
    This fixes the 'str' object has no attribute 'get' error."""
    if isinstance(sentence, str):
        return sentence
    elif isinstance(sentence, dict):
        return sentence.get(key, "") or sentence.get("en", "") or fallback
    return fallback


async def build_lesson_strict(target_lang: str, num_words: int = DEFAULT_NUM_WORDS, set_number: int = None, model: str = "gpt") -> list:
    """Build lesson from vocab file for strict mode - uses num_words from input, filtered by set if specified"""
    vocab = await load_vocab_file(set_number=set_number)
    
    if not vocab:
        error_msg = f"No vocabulary found in database for set {set_number}." if set_number else "No vocabulary found in database. Please run seed_tables.py first."
        raise HTTPException(status_code=500, detail=error_msg)

    selected = sample_vocab(vocab, num_words)
    
    async def normalize_sentence(s, target_lang):
        """Convert sentence to dict format if it's a string and ensure target translation."""
        if isinstance(s, str):
            target_text = s if target_lang == "en" else await translate_text(s, "en", target_lang)
            return {"en": s, target_lang: target_text}
        elif isinstance(s, dict):
            if target_lang not in s and s.get("en"):
                target_text = s["en"] if target_lang == "en" else await translate_text(s["en"], "en", target_lang)
                s = {**s, target_lang: target_text}
            return s
        return {"en": "", target_lang: ""}
    
    lesson = []
    for item in selected:
        word_source = item["word"]
        word_target = word_source if target_lang == "en" else await translate_text(word_source, "en", target_lang)
        meaning_en = item.get("meaning_en", "")
        meaning_target = item.get(f"meaning_{target_lang}")
        if not meaning_target:
            meaning_target = meaning_en if target_lang == "en" else await translate_text(meaning_en, "en", target_lang)
        
        existing_sentences_raw = item.get("sentences", [])
        
        # Normalize sentences to dict format
        existing_sentences = []
        for s in existing_sentences_raw:
            existing_sentences.append(await normalize_sentence(s, target_lang))
        
        
        if len(existing_sentences) >= SENTENCES_PER_WORD_STRICT:
            sentences = existing_sentences[:SENTENCES_PER_WORD_STRICT]
        elif existing_sentences:
            
            needed = SENTENCES_PER_WORD_STRICT - len(existing_sentences)
            extra = await generate_sentences_llm(word_target, target_lang, needed, model=model)
            sentences = existing_sentences + extra
        else:
            
            sentences = await generate_sentences_llm(word_target, target_lang, SENTENCES_PER_WORD_STRICT, model=model)
        
        lesson.append({
            "word": word_target,
            "meaning_en": meaning_en,
            f"meaning_{target_lang}": meaning_target,
            "sentences": sentences[:SENTENCES_PER_WORD_STRICT]
        })
    
    return lesson




async def analyze_pronunciation_detailed(audio_path: str, expected_text: str, spoken_text: str, level: str = "Intermediate", target_lang: str = "en") -> dict:
    """detailed pronunciation analysis combining wer and word confidence"""
    
    
    transcription_data = await transcribe_audio_with_words(audio_path, target_lang)
    
    
    base_score = pronunciation_score_wer(expected_text, spoken_text)
    
    
    mispronounced = []
    if transcription_data.get("words"):
        for word_data in transcription_data["words"]:
            if word_data.get("probability", 1.0) < 0.7:
                mispronounced.append({
                    "word": word_data["word"],
                    "confidence": round(word_data["probability"] * 100, 1),
                    "suggestion": "speak more clearly"
                })
    
    
    duration = transcription_data.get("duration", 5)
    word_count = len(spoken_text.split())
    wpm = int((word_count / duration) * 60) if duration > 0 else 0
    
    return {
        "score": base_score,
        "mispronounced_words": mispronounced,
        "fluency": {
            "wpm": wpm,
            "speed_status": "slow" if wpm < 100 else "normal" if wpm < 160 else "fast",
            "duration": round(duration, 2)
        },
        "transcription": spoken_text
    }






async def generate_word_feedback(expected: str, spoken: str, score: int, attempt: int, word_analysis: dict = None, model: str = "gpt") -> dict:
    """Generate LLM-based feedback for word practice with specific tips"""
    
    if score >= PASSING_SCORE:
        return {
            "status": "success",
            "message": f"Awesome! ðŸŽ‰ You nailed '{expected}'! That sounded really clear. Now let's try it in a sentence!",
            "next_action": "next_phase"
        }
    elif attempt >= MAX_ATTEMPTS:
        return {
            "status": "max_attempts",
            "message": f"Hey, don't worry! '{expected}' is tricky. You gave it {MAX_ATTEMPTS} good tries - let's move on to sentences and come back to it!",
            "next_action": "next_phase"
        }
    else:
        
        confidence = word_analysis.get("confidence", 0) if word_analysis else 0
        detected = word_analysis.get("detected", False) if word_analysis else False
        
        prompt = f"""You are a super friendly pronunciation buddy (like a supportive friend, NOT a teacher). Give casual, encouraging feedback.

Word to pronounce: "{expected}"
User said: "{spoken}"
Score: {score}%
Word detected: {detected}
Confidence: {confidence}%
Attempt: {attempt} of {MAX_ATTEMPTS}

Generate a response that feels like a friend helping out:
1. START with a warm one-liner reaction (like "Almost there!" or "You're so close!" or "Nice try!")
2. Then 1 sentence of encouragement + ONE specific tip for "{expected}"
3. Mention it's attempt {attempt} of {MAX_ATTEMPTS} naturally

Return JSON: {{"message": "your friendly feedback here", "tip": "quick pronunciation tip"}}"""

        try:
            raw = await call_llm(prompt, timeout=10, model=model)
            data = safe_json_loads(raw)
            message = data.get("message", f"Attempt {attempt}/{MAX_ATTEMPTS}. Try saying '{expected}' more clearly.")
            tip = data.get("tip", "Speak slowly and clearly")
        except:
            message = f"Attempt {attempt}/{MAX_ATTEMPTS}. Focus on pronouncing '{expected}' clearly."
            tip = "Try breaking the word into syllables"
        
        return {
            "status": "retry",
            "message": message,
            "tip": tip,
            "next_action": "retry"
        }


async def generate_sentence_feedback(expected: str, spoken: str, score: int, analysis: dict, model: str = "gpt") -> dict:
    """Generate LLM-based feedback for sentence practice with mismatch details"""
    pron_analysis = analysis.get("pronunciation", {})
    mismatches = pron_analysis.get("mismatches", [])
    mispronounced = pron_analysis.get("mispronounced_words", [])
    fluency = pron_analysis.get("fluency", {})
    wpm = fluency.get("wpm", 0)
    speed_status = fluency.get("speed_status", "normal")
    
    if score >= PASSING_SCORE:
        
        prompt = f"""You are a super friendly pronunciation buddy (like a supportive friend). Give casual, celebratory feedback!

Expected: "{expected}"
User said: "{spoken}"
Score: {score}%
Speaking speed: {wpm} WPM ({speed_status})

Generate a warm, friendly response:
1. START with an excited one-liner ("Nice! ðŸ”¥", "You're on fire!", "That was great!")
2. Then 1 sentence mentioning their good pronunciation
3. Optionally mention their speaking pace

Return JSON: {{"message": "your excited feedback", "fluency_note": "speed observation"}}"""

        try:
            raw = await call_llm(prompt, timeout=10, model=model)
            data = safe_json_loads(raw)
            message = data.get("message", "Great pronunciation! That sounded natural.")
            fluency_note = data.get("fluency_note", f"Your pace was {speed_status}.")
        except:
            message = "That sounded great! Well done."
            fluency_note = f"Speaking speed: {speed_status}"
        
        return {
            "status": "success",
            "message": message,
            "fluency_note": fluency_note,
            "pronunciation_feedback": pron_analysis,
            "next_action": "next_sentence"
        }
    else:
        
        mismatch_info = ", ".join([f"'{m['expected']}' vs '{m['spoken']}'" for m in mismatches[:3]]) if mismatches else "some words unclear"
        low_conf_words = [w["word"] for w in mispronounced[:3]] if mispronounced else []
        
        prompt = f"""You are a super friendly pronunciation buddy (like a supportive friend). Give casual, motivating feedback.

Expected: "{expected}"
User said: "{spoken}"
Score: {score}%
Mismatched words: {mismatch_info}
Low confidence words: {low_conf_words}
Speaking speed: {wpm} WPM ({speed_status})

Generate a response like a friend would:
1. START with a warm one-liner ("You're getting there!", "Almost!", "Good try!")
2. Then 1 sentence focusing on ONE word they should practice
3. Keep it encouraging and casual!

Return JSON: {{"message": "your friendly feedback", "focus_word": "word to practice", "tip": "quick tip"}}"""

        try:
            raw = await call_llm(prompt, timeout=10, model=model)
            data = safe_json_loads(raw)
            message = data.get("message", "Good effort! Focus on speaking more clearly.")
            focus_word = data.get("focus_word", "")
            tip = data.get("tip", "Speak slowly and clearly")
        except:
            message = "Good effort! Try to match the sentence more closely."
            focus_word = mismatches[0]["expected"] if mismatches else ""
            tip = "Focus on each word clearly"
        
        return {
            "status": "needs_improvement",
            "message": message,
            "focus_word": focus_word,
            "tip": tip,
            "pronunciation_feedback": pron_analysis,
            "next_action": "next_sentence"
        }


async def generate_session_summary(session: dict, model: str = "gpt") -> dict:
    """Generate comprehensive end of session summary with per-turn WPM analysis - aligned with interview/fluent APIs"""
    history = session.get("history", [])
    
    total_attempts = len(history)
    successful_attempts = sum(1 for h in history if h.get("score", 0) >= PASSING_SCORE)
    
    avg_score = sum(h.get("score", 0) for h in history) / total_attempts if total_attempts > 0 else 0
    
    
    turn_history = []
    total_wpm = 0
    for i, h in enumerate(history, 1):
        wpm = h.get("wpm", 0)
        total_wpm += wpm
        # Extract word properly - could be string or dict
        word_data = h.get("word", "")
        if isinstance(word_data, dict):
            word_str = word_data.get("target", word_data.get("word", ""))
        else:
            word_str = str(word_data)
        
        turn_history.append({
            "turn": i,
            "word": word_str,
            "score": h.get("score", 0),
            "wpm": wpm,
            "passed": h.get("score", 0) >= PASSING_SCORE
        })
    
    average_wpm = int(total_wpm / total_attempts) if total_attempts > 0 else 0
    wpm_status = "slow" if average_wpm < 100 else "normal" if average_wpm <= 150 else "fast"
    
    
    strengths = []
    improvement_areas = []
    if avg_score >= 80:
        strengths.append("pronunciation accuracy")
    elif avg_score < 60:
        improvement_areas.append("pronunciation accuracy")
    
    if average_wpm >= 100 and average_wpm <= 150:
        strengths.append("speaking pace")
    elif average_wpm < 100:
        improvement_areas.append("speaking pace - try to speak faster")
    elif average_wpm > 150:
        improvement_areas.append("speaking pace - slow down for clarity")
    
    # Helper to extract word string from history item
    def get_word_str(h):
        word_data = h.get("word", "")
        if isinstance(word_data, dict):
            return word_data.get("target", word_data.get("word", ""))
        return str(word_data)
    
    difficult_words = [get_word_str(h) for h in history if h.get("score", 0) < 70][:5]
    well_pronounced = [get_word_str(h) for h in history if h.get("score", 0) >= 85][:5]
    
    
    prompt = f"""You are an expert pronunciation coach providing a detailed session summary.

SESSION DATA:
- Student: {session.get('user_name', 'User')}
- Level: {session.get('level', 'B1')}
- Total Words Practiced: {session.get('total_words', 0)}
- Success Rate: {successful_attempts}/{total_attempts} ({round(successful_attempts/total_attempts*100, 1) if total_attempts > 0 else 0}%)
- Average Score: {round(avg_score, 1)}%
- Average WPM: {average_wpm}

PER-TURN PERFORMANCE:
{json.dumps(turn_history, indent=2)}

DIFFICULT WORDS: {difficult_words}
WELL PRONOUNCED: {well_pronounced}

Generate a detailed, personalized, and encouraging session summary analyzing WPM trends.

Return STRICTLY valid JSON:
{{
    "overall_assessment": "3-4 sentences summarizing their pronunciation practice, mentioning WPM trends",
    "pronunciation_feedback": {{
        "score": {round(avg_score, 1)},
        "status": "Excellent/Good/Needs Work",
        "what_went_well": "specific positive observation",
        "improvement_tip": "specific actionable tip",
        "practice_words": {json.dumps(difficult_words[:3])}
    }},
    "fluency_feedback": {{
        "score": {average_wpm},
        "wpm_status": "{wpm_status}",
        "trend": "analysis of WPM across turns - improving/declining/stable",
        "tip": "specific tip for speaking pace"
    }},
    "action_plan": [
        "specific action item 1",
        "specific action item 2",
        "specific action item 3"
    ],
    "encouragement": "2-3 encouraging sentences personalized for the student",
    "next_practice_words": ["word1", "word2", "word3"]
}}
"""
    
    try:
        raw = await call_llm(prompt, model=model, timeout=20)
        data = safe_json_loads(raw)
        
        return {
            "overall_score": int(avg_score),  
            "total_words": session.get("total_words", 0),
            "average_score": round(avg_score, 1),
            "successful_attempts": successful_attempts,
            "total_attempts": total_attempts,
            "average_wpm": average_wpm,
            "wpm_status": wpm_status,
            "turn_history": turn_history,
            "strengths": strengths,
            "improvement_areas": improvement_areas,
            "difficult_words": difficult_words,
            "well_pronounced": well_pronounced,
            
            "overall_assessment": data.get("overall_assessment", f"Great practice session with {total_attempts} words!"),
            "pronunciation_feedback": data.get("pronunciation_feedback", {"score": round(avg_score, 1), "status": "Good"}),
            "fluency_feedback": data.get("fluency_feedback", {"score": average_wpm, "wpm_status": wpm_status}),
            "action_plan": data.get("action_plan", ["Keep practicing daily"]),
            "encouragement": data.get("encouragement", "Keep up the great work!"),
            "next_practice_words": data.get("next_practice_words", difficult_words[:3])
        }
    except Exception as e:
        logger.error(f"summary generation error: {e}")
        return {
            "overall_score": int(avg_score),  
            "total_words": session.get("total_words", 0),
            "average_score": round(avg_score, 1),
            "successful_attempts": successful_attempts,
            "total_attempts": total_attempts,
            "average_wpm": average_wpm,
            "wpm_status": wpm_status,
            "turn_history": turn_history,
            "strengths": strengths,
            "improvement_areas": improvement_areas,
            "difficult_words": difficult_words,
            "well_pronounced": well_pronounced,
            "overall_assessment": "Great practice session! Keep up the good work.",
            "pronunciation_feedback": {"score": round(avg_score, 1), "status": "Good", "improvement_tip": "Practice difficult words slowly"},
            "fluency_feedback": {"score": average_wpm, "wpm_status": wpm_status, "trend": "stable"},
            "action_plan": ["Practice daily for best results", "Focus on difficult words"],
            "encouragement": "You're making progress! Keep practicing.",
            "next_practice_words": difficult_words[:3]
        }






@router.post("/practice_pronunciation")
async def practice_pronunciation(
    name: str = Form(default="User"),
    level: str = Form(default="B1"),
    mode: str = Form(default="normal"),
    native_language: str = Form(...),  
    target_lang: str = Form(default="en"),  
    topic: str = Form(default="daily life"),
    num_words: int = Form(default=5),
    set_number: int = Form(default=None),  
    audio_file: Optional[UploadFile] = File(default=None),
    session_id: Optional[str] = Form(default=None),
    action: Optional[str] = Form(default=None),
    model: Optional[str] = Form(default="gpt"),
    voice_id: Optional[str] = Form(default=None),
    request: Request = None,
    current_user: User = Depends(get_current_user),
):

    """
    pronunciation practice api - handles word and sentence practice
    
    modes:
    - normal: llm-generated lessons with full analysis
    - strict: vocab file based with 15 words, 3 sentences each
    
    flow:
    1. first call (no audio): creates session, returns first word
    2. with audio: analyzes pronunciation, returns feedback
    3. action="next": skip to next word/sentence
    4. action="end": end session early
    """
    
    try:
        
        if action == "end" and session_id:
            session = await db.get_user_session(session_id)
            if session:
                summary = await generate_session_summary(session, model=model)
                native_lang = session.get("native_language", "en")
                summary_bilingual = await make_bilingual(summary, "en", native_lang)
                msg_en = "Session ended. Great practice!"
                msg_target = msg_en if session.get("target_lang", "en") == "en" else await translate_text(msg_en, "en", session.get("target_lang", "en"))
                msg_native = msg_target if native_lang == session.get("target_lang", "en") else await translate_text(msg_en, "en", native_lang)
                
                # Build response first, then save it
                response = {
                    "status": "complete",
                    "session_id": session_id,
                    "target_lang": session.get("target_lang", "en"),
                    "native_lang": native_lang,
                    "is_session_complete": True,
                    "session_summary": summary_bilingual,
                    "message": {"target": msg_target, "native": msg_native}
                }
                
                await db.complete_session(session_id, final_feedback=summary_bilingual, termination_response=response)
                
                return response
            else:
                
                return {
                    "status": "error",
                    "session_id": session_id,
                    "error": "Session not found or already expired. Cannot end a non-existent session."
                }
        
        
        session = None
        if session_id:
            session = await db.get_user_session(session_id)
        
        
        if session and session.get("status") == "completed":
            return {"status": "error", "session_id": session_id, "error": "This session has ended. Please start a new session."}
        
        if not session:
            session_id = str(uuid.uuid4())
            
            
            if mode == "strict":
                lesson = await build_lesson_strict(target_lang, num_words, set_number=set_number, model=model)
            else:
                lesson = await generate_lesson_llm(topic, num_words, target_lang, model=model)
            
            if not lesson:
                return {
                    "status": "error",
                    "message": "failed to generate lesson. please try again."
                }
            
            
            session = {
                "user_name": name,
                "mode": mode,
                "level": level,
                "native_language": native_language,  
                "target_lang": target_lang,
                "topic": topic,
                "lesson": lesson,
                "current_word_index": 0,
                "current_phase": "word",
                "current_sentence_index": 0,
                "attempt_count": 0,
                "history": [],
                "scores": {"pronunciation": []},
                "total_words": len(lesson),
                "turn_history": []
            }
            await db.create_session(
                session_id=session_id,
                session_type="pronunciation",
                data=session,
                user_id=current_user.id if current_user else None,
                user_name=name
            )
            
            
            first_word = lesson[0]
            
            
            greeting_en = f"Hi {name}! I'm Sara. Let's practice pronunciation together. Relax and speak naturally."
            instruction_en = f"Listen carefully and repeat after me: {first_word['word']}"
            greeting_target = greeting_en if target_lang == "en" else await translate_text(greeting_en, "en", target_lang)
            instruction_target = instruction_en if target_lang == "en" else await translate_text(instruction_en, "en", target_lang)
            greeting_native = greeting_target if native_language == target_lang else await translate_text(greeting_en, "en", native_language)
            instruction_native = instruction_target if native_language == target_lang else await translate_text(instruction_en, "en", native_language)
            
            # Generate TTS audio URLs for greeting
            greeting_audio = ""
            if request:
                greeting_audio = await generate_tts_url(request, greeting_target, target_lang, voice_id=voice_id)
            word_audio =""
            if request:
                word_audio = await generate_tts_url(request, first_word["word"], target_lang, voice_id=voice_id)
            meaning_target = first_word.get(f"meaning_{target_lang}", first_word.get("meaning_en", ""))
            meaning_native = first_word.get(f"meaning_{native_language}", "")
            if not meaning_native:
                source_lang = target_lang if first_word.get(f"meaning_{target_lang}") else "en"
                meaning_native = await translate_text(meaning_target, source_lang, native_language)
            
            return {
                "status": "new_session",
                "session_id": session_id,
                "target_lang": target_lang,
                "native_lang": native_language,
                "mode": mode,
                "greeting": {"target": greeting_target, "native": greeting_native, "audio_url": greeting_audio},
                "current_word": {
                    "word": first_word["word"],
                    "word_url":word_audio,
                    "word_native": first_word["word"] if native_language == target_lang else await translate_text(first_word["word"], "auto", native_language),
                     "meaning": {
                        "target": meaning_target,
                        "native": meaning_native
                    },
                    "instruction": {"target": instruction_target, "native": instruction_native}
                },
                "phase": "word",
                "attempt_number": 1,
                "max_attempts": MAX_ATTEMPTS,
                "progress": {
                    "current_word_index": 1,
                    "total_words": len(lesson),
                    "completed_words": []
                }
            }
        
        
        lesson = session["lesson"]
        current_idx = session["current_word_index"]
        current_phase = session["current_phase"]
        current_word = lesson[current_idx]
        
        
        
        native_lang = session.get("native_language", "en")
        
        if action == "next":
            
            session_mode = session.get("mode", "normal")
            
            if current_phase == "word":
                
                session["current_phase"] = "sentence"
                session["current_sentence_index"] = 0
                session["attempt_count"] = 0
                
                instruction_en = "Now practice this sentence."
                instruction_target = instruction_en if target_lang == "en" else await translate_text(instruction_en, "en", target_lang)
                instruction_native = instruction_target if native_lang == target_lang else await translate_text(instruction_en, "en", native_lang)
                
                
                if "sentences" in current_word and current_word["sentences"]:
                    sentence = current_word["sentences"][0]
                    sentence_target = safe_get_sentence_text(sentence, target_lang)
                    source_lang = target_lang if isinstance(sentence, dict) and sentence.get(target_lang) else "en"
                    sentence_native = safe_get_sentence_text(sentence, native_lang) or await translate_text(sentence_target, source_lang, native_lang)
                    audio_urll = ""
                    if request:
                        audio_urll = await generate_tts_url(request, sentence_target, target_lang, voice_id=voice_id)
                    
                    await db.update_session(session_id, session)
                    
                    return {
                        "status": "next_phase",
                        "session_id": session_id,
                        "target_lang": session.get("target_lang", "en"),
                        "native_lang": native_lang,
                        "current_word": {"word": current_word["word"]},
                        "current_sentence": {
                            "text": {"target": sentence_target, "native": sentence_native,"audio_url": audio_urll}
                        },
                        "phase": "sentence",
                        "sentence_number": 1,
                        "total_sentences": len(current_word["sentences"]),
                        "instruction": {"target": instruction_target, "native": instruction_native},
                        "progress": {
                            "current_word_index": current_idx + 1,
                            "total_words": len(lesson)
                        }
                    }
                else:
                    
                    sentence_en = current_word.get("sentence", f"Practice saying {current_word['word']}.")
                    sentence_target = sentence_en if target_lang == "en" else await translate_text(sentence_en, "en", target_lang)
                    sentence_native = await translate_text(sentence_target, target_lang if target_lang != "en" else "en", native_lang)
                    audio_url=""
                    if request:
                        audio_url = await generate_tts_url(request, sentence_target, target_lang, voice_id=voice_id)
                    
                    await db.update_session(session_id, session)
                    
                    return {
                        "status": "next_phase",
                        "session_id": session_id,
                        "target_lang": session.get("target_lang", "en"),
                        "native_lang": native_lang,
                        "current_word": {"word": current_word["word"]},
                        "current_sentence": {
                            "text": {"target": sentence_target, "native": sentence_native,"audio_url": audio_url}
                        },
                        "phase": "sentence",
                        "sentence_number": 1,
                        "total_sentences": 1,
                        "instruction": {"target": instruction_target, "native": instruction_native},
                        "progress": {
                            "current_word_index": current_idx + 1,
                            "total_words": len(lesson)
                        }
                    }
            else:
                
                sentence_idx = session.get("current_sentence_index", 0)
                
                
                if "sentences" in current_word and sentence_idx + 1 < len(current_word["sentences"]):
                    
                    session["current_sentence_index"] = sentence_idx + 1
                    next_sentence = current_word["sentences"][session["current_sentence_index"]]
                    next_sentence_target = safe_get_sentence_text(next_sentence, target_lang)
                    source_lang = target_lang if isinstance(next_sentence, dict) and next_sentence.get(target_lang) else "en"
                    sentence_native = safe_get_sentence_text(next_sentence, native_lang) or await translate_text(next_sentence_target, source_lang, native_lang)
                    next_sentence_audio = ""
                    if request:
                        next_sentence_audio = await generate_tts_url(request, next_sentence_target, target_lang, voice_id=voice_id)
                    
                    
                    await db.update_session(session_id, session)
                    
                    return {
                        "status": "next_sentence",
                        "session_id": session_id,
                        "target_lang": session.get("target_lang", "en"),
                        "native_lang": native_lang,
                        "current_word": {"word": current_word["word"]},
                        "current_sentence": {
                            "text": {"target": next_sentence_target, "native": sentence_native, "audio_url": next_sentence_audio}
                        },
                        "phase": "sentence",
                        "sentence_number": session["current_sentence_index"] + 1,
                        "total_sentences": len(current_word["sentences"]),
                        "progress": {
                            "current_word_index": current_idx + 1,
                            "total_words": len(lesson)
                        }
                    }
                
                
                session["current_word_index"] += 1
                session["current_phase"] = "word"
                session["current_sentence_index"] = 0
                session["attempt_count"] = 0
                
                if session["current_word_index"] >= len(lesson):
                    
                    summary = await generate_session_summary(session)
                    
                    summary_bilingual = await make_bilingual(summary, "en", native_lang)
                    msg_en = "Excellent work! You've completed all words."
                    msg_native = await translate_text(msg_en, "en", native_lang)
                    complete_audio = ""
                    if request:
                        complete_audio = await generate_tts_url(request, msg_en, session.get("target_lang", "en"), voice_id=voice_id)
                    
                    # Build response first, then save it
                    response = {
                        "status": "complete",
                        "session_id": session_id,
                        "target_lang": session.get("target_lang", "en"),
                        "native_lang": native_lang,
                        "is_session_complete": True,
                        "session_summary": summary_bilingual,
                        "message": {"target": msg_en, "native": msg_native, "audio_url": complete_audio}
                    }
                    
                    await db.complete_session(session_id, final_feedback=summary_bilingual, termination_response=response)
                    
                    return response
                
                next_word = lesson[session["current_word_index"]]
                instruction_en = f"Next word: {next_word['word']}"
                instruction_target = instruction_en if target_lang == "en" else await translate_text(instruction_en, "en", target_lang)
                instruction_native = instruction_target if native_lang == target_lang else await translate_text(instruction_en, "en", native_lang)
                
                
                meaning_target = next_word.get(f"meaning_{target_lang}", next_word.get("meaning_en", ""))
                meaning_native = next_word.get(f"meaning_{native_lang}", "")
                if not meaning_native:
                    source_lang = target_lang if next_word.get(f"meaning_{target_lang}") else "en"
                    meaning_native = await translate_text(meaning_target, source_lang, native_lang)
                
                word_url =""
                if request:
                    word_url = await generate_tts_url(request, next_word["word"], target_lang, voice_id=voice_id)
                await db.update_session(session_id, session)
                
                return {
                    "status": "next_word",
                    "session_id": session_id,
                    "target_lang": session.get("target_lang", "en"),
                    "native_lang": native_lang,
                    "current_word": {
                        "word": next_word["word"],
                        "word_url":word_url,
                        "audio_url": word_url,
                        "meaning": {
                            "target": meaning_target,
                            "native": meaning_native
                        },
                        "instruction": {"target": instruction_target, "native": instruction_native}
                    },
                    "phase": "word",
                    "attempt_number": 1,
                    "max_attempts": MAX_ATTEMPTS,
                    "progress": {
                        "current_word_index": session["current_word_index"] + 1,
                        "total_words": len(lesson)
                    }
                }
        
        
        if not audio_file:
            msg_en = "please provide audio to continue"
            msg_native = await translate_text(msg_en, "en", native_lang)
            waiting_audio = ""
            if request:
                waiting_audio = await generate_tts_url(request, msg_en, session.get("target_lang", "en"), voice_id=voice_id)
            return {
                "status": "waiting_audio",
                "session_id": session_id,
                "target_lang": session.get("target_lang", "en"),
                "native_lang": native_lang,
                "message": {"target": msg_en, "native": msg_native, "audio_url": waiting_audio},
                "current_word": {"word": current_word["word"]},
                "phase": current_phase
            }
        
        temp_dir = tempfile.mkdtemp()
        audio_path = os.path.join(temp_dir, f"audio_{session_id}.wav")
        
        try:
            
            content = await audio_file.read()
            original_filename = audio_file.filename or "audio.wav"
            original_ext = os.path.splitext(original_filename)[1].lower()
            temp_input_path = os.path.join(temp_dir, f"input_{session_id}{original_ext or '.wav'}")
            
            with open(temp_input_path, "wb") as f:
                f.write(content)
            
            
            if original_ext in ['.mp3', '.m4a', '.ogg', '.flac', '.aac', '.webm']:
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_file(temp_input_path)
                    audio.export(audio_path, format="wav")
                except Exception as conv_err:
                    logger.warning(f"Audio conversion failed, using original: {conv_err}")
                    shutil.copy(temp_input_path, audio_path)
            else:
                
                shutil.copy(temp_input_path, audio_path)
            
            
            target_lang_for_audio = session.get("target_lang", "en")
            transcription = await transcribe_audio(audio_path, target_lang_for_audio)
            
            if not transcription:
                
                shutil.rmtree(temp_dir, ignore_errors=True)
                return {
                    "status": "transcription_failed",
                    "session_id": session_id,
                    "message": "could not understand audio. please try again.",
                    "phase": current_phase
                }

            
            
            if current_phase == "word":
                expected = current_word["word"]
                
                
                word_analysis = await analyze_word_pronunciation(audio_path, expected, target_lang_for_audio)
                score = word_analysis["score"]
                transcription = word_analysis["transcription"] or transcription
                
                
                try:
                    from pydub import AudioSegment
                    audio_for_wpm = AudioSegment.from_file(audio_path)
                    audio_duration_seconds = len(audio_for_wpm) / 1000
                    word_count = len(transcription.split()) if transcription else 1
                    word_wpm = int((word_count / audio_duration_seconds) * 60) if audio_duration_seconds > 0 else 120
                except:
                    word_wpm = 120  
                
                # Calculate speed_status for word
                if word_wpm < 100:
                    word_speed_status = "slow"
                elif word_wpm <= 150:
                    word_speed_status = "normal"
                else:
                    word_speed_status = "fast"
                
                session["attempt_count"] += 1
                
                feedback = await generate_word_feedback(expected, transcription, score, session["attempt_count"], word_analysis, model=model)
                
                session["history"].append({
                    "phase": "word",
                    "word": {  
                        "target": current_word["word"],
                        "meaning_en": current_word.get("meaning_en", ""),
                        "meaning_native": current_word.get(f"meaning_{session.get('native_language', 'hi')}", current_word.get("meaning_native", ""))
                    },
                    "expected": expected,
                    "spoken": transcription,
                    "score": score,
                    "attempt": session["attempt_count"],
                    "confidence": word_analysis.get("confidence", 0),
                    "wpm": word_wpm,
                    "speed_status": word_speed_status,
                    "pronunciation_analysis": word_analysis,
                    # Store feedback text for /feedback endpoint
                    "feedback_message": feedback.get("message", ""),
                    "feedback_tip": feedback.get("tip", ""),
                    "feedback_status": feedback.get("status", "")
                })
                session["scores"]["pronunciation"].append(score)
                
                syllable_guide = None
                if word_analysis.get("needs_practice"):
                    
                    syllable_cache = session.get("syllable_cache", {})
                    if expected.lower() in syllable_cache:
                        syllable_guide = syllable_cache[expected.lower()]
                    else:
                        syllable_guide = await generate_syllable_guide(expected, model=model)
                        
                        if "syllable_cache" not in session:
                            session["syllable_cache"] = {}
                        session["syllable_cache"][expected.lower()] = syllable_guide
                
                
                current_attempt = session["attempt_count"]
                
                
                if feedback["next_action"] == "next_phase":
                    session["current_phase"] = "sentence"
                    session["current_sentence_index"] = 0
                    session["attempt_count"] = 0
                
                shutil.rmtree(temp_dir, ignore_errors=True)
                
                
                await db.update_session(session_id, session)
                
                
                feedback_target = feedback["message"] if target_lang_for_audio == "en" else await translate_text(feedback["message"], "en", target_lang_for_audio)
                feedback_native = feedback_target if native_lang == target_lang_for_audio else await translate_text(feedback["message"], "en", native_lang)
                
                # Generate TTS audio URL for feedback
                feedback_audio = ""
                if request:
                    feedback_audio = await generate_tts_url(request, feedback_target, session.get("target_lang", "en"), voice_id=voice_id)
                
                response = {
                    "status": feedback["status"],
                    "session_id": session_id,
                    "target_lang": session.get("target_lang", "en"),
                    "native_lang": native_lang,
                    "transcription": transcription,
                    "pronunciation_score": score,
                    "feedback": {"target": feedback_target, "native": feedback_native, "audio_url": feedback_audio},
                    "current_word": {"word": current_word["word"]},
                    "phase": "word" if feedback["next_action"] == "retry" else "sentence",
                    "attempt_number": current_attempt,
                    "max_attempts": MAX_ATTEMPTS,
                    "next_action": feedback["next_action"],
                    "progress": {
                        "current_word_index": current_idx + 1,
                        "total_words": len(lesson)
                    },
                    
                    "analysis": {
                        "pronunciation": {
                            "score": score,
                            "confidence": word_analysis.get("confidence", 0),
                            "expected": expected,
                            "spoken": transcription,
                            "detected": word_analysis.get("detected", False),
                            "match_type": word_analysis.get("match_type", "unknown")
                        }
                    }
                }
                
                
                if syllable_guide:
                    response["syllable_guide"] = syllable_guide
                
                
                if feedback["next_action"] == "next_phase":
                    
                    if "sentences" in current_word and current_word["sentences"]:
                        sentence = current_word["sentences"][0]
                        sentence_target = safe_get_sentence_text(sentence, target_lang)
                        source_lang = target_lang if isinstance(sentence, dict) and sentence.get(target_lang) else "en"
                        sentence_native = safe_get_sentence_text(sentence, native_lang) or await translate_text(sentence_target, source_lang, native_lang)
                        response["current_sentence"] = {
                            "text": {"target": sentence_target, "native": sentence_native}
                        }
                        response["sentence_number"] = 1
                        response["total_sentences"] = len(current_word["sentences"])
                    else:
                        
                        sentence_en = current_word.get("sentence", "")
                        sentence_target = sentence_en if target_lang == "en" else await translate_text(sentence_en, "en", target_lang) if sentence_en else ""
                        sentence_native = current_word.get(f"sentence_{native_lang}", "") or await translate_text(sentence_target, target_lang if target_lang != "en" else "en", native_lang) if sentence_target else ""
                        response["current_sentence"] = {
                            "text": {"target": sentence_target, "native": sentence_native},
                            "example": current_word.get("example", "")
                        }
                        response["sentence_number"] = 1
                        response["total_sentences"] = 1
                
                return response
            
            
            else:
                
                sentence_idx = session.get("current_sentence_index", 0)
                if "sentences" in current_word and current_word["sentences"]:
                    sentences = current_word["sentences"]
                    current_sentence = sentences[sentence_idx]
                    expected = safe_get_sentence_text(current_sentence, target_lang)
                else:
                    
                    expected = current_word.get("sentence", "")
                
                
                sentence_analysis = await analyze_sentence_pronunciation(audio_path, expected, transcription, target_lang_for_audio)
                score = sentence_analysis["score"]
                
                analysis = {
                    "pronunciation": {
                        "score": score,
                        "expected": expected,
                        "spoken": transcription,
                        "mismatches": sentence_analysis.get("mismatches", []),
                        "mismatch_count": sentence_analysis.get("mismatch_count", 0),
                        "mispronounced_words": sentence_analysis.get("mispronounced_words", []),
                        "well_pronounced_words": sentence_analysis.get("well_pronounced_words", []),
                        "fluency": sentence_analysis.get("fluency", {}),
                        "accuracy_percentage": sentence_analysis.get("accuracy_percentage", 0)
                    }
                }
                
                # Get speed_status from fluency analysis
                sentence_speed_status = sentence_analysis.get("fluency", {}).get("speed_status", "normal")
                
                feedback = await generate_sentence_feedback(expected, transcription, score, analysis, model=model)
                
                session["history"].append({
                    "phase": "sentence",
                    "word": {  
                        "target": current_word["word"],
                        "meaning_en": current_word.get("meaning_en", ""),
                        "meaning_native": current_word.get(f"meaning_{session.get('native_language', 'hi')}", current_word.get("meaning_native", ""))
                    },
                    "expected": expected,
                    "spoken": transcription,
                    "score": score,
                    "mismatches": sentence_analysis.get("mismatches", []),
                    "wpm": sentence_analysis.get("fluency", {}).get("wpm", 120),
                    "speed_status": sentence_speed_status,
                    "pronunciation_analysis": sentence_analysis,
                    # Store feedback text for /feedback endpointttttt
                    "feedback_message": feedback.get("message", ""),
                    "feedback_tip": feedback.get("tip", ""),
                    "feedback_status": feedback.get("status", ""),
                    "focus_word": feedback.get("focus_word", ""),
                    "fluency_note": feedback.get("fluency_note", "")
                })
                session["scores"]["pronunciation"].append(score)
                
                shutil.rmtree(temp_dir, ignore_errors=True)
                
                
                next_action = "next_word"
                is_complete = False
                
                
                if "sentences" in current_word and current_word["sentences"]:
                    sentence_idx = session.get("current_sentence_index", 0)
                    if sentence_idx + 1 < len(current_word["sentences"]):
                        session["current_sentence_index"] = sentence_idx + 1
                        next_action = "next_sentence"
                    else:
                        
                        session["current_word_index"] += 1
                        session["current_phase"] = "word"
                        session["current_sentence_index"] = 0
                        session["attempt_count"] = 0
                        
                        if session["current_word_index"] >= len(lesson):
                            is_complete = True
                            next_action = "complete"
                else:
                    
                    session["current_word_index"] += 1
                    session["current_phase"] = "word"
                    session["attempt_count"] = 0
                    
                    if session["current_word_index"] >= len(lesson):
                        is_complete = True
                        next_action = "complete"
                
                
                feedback_target = feedback["message"] if target_lang_for_audio == "en" else await translate_text(feedback["message"], "en", target_lang_for_audio)
                feedback_native = feedback_target if native_lang == target_lang_for_audio else await translate_text(feedback["message"], "en", native_lang)
                
                # Generate TTS audio URL for feedback
                feedback_audio = ""
                if request:
                    feedback_audio = await generate_tts_url(request, feedback_target, session.get("target_lang", "en"), voice_id=voice_id)
                
                response_status = "complete" if is_complete else feedback["status"]
                
                response = {
                    "status": response_status,
                    "session_id": session_id,
                    "target_lang": session.get("target_lang", "en"),
                    "native_lang": native_lang,
                    "transcription": transcription,
                    "pronunciation_score": score,
                    "feedback": {"target": feedback_target, "native": feedback_native, "audio_url": feedback_audio},
                    "analysis": analysis,
                    "current_word": {"word": current_word["word"]},
                    "phase": "sentence",
                    "next_action": next_action,
                    "is_session_complete": is_complete,
                    "progress": {
                        "current_word_index": session["current_word_index"] + 1 if not is_complete else len(lesson),
                        "total_words": len(lesson)
                    }
                }
                
                
                if is_complete:
                    summary = await generate_session_summary(session, model=model)
                    
                    summary_bilingual = await make_bilingual(summary, "en", native_lang)
                    msg_en = "Excellent work! You've completed the session."
                    msg_target = msg_en if session.get("target_lang", "en") == "en" else await translate_text(msg_en, "en", session.get("target_lang", "en"))
                    msg_native = msg_target if native_lang == session.get("target_lang", "en") else await translate_text(msg_en, "en", native_lang)
                    complete_audio = ""
                    if request:
                        complete_audio = await generate_tts_url(request, msg_target, session.get("target_lang", "en"), voice_id=voice_id)
                    
                    response = {
                        "status": "complete",
                        "session_id": session_id,
                        "target_lang": session.get("target_lang", "en"),
                        "native_lang": native_lang,
                        "is_session_complete": True,
                        "session_summary": summary_bilingual,
                        "message": {"target": msg_target, "native": msg_native, "audio_url": complete_audio}
                    }
                    
                    await db.complete_session(session_id, final_feedback=summary_bilingual, termination_response=response)
                    return response
                    
                elif next_action == "next_sentence" and "sentences" in current_word:
                    next_sentence = current_word["sentences"][session["current_sentence_index"]]
                    next_sentence_target = safe_get_sentence_text(next_sentence, target_lang)
                    source_lang = target_lang if isinstance(next_sentence, dict) and next_sentence.get(target_lang) else "en"
                    sentence_native = safe_get_sentence_text(next_sentence, native_lang) or await translate_text(next_sentence_target, source_lang, native_lang)
                    response["current_sentence"] = {
                        "text": {"target": next_sentence_target, "native": sentence_native}
                    }
                    response["sentence_number"] = session["current_sentence_index"] + 1
                    response["total_sentences"] = len(current_word["sentences"])
                elif next_action == "next_word" and session["current_word_index"] < len(lesson):
                    next_word = lesson[session["current_word_index"]]
                    
                    meaning_target = next_word.get(f"meaning_{target_lang}", next_word.get("meaning_en", ""))
                    meaning_native = next_word.get(f"meaning_{native_lang}", "")
                    if not meaning_native:
                        source_lang = target_lang if next_word.get(f"meaning_{target_lang}") else "en"
                        meaning_native = await translate_text(meaning_target, source_lang, native_lang)
                    response["next_word"] = {
                        "word": next_word["word"],
                        "meaning": {
                            "target": meaning_target,
                            "native": meaning_native
                        }
                    }
                
                
                await db.update_session(session_id, session)
                
                return response
        
        except Exception as e:
            shutil.rmtree(temp_dir, ignore_errors=True)
            raise e
    
    except Exception as e:
        logger.error(f"pronunciation api error: {e}")
        return {
            "status": "error",
            "message": f"an error occurred: {str(e)}"
        }









@router.get("/pronunciation_session/{session_id}")
async def get_pronunciation_session(session_id: str):
    """get pronunciation session data from database"""
    session_data = await db.get_user_session(session_id)
    if session_data:
        return {"status": "success", "session_id": session_id, "data": session_data}
    return {"status": "not_found", "session_id": session_id}




@router.get("/pronunciation_vocab")
async def get_pronunciation_vocab():
    """Get all pronunciation vocabulary from database"""
    async with async_session() as sess:
        result = await sess.execute(
            text("SELECT id, word, meaning_en, sentences, set_number, created_at FROM pronunciation_vocab ORDER BY id")
        )
        rows = result.fetchall()
        vocab_list = []
        for row in rows:
            vocab_list.append({
                "id": row[0],
                "word": row[1],
                "meaning_en": row[2],
                "sentences": row[3] if isinstance(row[3], list) else json.loads(row[3]) if row[3] else [],
                "set_number": row[4],
                "created_at": str(row[5]) if row[5] else None
            })
        return {
            "status": "success",
            "total": len(vocab_list),
            "vocabulary": vocab_list
        }


@router.post("/pronunciation_vocab/upload")
async def upload_pronunciation_vocab(
    file: UploadFile = File(...),
    replace_all: bool = Form(default=False),
    default_set_number: int = Form(default=None)  
):
    """
    Upload pronunciation vocabulary from Excel file.
    
    Excel format (with optional set_number column):
    | set_number | word | meaning_en | sentence_1 | sentence_2 | sentence_3 |
    
    Or:
    | word | meaning_en | sentences (comma-separated) |
    
    If set_number column not in Excel, uses default_set_number param.
    """
    import pandas as pd
    import io
    
    
    content = await file.read()
    
    try:
        
        if file.filename.endswith('.xlsx') or file.filename.endswith('.xls'):
            df = pd.read_excel(io.BytesIO(content))
        elif file.filename.endswith('.csv'):
            df = pd.read_csv(io.BytesIO(content))
        else:
            return {"status": "error", "message": "Unsupported file format. Use .xlsx, .xls, or .csv"}
        
        
        required_cols = ['word', 'meaning_en']
        if not all(col in df.columns for col in required_cols):
            return {"status": "error", "message": f"Missing required columns: {required_cols}"}
        
        
        vocab_items = []
        for _, row in df.iterrows():
            word = str(row['word']).strip()
            meaning_en = str(row['meaning_en']).strip()
            
            
            sentences = []
            
            
            for col in df.columns:
                if col.startswith('sentence_') and pd.notna(row.get(col)):
                    sentences.append(str(row[col]).strip())
            
            
            if not sentences and 'sentences' in df.columns and pd.notna(row.get('sentences')):
                sentences_str = str(row['sentences'])
                sentences = [s.strip() for s in sentences_str.split(',') if s.strip()]
            
            
            if not sentences:
                sentences = [f"I use the word {word} every day."]
            
            
            row_set_number = None
            if 'set_number' in df.columns and pd.notna(row.get('set_number')):
                row_set_number = int(row['set_number'])
            elif default_set_number is not None:
                row_set_number = default_set_number
            
            vocab_items.append({
                "word": word,
                "meaning_en": meaning_en,
                "sentences": sentences,
                "set_number": row_set_number
            })
        
        
        async with async_session() as sess:
            
            if replace_all:
                await sess.execute(text("DELETE FROM pronunciation_vocab"))
            
            inserted = 0
            skipped = 0
            
            for item in vocab_items:
                try:
                    await sess.execute(
                        text("INSERT INTO pronunciation_vocab (word, meaning_en, sentences, set_number, created_at) VALUES (:word, :meaning_en, cast(:sentences as jsonb), :set_number, NOW()) ON CONFLICT (word) DO UPDATE SET meaning_en = :meaning_en, sentences = cast(:sentences as jsonb), set_number = :set_number"),
                        {"word": item["word"], "meaning_en": item["meaning_en"], "sentences": json.dumps(item["sentences"]), "set_number": item.get("set_number")}
                    )
                    inserted += 1
                except Exception as e:
                    logger.error(f"Error inserting {item['word']}: {e}")
                    skipped += 1
            
            await sess.commit()
        
        return {
            "status": "success",
            "message": f"Uploaded vocabulary successfully",
            "inserted": inserted,
            "skipped": skipped,
            "total_in_file": len(vocab_items)
        }
        
    except Exception as e:
        logger.error(f"Upload error: {e}")
        return {"status": "error", "message": str(e)}


@router.get("/completed_sessions")
async def get_completed_pronunciation_sessions(current_user: User = Depends(get_current_user)):
    """
    Get only completed pronunciation sessions for the current user.
    Returns sessions where status='completed' and termination_response exists.
    """
    user_id = current_user.id if current_user else None
    sessions = await db.get_sessions_by_user_id(user_id, session_type="pronunciation")
    
    session_ids = []
    for s in sessions:
        session_data = await db.get_user_session(s.get("session_id"))
        if not session_data:
            continue
        if session_data.get("status") != "completed":
            continue
        if not session_data.get("termination_response"):
            continue
        
        session_ids.append(s.get("session_id"))
    
    return {
        "user_id": user_id,
        "total_sessions": len(session_ids),
        "sessions_ids": session_ids
    }


@router.get("/feedback/{session_id}")
async def get_pronunciation_feedback(session_id: str):
    """
    Get detailed per-turn feedback for a pronunciation session.
    
    Returns the same response that was returned when the session ended.
    Falls back to structured per-turn feedback if termination_response not available.
    """
    # First try to get the stored termination response
    session_data = await db.get_user_session(session_id)
    if not session_data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # Return the stored termination response if available (same as session end response)
    if "termination_response" in session_data:
        return session_data["termination_response"]
    
    # Fall back to get_session_feedback for older sessions without termination_response
    feedback = await db.get_session_feedback(session_id)
    if not feedback:
        raise HTTPException(status_code=404, detail="Session not found")
    if feedback["session_type"] != "pronunciation":
        raise HTTPException(status_code=400, detail="Not a pronunciation session")
    return feedback


async def init_pronunciation_tables():
    """
    Create/sync pronunciation tables - call at app startup.
    Adds missing columns to existing tables.
    """
    async with async_session() as sess:
        # Create pronunciation_vocab table if not exists
        await sess.execute(text("""
            CREATE TABLE IF NOT EXISTS pronunciation_vocab (
                id SERIAL PRIMARY KEY,
                word VARCHAR(255) UNIQUE NOT NULL,
                meaning_en TEXT,
                sentences JSONB,
                set_number INTEGER,
                created_at TIMESTAMP DEFAULT NOW()
            )
        """))
        
        # Add missing columns to pronunciation_vocab (safe - ignores if exists)
        migration_queries = [
            "ALTER TABLE pronunciation_vocab ADD COLUMN IF NOT EXISTS meaning_en TEXT",
            "ALTER TABLE pronunciation_vocab ADD COLUMN IF NOT EXISTS sentences JSONB",
            "ALTER TABLE pronunciation_vocab ADD COLUMN IF NOT EXISTS set_number INTEGER",
            "ALTER TABLE pronunciation_vocab ADD COLUMN IF NOT EXISTS created_at TIMESTAMP DEFAULT NOW()",
        ]
        for query in migration_queries:
            try:
                await sess.execute(text(query))
            except Exception as e:
                logger.debug(f"Migration note: {e}")
        
        await sess.commit()
    logger.info("pronunciation_vocab table ready")


async def init_bookmarks_table():
    """Create/sync user_bookmarks table - call at app startup"""
    async with async_session() as sess:
        await sess.execute(text("""
            CREATE TABLE IF NOT EXISTS user_bookmarks (
                id SERIAL PRIMARY KEY,
                user_id INTEGER NOT NULL,
                word VARCHAR(255) NOT NULL,
                meaning_target TEXT,
                meaning_native TEXT,
                target_lang VARCHAR(10) DEFAULT 'en',
                native_lang VARCHAR(10) DEFAULT 'hi',
                created_at TIMESTAMP DEFAULT NOW(),
                UNIQUE(user_id, word)
            )
        """))
        
        # Add missing columns (safe - ignores if exists)
        migration_queries = [
            "ALTER TABLE user_bookmarks ADD COLUMN IF NOT EXISTS meaning_target TEXT",
            "ALTER TABLE user_bookmarks ADD COLUMN IF NOT EXISTS meaning_native TEXT",
            "ALTER TABLE user_bookmarks ADD COLUMN IF NOT EXISTS target_lang VARCHAR(10) DEFAULT 'en'",
            "ALTER TABLE user_bookmarks ADD COLUMN IF NOT EXISTS native_lang VARCHAR(10) DEFAULT 'hi'",
            "ALTER TABLE user_bookmarks ADD COLUMN IF NOT EXISTS created_at TIMESTAMP DEFAULT NOW()",
        ]
        for query in migration_queries:
            try:
                await sess.execute(text(query))
            except Exception as e:
                logger.debug(f"Migration note: {e}")
        
        await sess.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_bookmarks_user_lang ON user_bookmarks(user_id, native_lang)
        """))
        await sess.commit()
    logger.info("user_bookmarks table ready")


async def init_all_pronunciation_tables():
    """Initialize all pronunciation-related tables - call this at app startup"""
    await init_pronunciation_tables()
    await init_bookmarks_table()
    logger.info("All pronunciation tables initialized")

@router.post("/bookmark")
async def add_bookmark(
    word: str = Form(...),
    meaning_target: str = Form(default=""),  
    meaning_native: str = Form(default=""),  
    target_lang: str = Form(default="en"),
    native_lang: str = Form(default="hi"),
    current_user: User = Depends(get_current_user)
):
    """
    Bookmark a word with meanings in both target and native languages.
    
    When moving to auth project:
    - Remove user_id from Form
    - Add: current_user: User = Depends(get_current_user)
    - Use: user_id = current_user.id
    """
    user_id = current_user.id
    async with async_session() as sess:
        
        existing = await sess.execute(
            text("SELECT id FROM user_bookmarks WHERE user_id = :uid AND word = :word"),
            {"uid": user_id, "word": word.lower().strip()}
        )
        if existing.fetchone():
            return {"status": "already_bookmarked", "word": word}
        
        
        await sess.execute(
            text("""
                INSERT INTO user_bookmarks (user_id, word, meaning_target, meaning_native, target_lang, native_lang, created_at)
                VALUES (:uid, :word, :m_target, :m_native, :t_lang, :n_lang, NOW())
            """),
            {
                "uid": user_id,
                "word": word.lower().strip(),
                "m_target": meaning_target,
                "m_native": meaning_native,
                "t_lang": target_lang,
                "n_lang": native_lang
            }
        )
        await sess.commit()
    
    return {"status": "bookmarked", "word": word, "user_id": user_id}


@router.get("/bookmarks")
async def get_bookmarks(
    native_lang: Optional[str] = None,  
    target_lang: Optional[str] = None,
    current_user: User = Depends(get_current_user)
):
    """
    Get all bookmarked words for a user.
    Optionally filter by native_lang, target_lang, or both.
    
    When moving to auth project:
    - Remove user_id query param
    - Add: current_user: User = Depends(get_current_user)
    - Use: user_id = current_user.id
    """
    user_id = current_user.id
    async with async_session() as sess:
        
        base_query = """
            SELECT word, meaning_target, meaning_native, target_lang, native_lang, created_at
            FROM user_bookmarks
            WHERE user_id = :uid
        """
        params = {"uid": user_id}
        
        if native_lang and target_lang:
            query = base_query + " AND native_lang = :n_lang AND target_lang = :t_lang ORDER BY created_at DESC"
            params["n_lang"] = native_lang
            params["t_lang"] = target_lang
        elif native_lang:
            query = base_query + " AND native_lang = :n_lang ORDER BY created_at DESC"
            params["n_lang"] = native_lang
        elif target_lang:
            query = base_query + " AND target_lang = :t_lang ORDER BY created_at DESC"
            params["t_lang"] = target_lang
        else:
            query = base_query + " ORDER BY created_at DESC"
        
        result = await sess.execute(text(query), params)
        rows = result.fetchall()
    
    words = [
        {
            "word": r[0],
            "meaning_target": r[1],
            "meaning_native": r[2],
            "target_lang": r[3],
            "native_lang": r[4],
            "created_at": str(r[5]) if r[5] else None
        }
        for r in rows
    ]
    
    
    filter_info = {}
    if native_lang:
        filter_info["native_lang"] = native_lang
    if target_lang:
        filter_info["target_lang"] = target_lang
    
    return {
        "user_id": user_id,
        "total": len(words),
        "filter": filter_info if filter_info else None,
        "words": words
    }


@router.delete("/bookmark/{word}")
async def remove_bookmark(
    word: str,
    current_user: User = Depends(get_current_user)
):
    """
    Remove a bookmarked word.
    
    When moving to auth project:
    - Remove user_id query param
    - Add: current_user: User = Depends(get_current_user)
    - Use: user_id = current_user.id
    """
    user_id = current_user.id
    async with async_session() as sess:
        result = await sess.execute(
            text("DELETE FROM user_bookmarks WHERE user_id = :uid AND word = :word RETURNING id"),
            {"uid": user_id, "word": word.lower().strip()}
        )
        deleted = result.fetchone()
        await sess.commit()
    
    if deleted:
        return {"status": "removed", "word": word}
    else:
        return {"status": "not_found", "word": word}




@router.get("/user_sessions/detailed")
async def get_pronunciation_sessions_detailed(current_user: User = Depends(get_current_user)):
    """

    Returns sessions labeled as Session 1, Session 2, etc.
    with complete turn-by-turn feedback.
    """
    user_id = current_user.id
    sessions = await db.get_sessions_by_user_id(user_id, session_type="pronunciation")
    
    detailed_sessions = []
    for idx, session in enumerate(sessions, 1):
        session_id = session.get("session_id")
        session_data = await db.get_user_session(session_id)
        feedback = await db.get_session_feedback(session_id)
        
        # Get session metadata
        lesson_id = session_data.get("lesson_id") if session_data else None
        target_lang = session_data.get("target_lang", "en") if session_data else "en"
        
        # Get full turn feedback
        full_turns = []
        if feedback and feedback.get("turn_feedback"):
            for turn in feedback.get("turn_feedback", []):
                full_turns.append({
                    "turn": turn.get("turn"),
                    "word": turn.get("word", {}),
                    "transcription": turn.get("transcription", ""),
                    "pronunciation_score": turn.get("pronunciation_score", 0),
                    "pronunciation": turn.get("pronunciation", {}),
                    "fluency": turn.get("fluency", {}),
                    "wpm": turn.get("wpm", 0)
                })
        
        # Get full final feedback
        final = feedback.get("final_feedback", {}) if feedback else {}
        
        detailed_sessions.append({
            "session_number": f"Session {idx}",
            "session_id": session_id,
            "lesson_id": lesson_id,
            "target_lang": target_lang,
            "overall_score": session.get("overall_score", 0),
            "status": session.get("status", "active"),
            "created_at": session.get("created_at"),
            "total_turns": len(full_turns),
            "turns": full_turns,
            "final_feedback": final
        })
    
    return {
        "user_id": user_id,
        "total_sessions": len(detailed_sessions),
        "sessions": detailed_sessions
    }


@router.get("/pronunciation_vocab_sets")
async def get_pronunciation_vocab_sets():
   """Get all unique set numbers from pronunciation vocabulary"""
   async with async_session() as sess:
       result = await sess.execute(
           text("SELECT DISTINCT set_number FROM pronunciation_vocab WHERE set_number IS NOT NULL ORDER BY set_number")
       )
       rows = result.fetchall()

       set_numbers = [row[0] for row in rows]

       return {
           "status": "success",
           "total": len(set_numbers),
           "set_numbers": set_numbers
       }
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

import asyncio
import json
import logging
import os
import re
import shutil
import tempfile
import uuid
from typing import Optional

from sqlalchemy import text
from db.base import SessionLocal
from faster_whisper import WhisperModel
from fastapi import APIRouter, Form, File, UploadFile, HTTPException, Depends, Request
from deep_translator import GoogleTranslator
from openai import AzureOpenAI
from pydub import AudioSegment

from utils.agents_utils import analyze_speaking_advanced, load_language_mapping, normalize_language_code
from utils.ai_fluent_utils import (
    call_gpt,
    detect_emotion,
    score_fluency,
    speech_to_text,
    BOT_NAME,
    BOT_ROLE,
    THRESHOLD,
)
from models import User
from db.agents_db import chat_session_db as db
from utils.tts_utils import generate_tts_url
from utils.user_details import get_current_user
import shutil

ffmpeg = shutil.which("ffmpeg")




llm_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)


logger = logging.getLogger(__name__)

_whisper_model = WhisperModel("large-v3", compute_type="int8")


router = APIRouter()

QWEN_ENABLED = False
qwen_client = None  
QWEN_MODEL_NAME = "Qwen/Qwen3-0.6B" 


PASSING_SCORE = 50
TERMINATION_PHRASES = ["exit", "stop", "end", "finish", "quit", "done", "bye", "goodbye"]

llm_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

LEVEL_KEYWORDS = {
    "beginner": "B1",
    "basic": "B1",
    "starter": "B1",
    "elementary": "B1",
    "intermediate": "B2",
    "medium": "B2",
    "moderate": "B2",
    "advanced": "C1",
    "fluent": "C1",
    "experienced": "C1",
    "proficient": "C2",
    "expert": "C2",
    "native": "C2",
    "master": "C2"
}


LEVEL_DISPLAY = {
    "B1": "Beginner",
    "B2": "Intermediate",
    "C1": "Advanced",
    "C2": "Proficient"
}

KNOWLEDGE_BASE = """
- Conversational Practice: Engage in real-time conversations on various topics.
- Vocabulary Building: Introduce new words and phrases with definitions.
- Grammar Exercises: Offer explanations and practice for grammatical structures.
- Pronunciation Practice: Provide feedback on pronunciation.
- Provide immediate, constructive feedback on the user's language use.
- Praise progress and highlight improvements.
"""

# Language-specific rules for grammar, vocabulary, and pronunciation analysis
# NOTE: English rules are already in the prompts, so only non-English languages are defined here
# These are REFERENCE guidelines for the LLM, not strict rules
LANGUAGE_RULES = {
    "de": {
        "name": "German",
        "grammar": {
            "articles": ["der (masc)", "die (fem)", "das (neut)", "ein/eine"],
            "cases": ["Nominativ (subject)", "Akkusativ (direct object)", "Dativ (indirect object)", "Genitiv (possession)"],
            "common_errors": [
                {"error": "wrong gender", "example": "die Tisch Ã¢â€ â€™ der Tisch", "tip": "Memorize noun genders with the article"},
                {"error": "case errors", "example": "Ich sehe der Mann Ã¢â€ â€™ Ich sehe den Mann", "tip": "Akkusativ changes derÃ¢â€ â€™den"},
                {"error": "verb position", "example": "Ich heute gehe Ã¢â€ â€™ Ich gehe heute", "tip": "Verb must be 2nd element in main clause"},
                {"error": "separable verbs", "example": "Ich aufstehe Ã¢â€ â€™ Ich stehe auf", "tip": "Prefix goes to end of clause"},
                {"error": "subordinate clause order", "example": "weil ich gehe Ã¢â€ â€™ weil ich gehe (verb at end)", "tip": "In subordinate clauses, verb goes to the end"}
            ],
            "word_order": "V2 (verb second) in main clause, verb-final in subordinate clauses",
            "verb_conjugation": "Conjugates for person (ich/du/er), number (singular/plural), tense (PrÃƒÂ¤sens/PrÃƒÂ¤teritum/Perfekt), mood (Indikativ/Konjunktiv)",
            "special_rules": [
                "All nouns are capitalized",
                "Verb is always the second element in declarative sentences",
                "Modal verbs push main verb to the end in infinitive form",
                "Adjective endings change based on article type and case"
            ],
            "example_sentences": [
                {"wrong": "Ich habe gestern ein Buch gekauft.", "correct": "Ich habe gestern ein Buch gekauft.", "note": "Participle at end"},
                {"wrong": "Der Mann, der ich sehe", "correct": "Der Mann, den ich sehe", "note": "Relative pronoun case"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["du (informal/friends)", "Sie (formal/strangers/business)"],
            "compound_words": "Very common - combine words: Handschuh (hand+shoe = glove)",
            "common_collocations": ["eine Entscheidung treffen (make a decision)", "Pause machen (take a break)", "Bescheid sagen (let know)"],
            "false_friends": ["bekommen Ã¢â€°Â  become (means 'to get')", "Gift Ã¢â€°Â  gift (means 'poison')"],
            "separable_prefixes": ["auf-, an-, aus-, ein-, mit-, vor-, zu-, ab-, weg-"],
            "register_markers": ["Formal: wÃƒÂ¼rden Sie, kÃƒÂ¶nnten Sie", "Informal: kannst du, willst du"]
        },
        "pronunciation": {
            "stress_pattern": "Usually on first syllable, except for loanwords and prefixed verbs",
            "difficult_sounds": [
                "ÃƒÂ¼ [y] - round lips like 'oo', say 'ee'",
                "ÃƒÂ¶ [ÃƒÂ¸] - round lips like 'o', say 'e'",
                "ch [ÃƒÂ§/x] - after front vowels soft (ich), after back vowels hard (ach)",
                "r - uvular/throat sound, not like English",
                "ÃƒÅ¸ - always voiceless 's' sound"
            ],
            "umlauts": ["ÃƒÂ¤ = 'e' sound", "ÃƒÂ¶ = between 'o' and 'e'", "ÃƒÂ¼ = between 'u' and 'i'"],
            "final_devoicing": "Final b/d/g sound like p/t/k",
            "intonation": "Generally flatter than English, rises for yes/no questions"
        }
    },
    "fr": {
        "name": "French",
        "grammar": {
            "articles": ["le (masc sing)", "la (fem sing)", "les (plural)", "un/une (indefinite)", "du/de la (partitive)"],
            "common_errors": [
                {"error": "wrong gender", "example": "le table Ã¢â€ â€™ la table", "tip": "Most -tion/-sion words are feminine"},
                {"error": "agreement errors", "example": "les petit filles Ã¢â€ â€™ les petites filles", "tip": "Adjectives agree in gender AND number"},
                {"error": "wrong preposition", "example": "penser ÃƒÂ  Ã¢â€ â€™ penser de", "tip": "Prepositions are verb-specific"},
                {"error": "past tense auxiliary", "example": "J'ai allÃƒÂ© Ã¢â€ â€™ Je suis allÃƒÂ©", "tip": "Motion/state change verbs use ÃƒÂªtre"},
                {"error": "negation structure", "example": "Je ne sais Ã¢â€ â€™ Je ne sais pas", "tip": "Ne...pas wraps around verb"}
            ],
            "word_order": "Subject-Verb-Object, most adjectives AFTER noun (une maison grande)",
            "verb_conjugation": "Complex: person, number, tense (8+ tenses), mood (indicatif/subjonctif/conditionnel)",
            "special_rules": [
                "Adjectives agree in gender and number with noun",
                "Liaison: final consonant pronounced before vowel",
                "Partitive articles: du pain (some bread), de l'eau (some water)",
                "Object pronouns go BEFORE the verb (Je le vois)"
            ],
            "example_sentences": [
                {"wrong": "Je suis allÃƒÂ© ÃƒÂ  le magasin", "correct": "Je suis allÃƒÂ© au magasin", "note": "ÃƒÂ  + le = au"},
                {"wrong": "Il faut que je vais", "correct": "Il faut que j'aille", "note": "Subjunctive after 'il faut que'"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["tu (informal/friends)", "vous (formal/plural)"],
            "false_friends": ["actuellement = currently (not actually)", "librairie = bookstore (not library)", "assister = attend (not assist)"],
            "common_collocations": ["prendre une dÃƒÂ©cision", "faire une pause", "avoir l'air (to seem)", "faire semblant (pretend)"],
            "register_markers": ["Formal: Veuillez..., Je vous prie de...", "Informal: T'inquiÃƒÂ¨te, Ãƒâ€¡a va?"],
            "liaisons_importantes": ["les amis [lez-ami]", "nous avons [nuz-avÃƒÂµ]"]
        },
        "pronunciation": {
            "stress_pattern": "ALWAYS on last syllable of phrase/word group",
            "silent_letters": [
                "Final consonants usually silent (petit, grand, franÃƒÂ§ais)",
                "h is always silent (l'hÃƒÂ´tel, l'homme)",
                "e at end often silent (je parle)"
            ],
            "difficult_sounds": [
                "r [ÃŠÂ] - uvular/throat, not rolled",
                "Nasal vowels: on [ÃƒÂµ], an/en [Ã‰â€˜ÃŒÆ’], in [Ã‰â€ºÃŒÆ’], un [Ã…â€œÃŒÆ’]",
                "u [y] vs ou [u] - both are different",
                "eu [ÃƒÂ¸/Ã…â€œ] - rounded front vowel"
            ],
            "liaison": "Connect final consonant to next vowel (les enfants = lez-enfants)",
            "enchainement": "Final pronounced consonant links to next vowel",
            "intonation": "Rising at end of phrases, falling at end of statements"
        }
    },
    "ja": {
        "name": "Japanese",
        "grammar": {
            "articles": [],
            "particles": ["Ã£ÂÂ¯ (wa) topic", "Ã£ÂÅ’ (ga) subject", "Ã£â€šâ€™ (wo) object", "Ã£ÂÂ« (ni) direction/time", "Ã£ÂÂ§ (de) location/means", "Ã£ÂÂ¨ (to) with/and"],
            "common_errors": [
                {"error": "particle confusion", "example": "Ã§Â§ÂÃ£â€šâ€™Ã¥Â­Â¦Ã¦Â Â¡Ã£ÂÂ«Ã¨Â¡Å’Ã£ÂÂ Ã¢â€ â€™ Ã§Â§ÂÃ£ÂÂ¯Ã¥Â­Â¦Ã¦Â Â¡Ã£ÂÂ«Ã¨Â¡Å’Ã£ÂÂ", "tip": "Ã£ÂÂ¯ marks topic, Ã£â€šâ€™ marks direct object"},
                {"error": "verb form mixing", "example": "Ã©Â£Å¸Ã£ÂÂ¹Ã£â€šâ€¹Ã£ÂÂ¾Ã£Ââ€”Ã£ÂÅ¸ Ã¢â€ â€™ Ã©Â£Å¸Ã£ÂÂ¹Ã£ÂÂ¾Ã£Ââ€”Ã£ÂÅ¸", "tip": "Don't mix plain and polite forms"},
                {"error": "counter errors", "example": "Ã¤Â¸â€°Ã£ÂÂ¤Ã¤ÂºÂº Ã¢â€ â€™ Ã¤Â¸â€°Ã¤ÂºÂº", "tip": "Ã¤ÂºÂº has special counter (Ã£ÂÂ«Ã£â€šâ€œ/Ã¤ÂºÂº)"},
                {"error": "honorific levels", "example": "Ã¥â€¦Ë†Ã§â€Å¸Ã£ÂÅ’Ã¨Â¨â‚¬Ã£ÂÂ£Ã£ÂÅ¸ Ã¢â€ â€™ Ã¥â€¦Ë†Ã§â€Å¸Ã£ÂÅ’Ã£ÂÅ Ã£ÂÂ£Ã£Ââ€”Ã£â€šÆ’Ã£ÂÂ£Ã£ÂÅ¸", "tip": "Use humble/respectful forms appropriately"},
                {"error": "Ã£ÂÂ¯ vs Ã£ÂÅ’ confusion", "example": "Ã§Å’Â«Ã£ÂÂ¯Ã¥Â¥Â½Ã£ÂÂÃ£ÂÂ§Ã£Ââ„¢ (cats in general) vs Ã§Å’Â«Ã£ÂÅ’Ã¥Â¥Â½Ã£ÂÂÃ£ÂÂ§Ã£Ââ„¢ (emphasis)", "tip": "Ã£ÂÂ¯ = topic/contrast, Ã£ÂÅ’ = subject/new info"}
            ],
            "word_order": "Subject-Object-Verb (SOV) - verb ALWAYS at the end",
            "verb_conjugation": "Conjugates for tense, politeness, and aspect (not person/number)",
            "special_rules": [
                "Particles mark grammatical function (like prepositions but after noun)",
                "Verb is always at the end of the sentence",
                "No plural forms for nouns (context determines)",
                "Subjects/topics often omitted if understood from context",
                "Three politeness levels: casual, polite (Ã£ÂÂ§Ã£Ââ„¢/Ã£ÂÂ¾Ã£Ââ„¢), formal (keigo)"
            ],
            "example_sentences": [
                {"context": "Polite", "example": "Ã§Â§ÂÃ£ÂÂ¯Ã¥Â­Â¦Ã§â€Å¸Ã£ÂÂ§Ã£Ââ„¢Ã£â‚¬â€š", "note": "Ã£ÂÂ§Ã£Ââ„¢ for polite copula"},
                {"context": "Casual", "example": "Ã¤Â¿ÂºÃ£ÂÂ¯Ã¥Â­Â¦Ã§â€Å¸Ã£ÂÂ Ã£â‚¬â€š", "note": "Ã£ÂÂ  for casual copula"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["casual (Ã£ÂÂ /Ã£â€šâ€¹)", "polite (Ã£ÂÂ§Ã£Ââ„¢/Ã£ÂÂ¾Ã£Ââ„¢)", "humble (Ã¨Â¬â„¢Ã¨Â­Â²Ã¨ÂªÅ¾)", "respectful (Ã¥Â°Å Ã¦â€¢Â¬Ã¨ÂªÅ¾)"],
            "writing_systems": ["Hiragana (native words)", "Katakana (foreign words/emphasis)", "Kanji (Chinese characters)"],
            "counters": "Use specific counters: Ã¤ÂºÂº(people), Ã¦Å“Â¬(long things), Ã¦Å¾Å¡(flat things), Ã¥Å’Â¹(small animals)",
            "onomatopoeia": "Very common: Ã£Æ’Â¯Ã£â€šÂ¯Ã£Æ’Â¯Ã£â€šÂ¯(excited), Ã£Æ’â€°Ã£â€šÂ­Ã£Æ’â€°Ã£â€šÂ­(nervous), Ã£Æ’â€¢Ã£Æ’Â¯Ã£Æ’â€¢Ã£Æ’Â¯(fluffy)",
            "loan_words": "Many from English written in katakana: Ã£Æ’â€˜Ã£â€šÂ½Ã£â€šÂ³Ã£Æ’Â³, Ã£â€šÂ³Ã£Æ’Â¼Ã£Æ’â€™Ã£Æ’Â¼"
        },
        "pronunciation": {
            "stress_pattern": "Pitch accent (high-low patterns) - pitch changes meaning",
            "difficult_sounds": [
                "Long vowels (Ã£ÂÅ Ã£ÂÂ°Ã£Ââ€¢Ã£â€šâ€œ aunt vs Ã£ÂÅ Ã£ÂÂ°Ã£Ââ€šÃ£Ââ€¢Ã£â€šâ€œ grandmother)",
                "Double consonants (Ã£ÂÂÃ£ÂÂ¦ come vs Ã£ÂÂÃ£ÂÂ£Ã£ÂÂ¦ stamp)",
                "r - single tap, between 'r' and 'l'",
                "Pitch accent: Ã¦Â©â€¹ (hashi, low-high = chopsticks) vs Ã§Â®Â¸ (hashi, high-low = bridge)"
            ],
            "mora_timing": "Each mora (hiragana) has equal length",
            "vowel_devoicing": "i and u often whispered between voiceless consonants",
            "intonation": "Relatively flat, pitch accent is lexical"
        }
    },
    "zh": {
        "name": "Chinese (Mandarin)",
        "grammar": {
            "articles": [],
            "measure_words": ["Ã¤Â¸Âª (general)", "Ã¦Å“Â¬ (books)", "Ã¥Â¼Â  (flat things)", "Ã¦ÂÂ¡ (long things)", "Ã¥ÂÂª (animals)"],
            "common_errors": [
                {"error": "missing measure word", "example": "Ã¤Â¸â€°Ã¤Â¹Â¦ Ã¢â€ â€™ Ã¤Â¸â€°Ã¦Å“Â¬Ã¤Â¹Â¦", "tip": "Measure word required between number and noun"},
                {"error": "wrong aspect marker", "example": "Ã¦Ë†â€˜Ã¥ÂÆ’Ã©Â¥Â­ Ã¢â€ â€™ Ã¦Ë†â€˜Ã¥ÂÆ’Ã¤Âºâ€ Ã©Â¥Â­", "tip": "Ã¤Âºâ€  for completed, Ã¨Â¿â€¡ for experience, Ã§Ââ‚¬ for ongoing"},
                {"error": "word order in questions", "example": "Ã¥â€œÂªÃ©â€¡Å’Ã¤Â½Â Ã¥Å½Â»Ã¯Â¼Å¸ Ã¢â€ â€™ Ã¤Â½Â Ã¥Å½Â»Ã¥â€œÂªÃ©â€¡Å’Ã¯Â¼Å¸", "tip": "Question word stays in place"},
                {"error": "complement errors", "example": "Ã¥Â­Â¦Ã¥Â¥Â½ vs Ã¥Â­Â¦Ã¥Â¾â€”Ã¥Â¥Â½", "tip": "Ã¥Â¾â€” introduces result/degree complements"},
                {"error": "Ã¦Å Å  construction", "example": "Ã¦Ë†â€˜Ã¦â€°â€œÃ§Â Â´Ã¤Âºâ€ Ã¦ÂÂ¯Ã¥Â­Â Ã¢â€ â€™ Ã¦Ë†â€˜Ã¦Å Å Ã¦ÂÂ¯Ã¥Â­ÂÃ¦â€°â€œÃ§Â Â´Ã¤Âºâ€ ", "tip": "Ã¦Å Å  moves object before verb for disposal/result"}
            ],
            "word_order": "Subject-Verb-Object (SVO), Time-Place order (big to small)",
            "verb_conjugation": "NO conjugation - use aspect markers (Ã¤Âºâ€ , Ã¨Â¿â€¡, Ã§Ââ‚¬) and time words",
            "special_rules": [
                "No verb conjugation at all",
                "Measure words are REQUIRED between numbers and nouns",
                "Topic-prominent: what you're talking about comes first",
                "Verb complements show result/degree (Ã§Å“â€¹Ã¥Â¾â€”Ã¨Â§Â = can see)",
                "Serial verb constructions are common"
            ],
            "example_sentences": [
                {"example": "Ã¦Ë†â€˜Ã¦ËœÂ¨Ã¥Â¤Â©Ã¤Â¹Â°Ã¤Âºâ€ Ã¤Â¸â€°Ã¦Å“Â¬Ã¤Â¹Â¦", "analysis": "Subject + Time + Verb + Ã¤Âºâ€  + Number + Measure + Noun"},
                {"example": "Ã¤Â»â€“Ã¨Â·â€˜Ã¥Â¾â€”Ã¥Â¾Ë†Ã¥Â¿Â«", "analysis": "Degree complement with Ã¥Â¾â€”"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["casual (Ã¥ÂÂ£Ã¨Â¯Â­)", "formal (Ã¤Â¹Â¦Ã©ÂÂ¢Ã¨Â¯Â­)", "literary (Ã¦â€“â€¡Ã¨Â¨â‚¬)"],
            "measure_words": "Must use correct classifier for each noun category",
            "chengyu": "Four-character idioms are important (Ã¦Ë†ÂÃ¨Â¯Â­): Ã¤Â¸â‚¬Ã¤Â¸Â¾Ã¤Â¸Â¤Ã¥Â¾â€”, Ã§â€Â»Ã¨â€ºâ€¡Ã¦Â·Â»Ã¨Â¶Â³",
            "homophones": "Many due to limited syllables (~400) - context is crucial",
            "register": ["Formal: Ã¨Â¯Â·Ã©â€”Â®, Ã¦â€šÂ¨ | Casual: Ã©â€”Â®Ã¤Â¸â‚¬Ã¤Â¸â€¹, Ã¤Â½Â "]
        },
        "pronunciation": {
            "tones": [
                "1st tone (Ã‹â€°): high flat - Ã¥Â¦Ë† (mÃ„Â) mother",
                "2nd tone (Ã‹Å ): rising - Ã©ÂºÂ» (mÃƒÂ¡) hemp",
                "3rd tone (Ã‹â€¡): dipping - Ã©Â©Â¬ (mÃ‡Å½) horse",
                "4th tone (Ã‹â€¹): falling - Ã©Âªâ€š (mÃƒÂ ) scold",
                "Neutral: short, unstressed - Ã¥Ââ€” (ma) question particle"
            ],
            "difficult_sounds": [
                "zh/ch/sh (retroflex) vs z/c/s (alveolar)",
                "ÃƒÂ¼ [y] - round lips, say 'ee'",
                "Retroflex finals: er, Ã¥â€žÂ¿Ã¥Å’â€“",
                "j/q/x (palatal sounds)"
            ],
            "tone_sandhi": "Two 3rd tones Ã¢â€ â€™ first becomes 2nd tone (Ã¤Â½Â Ã¥Â¥Â½ = nÃƒÂ­ hÃ‡Å½o)",
            "intonation": "Tones are LEXICAL (change meaning), not just intonational"
        }
    },
    "hi": {
        "name": "Hindi",
        "grammar": {
            "articles": [],
            "postpositions": ["Ã Â¤Â®Ã Â¥â€¡Ã Â¤â€š (in)", "Ã Â¤ÂªÃ Â¤Â° (on)", "Ã Â¤Â¸Ã Â¥â€¡ (from/with)", "Ã Â¤â€¢Ã Â¥â€¹ (to/object marker)", "Ã Â¤â€¢Ã Â¥â€¡ Ã Â¤Â²Ã Â¤Â¿Ã Â¤Â (for)"],
            "common_errors": [
                {"error": "gender agreement", "example": "Ã Â¤Â¬Ã Â¤Â¡Ã Â¤Â¼Ã Â¤Â¾ Ã Â¤Â²Ã Â¤Â¡Ã Â¤Â¼Ã Â¤â€¢Ã Â¥â‚¬ Ã¢â€ â€™ Ã Â¤Â¬Ã Â¤Â¡Ã Â¤Â¼Ã Â¥â‚¬ Ã Â¤Â²Ã Â¤Â¡Ã Â¤Â¼Ã Â¤â€¢Ã Â¥â‚¬", "tip": "Adjectives agree with noun gender"},
                {"error": "postposition errors", "example": "Ã Â¤ËœÃ Â¤Â° Ã Â¤â€¢Ã Â¥â€¹ Ã Â¤Å“Ã Â¤Â¾Ã Â¤Â¨Ã Â¤Â¾ Ã¢â€ â€™ Ã Â¤ËœÃ Â¤Â° Ã Â¤Å“Ã Â¤Â¾Ã Â¤Â¨Ã Â¤Â¾", "tip": "Ã Â¤â€¢Ã Â¥â€¹ not needed with Ã Â¤Å“Ã Â¤Â¾Ã Â¤Â¨Ã Â¤Â¾ for destinations"},
                {"error": "verb agreement", "example": "Ã Â¤Â²Ã Â¤Â¡Ã Â¤Â¼Ã Â¤â€¢Ã Â¥â‚¬ Ã Â¤â€”Ã Â¤Â¯Ã Â¤Â¾ Ã¢â€ â€™ Ã Â¤Â²Ã Â¤Â¡Ã Â¤Â¼Ã Â¤â€¢Ã Â¥â‚¬ Ã Â¤â€”Ã Â¤Ë†", "tip": "Verb agrees with subject in gender"},
                {"error": "honorific forms", "example": "Ã Â¤â€ Ã Â¤Âª Ã Â¤â€¢Ã Â¥ÂÃ Â¤Â¯Ã Â¤Â¾ Ã Â¤Å¡Ã Â¤Â¾Ã Â¤Â¹Ã Â¤Â¤Ã Â¥â€¡ Ã Â¤Â¹Ã Â¥â€¹ Ã¢â€ â€™ Ã Â¤â€ Ã Â¤Âª Ã Â¤â€¢Ã Â¥ÂÃ Â¤Â¯Ã Â¤Â¾ Ã Â¤Å¡Ã Â¤Â¾Ã Â¤Â¹Ã Â¤Â¤Ã Â¥â€¡ Ã Â¤Â¹Ã Â¥Ë†Ã Â¤â€š", "tip": "Ã Â¤â€ Ã Â¤Âª takes Ã Â¤Â¹Ã Â¥Ë†Ã Â¤â€š, not Ã Â¤Â¹Ã Â¥â€¹"},
                {"error": "ergative case", "example": "Ã Â¤Â®Ã Â¥Ë†Ã Â¤â€šÃ Â¤Â¨Ã Â¥â€¡ Ã Â¤â€¢Ã Â¤Â¿Ã Â¤Â¤Ã Â¤Â¾Ã Â¤Â¬ Ã Â¤ÂªÃ Â¤Â¢Ã Â¤Â¼Ã Â¤Â¾ Ã¢â€ â€™ Ã Â¤Â®Ã Â¥Ë†Ã Â¤â€šÃ Â¤Â¨Ã Â¥â€¡ Ã Â¤â€¢Ã Â¤Â¿Ã Â¤Â¤Ã Â¤Â¾Ã Â¤Â¬ Ã Â¤ÂªÃ Â¤Â¢Ã Â¤Â¼Ã Â¥â‚¬", "tip": "In perfective tense, verb agrees with object if subject has Ã Â¤Â¨Ã Â¥â€¡"}
            ],
            "word_order": "Subject-Object-Verb (SOV) - verb at the end",
            "verb_conjugation": "Agrees with subject in gender, number, person; also honorific level",
            "special_rules": [
                "Postpositions (not prepositions) - come AFTER noun",
                "Verb is always at the end",
                "All nouns have gender (masculine/feminine)",
                "Ergative construction: Ã Â¤Â¨Ã Â¥â€¡ marks agent in perfective",
                "Three levels of respect: Ã Â¤Â¤Ã Â¥â€š < Ã Â¤Â¤Ã Â¥ÂÃ Â¤Â® < Ã Â¤â€ Ã Â¤Âª"
            ],
            "example_sentences": [
                {"example": "Ã Â¤Â®Ã Â¥Ë†Ã Â¤â€š Ã Â¤Â¸Ã Â¥ÂÃ Â¤â€¢Ã Â¥â€šÃ Â¤Â² Ã Â¤Å“Ã Â¤Â¾Ã Â¤Â¤Ã Â¤Â¾ Ã Â¤Â¹Ã Â¥â€šÃ Â¤Â", "analysis": "I school go-MASC am (male speaker)"},
                {"example": "Ã Â¤Â®Ã Â¥Ë†Ã Â¤â€š Ã Â¤Â¸Ã Â¥ÂÃ Â¤â€¢Ã Â¥â€šÃ Â¤Â² Ã Â¤Å“Ã Â¤Â¾Ã Â¤Â¤Ã Â¥â‚¬ Ã Â¤Â¹Ã Â¥â€šÃ Â¤Â", "analysis": "I school go-FEM am (female speaker)"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["Ã Â¤Â¤Ã Â¥â€š (very intimate)", "Ã Â¤Â¤Ã Â¥ÂÃ Â¤Â® (informal/friends)", "Ã Â¤â€ Ã Â¤Âª (formal/respect)"],
            "sanskrit_influence": "Formal/literary uses Sanskrit words (Ã Â¤Â¶Ã Â¤Â¿Ã Â¤â€¢Ã Â¥ÂÃ Â¤Â·Ã Â¤Â¾, Ã Â¤ÂµÃ Â¤Â¿Ã Â¤Â¦Ã Â¥ÂÃ Â¤Â¯Ã Â¤Â¾Ã Â¤Â²Ã Â¤Â¯)",
            "urdu_influence": "Everyday speech uses Persian/Arabic words (Ã Â¤Â¦Ã Â¥â€¹Ã Â¤Â¸Ã Â¥ÂÃ Â¤Â¤, Ã Â¤â€“Ã Â¤Â¬Ã Â¤Â°)",
            "honorifics": "Ã Â¤Å“Ã Â¥â‚¬ suffix for respect (Ã Â¤Å“Ã Â¥â‚¬, Ã Â¤Â¸Ã Â¤Â¾Ã Â¤Â¹Ã Â¤Â¬, Ã Â¤Â¶Ã Â¥ÂÃ Â¤Â°Ã Â¥â‚¬, Ã Â¤Â¶Ã Â¥ÂÃ Â¤Â°Ã Â¥â‚¬Ã Â¤Â®Ã Â¤Â¤Ã Â¥â‚¬)",
            "echo_words": "Reduplication: Ã Â¤â€“Ã Â¤Â¾Ã Â¤Â¨Ã Â¤Â¾-Ã Â¤ÂµÃ Â¤Â¾Ã Â¤Â¨Ã Â¤Â¾ (food and stuff), Ã Â¤Å¡Ã Â¤Â¾Ã Â¤Â¯-Ã Â¤ÂµÃ Â¤Â¾Ã Â¤Â¯"
        },
        "pronunciation": {
            "stress_pattern": "Generally on second-to-last syllable; longer syllables get stress",
            "difficult_sounds": [
                "Aspirated vs unaspirated: Ã Â¤â€¢ [k] vs Ã Â¤â€“ [kÃŠÂ°], Ã Â¤Âª [p] vs Ã Â¤Â« [pÃŠÂ°]",
                "Retroflex sounds: Ã Â¤Å¸, Ã Â¤Â , Ã Â¤Â¡, Ã Â¤Â¢, Ã Â¤Â£ (tongue curled back)",
                "Nasal vowels: Ã Â¤Â®Ã Â¤Â¾Ã Â¤Â, Ã Â¤Â¹Ã Â¤Â¾Ã Â¤Â (with Ã Â¤Â/Ã Â¤â€š)",
                "Ã Â¤Â¡Ã Â¤Â¼ and Ã Â¤Â¢Ã Â¤Â¼ - flapped retroflex"
            ],
            "schwa_deletion": "Final inherent 'a' vowel often not pronounced (Ã Â¤Â°Ã Â¤Â¾Ã Â¤Â® = raam, not raama)",
            "gemination": "Double consonants are longer: Ã Â¤ÂªÃ Â¤â€¢Ã Â¤Â¾ (ripe) vs Ã Â¤ÂªÃ Â¤â€¢Ã Â¥ÂÃ Â¤â€¢Ã Â¤Â¾ (firm)",
            "nasalization": "Vowels can be nasalized with chandrabindu (Ã Â¤Â)"
        }
    },
    "te": {
        "name": "Telugu",
        "grammar": {
            "articles": [],
            "case_suffixes": ["Ã Â°Â¨Ã Â°Â¿ (accusative)", "Ã Â°â€¢Ã Â±Â/Ã Â°â€¢Ã Â°Â¿ (dative)", "Ã Â°Â²Ã Â±â€¹ (locative)", "Ã Â°Â¤Ã Â±â€¹ (instrumental)", "Ã Â°Â¨Ã Â±ÂÃ Â°â€šÃ Â°Å¡Ã Â°Â¿ (ablative)"],
            "common_errors": [
                {"error": "case suffix errors", "example": "Ã Â°Â¨Ã Â±â€¡Ã Â°Â¨Ã Â±Â Ã Â°â€¡Ã Â°â€šÃ Â°Å¸Ã Â°Â¿Ã Â°â€¢Ã Â°Â¿ Ã Â°ÂµÃ Â±â€ Ã Â°Â³Ã Â±ÂÃ Â°Â³Ã Â°Â¾Ã Â°Â¨Ã Â±Â Ã¢â€ â€™ proper case endings", "tip": "Use correct case suffix for each function"},
                {"error": "verb agreement", "example": "Ã Â°â€¦Ã Â°Â¤Ã Â°Â¨Ã Â±Â Ã Â°ÂµÃ Â°Å¡Ã Â±ÂÃ Â°Å¡Ã Â°Â¿Ã Â°â€šÃ Â°Â¦Ã Â°Â¿ Ã¢â€ â€™ Ã Â°â€¦Ã Â°Â¤Ã Â°Â¨Ã Â±Â Ã Â°ÂµÃ Â°Å¡Ã Â±ÂÃ Â°Å¡Ã Â°Â¾Ã Â°Â¡Ã Â±Â", "tip": "Verb ending must match subject gender/number"},
                {"error": "sandhi errors", "example": "Word junction rules", "tip": "Consonant/vowel changes at word boundaries"},
                {"error": "respectful forms", "example": "Ã Â°ÂµÃ Â°Å¡Ã Â±ÂÃ Â°Å¡Ã Â°Â¾Ã Â°Â°Ã Â±Â vs Ã Â°ÂµÃ Â°Å¡Ã Â±ÂÃ Â°Å¡Ã Â°Â¾Ã Â°Â¡Ã Â±Â", "tip": "Use -Ã Â°Â¾Ã Â°Â°Ã Â±Â suffix for respect"},
                {"error": "tense markers", "example": "Mixing simple past with other forms", "tip": "Past: -Ã Â°Â¾Ã Â°Â¨Ã Â±Â/-Ã Â°Â¾Ã Â°ÂµÃ Â±Â/-Ã Â°Â¾Ã Â°Â¡Ã Â±Â, Future: -Ã Â°Â¤Ã Â°Â¾Ã Â°Â¨Ã Â±Â/-Ã Â°Â¤Ã Â°Â¾Ã Â°ÂµÃ Â±Â"}
            ],
            "word_order": "Subject-Object-Verb (SOV) - verb always at end",
            "verb_conjugation": "Agrees with subject in person, number, gender, and respect level",
            "special_rules": [
                "Agglutinative: suffixes stack on words",
                "Sandhi: sound changes at word boundaries",
                "Case suffixes mark grammatical relations",
                "Verb at end of sentence",
                "Extensive use of participles and complex clauses"
            ],
            "example_sentences": [
                {"example": "Ã Â°Â¨Ã Â±â€¡Ã Â°Â¨Ã Â±Â Ã Â°ÂªÃ Â±ÂÃ Â°Â¸Ã Â±ÂÃ Â°Â¤Ã Â°â€¢Ã Â°â€š Ã Â°Å¡Ã Â°Â¦Ã Â±ÂÃ Â°ÂµÃ Â±ÂÃ Â°Â¤Ã Â±ÂÃ Â°Â¨Ã Â±ÂÃ Â°Â¨Ã Â°Â¾Ã Â°Â¨Ã Â±Â", "analysis": "I book reading-am (present continuous)"},
                {"example": "Ã Â°â€¦Ã Â°Â¤Ã Â°Â¨Ã Â±Â Ã Â°Â¬Ã Â°Â¡Ã Â°Â¿Ã Â°â€¢Ã Â°Â¿ Ã Â°ÂµÃ Â±â€ Ã Â°Â³Ã Â±ÂÃ Â°Â³Ã Â°Â¾Ã Â°Â¡Ã Â±Â", "analysis": "He school-to went (male subject)"}
            ]
        },
        "vocabulary": {
            "formality_levels": ["Ã Â°Â¨Ã Â±ÂÃ Â°ÂµÃ Â±ÂÃ Â°ÂµÃ Â±Â (informal)", "Ã Â°Â®Ã Â±â‚¬Ã Â°Â°Ã Â±Â (formal/plural)"],
            "sanskrit_influence": "Literary/formal uses Sanskrit: Ã Â°ÂµÃ Â°Â¿Ã Â°Â¦Ã Â±ÂÃ Â°Â¯ (knowledge), Ã Â°â€”Ã Â±ÂÃ Â°Â°Ã Â°â€šÃ Â°Â¥Ã Â°Â¾Ã Â°Â²Ã Â°Â¯Ã Â°â€š (library)",
            "honorific_suffixes": ["Ã Â°â€”Ã Â°Â¾Ã Â°Â°Ã Â±Â (respect)", "Ã Â°ÂµÃ Â°Â¾Ã Â°Â°Ã Â±Â (high respect)"],
            "native_vs_borrowed": "Ã Â°Â¤Ã Â°Â¤Ã Â±ÂÃ Â°Â¸Ã Â°Â® (direct Sanskrit) vs Ã Â°Â¤Ã Â°Â¦Ã Â±ÂÃ Â°Â­Ã Â°Âµ (adapted native forms)",
            "echo_words": "Reduplication common: Ã Â°â€¦Ã Â°Â¨Ã Â±ÂÃ Â°Â¨Ã Â°â€š-Ã Â°â€”Ã Â°Â¿Ã Â°Â¨Ã Â±ÂÃ Â°Â¨Ã Â°â€š (rice and such)"
        },
        "pronunciation": {
            "stress_pattern": "Generally on first syllable of word",
            "difficult_sounds": [
                "Retroflex consonants: Ã Â°Å¸, Ã Â°Â¡, Ã Â°Â£ (tongue curled back)",
                "Aspirated sounds: Ã Â°â€“, Ã Â°â€º, Ã Â°Â¥, Ã Â°Â« (with breath)",
                "Ã Â°Â³ [Ã‰Â­] - retroflex lateral (unique to Dravidian)",
                "Ã Â°Â± - older retroflex flap (rare now)"
            ],
            "vowel_length": "Short vs long vowels change meaning: Ã Â°ÂªÃ Â°Â²Ã Â±Â (teeth) vs Ã Â°ÂªÃ Â°Â¾Ã Â°Â²Ã Â±Â (milk)",
            "gemination": "Double consonants are important: Ã Â°â€¢Ã Â°Â² (dream) vs Ã Â°â€¢Ã Â°Â³Ã Â±ÂÃ Â°Â³ (eyes)",
            "sandhi_phonetics": "Sound changes occur at morpheme/word boundaries"
        }
    }
}

def get_language_rules(lang_code: str) -> dict:
    """Get language-specific rules for a given language code. Returns None for English."""
    lang_lower = lang_code.lower()
    # Map common language names/codes to our keys
    lang_mapping = {
        "english": "en", "en": "en",
        "german": "de", "de": "de", "deutsch": "de",
        "french": "fr", "fr": "fr", "franÃƒÂ§ais": "fr", "francais": "fr",
        "japanese": "ja", "ja": "ja", "jp": "ja", "Ã¦â€”Â¥Ã¦Å“Â¬Ã¨ÂªÅ¾": "ja",
        "chinese": "zh", "zh": "zh", "mandarin": "zh", "Ã¤Â¸Â­Ã¦â€“â€¡": "zh",
        "hindi": "hi", "hi": "hi", "Ã Â¤Â¹Ã Â¤Â¿Ã Â¤â€šÃ Â¤Â¦Ã Â¥â‚¬": "hi",
        "telugu": "te", "te": "te", "Ã Â°Â¤Ã Â±â€ Ã Â°Â²Ã Â±ÂÃ Â°â€”Ã Â±Â": "te"
    }
    key = lang_mapping.get(lang_lower, "en")
    # Return None for English (rules already in prompts)
    if key == "en":
        return None
    return LANGUAGE_RULES.get(key)

 


def calculate_fluency(word_count: int, audio_duration: float) -> dict:
    """calculate fluency metrics"""
    wpm = int((word_count / audio_duration) * 60) if audio_duration > 0 else 100
    
    if wpm < 80:
        score = max(40.0, 70.0 - (80 - wpm) * 0.75)
        speed_status = "too_slow"
    elif wpm < 110:
        score = 70.0 + (wpm - 80)
        speed_status = "slow"
    elif wpm <= 160:
        score = max(90.0, 100.0 - (wpm - 110) * 0.2)
        speed_status = "normal"
    elif wpm <= 180:
        score = max(80.0, 90.0 - (wpm - 160) * 0.5)
        speed_status = "fast"
    else:
        score = max(60.0, 80.0 - (wpm - 180) * 0.5)
        speed_status = "too_fast"
    
    return {
        "score": int(min(100, round(score))),
        "wpm": wpm,
        "speed_status": speed_status,
        "audio_duration_seconds": round(audio_duration, 1),
        "feedback": f"Your speaking speed is {speed_status.replace('_', ' ')} ({wpm} WPM)."
    }


BOT_NAME = "sara"
BOT_ROLE = "language tutor"


async def analyze_fluency_metrics(user_text: str, audio_duration: float) -> dict:
    """async wrapper for fluency metrics from text and duration"""
    
    word_count = len(re.findall(r"\b\w+\b", user_text or ""))
    return calculate_fluency(word_count, audio_duration)


async def compare_attempts(attempts: list, level: str = "B1", user_type: str = "student", model: str = "gpt", target_language: str = "en") -> dict:
    """
    Compare attempts using LLM for detailed, elaborative feedback on ALL aspects:
    grammar, vocabulary, pronunciation, and fluency.
    """
    if len(attempts) < 2:
        return {
            "improvement": 0,
            "trend": "first_attempt",
            "message": "This is your first attempt. Let's see how you do!",
            "details": {}
        }
    
    prev = attempts[-2]
    current = attempts[-1]
    
    
    prev_grammar = (prev.get("grammar") or {}).get("score", 0) or 0
    current_grammar = (current.get("grammar") or {}).get("score", 0) or 0
    
    prev_vocab = (prev.get("vocabulary") or {}).get("score", 0) or 0
    current_vocab = (current.get("vocabulary") or {}).get("score", 0) or 0
    
    prev_pron = (prev.get("pronunciation") or {}).get("accuracy", 0) or 0
    current_pron = (current.get("pronunciation") or {}).get("accuracy", 0) or 0
    
    prev_fluency = (prev.get("fluency") or {}).get("score", 0) or 0
    current_fluency = (current.get("fluency") or {}).get("score", 0) or 0
    
    prev_overall = prev.get("overall_score", 0) or 0
    current_overall = current.get("overall_score", 0) or 0
    
    
    grammar_diff = round(current_grammar - prev_grammar, 1)
    vocab_diff = round(current_vocab - prev_vocab, 1)
    pron_diff = round(current_pron - prev_pron, 1)
    fluency_diff = round(current_fluency - prev_fluency, 1)
    overall_diff = round(current_overall - prev_overall, 1)
    
    
    if overall_diff > 10:
        trend = "significantly_improved"
    elif overall_diff > 0:
        trend = "improved"
    elif overall_diff < -10:
        trend = "declined"
    elif overall_diff < 0:
        trend = "slightly_declined"
    else:
        trend = "no_change"
    
    
    prev_grammar_errors = (prev.get("grammar") or {}).get("errors", [])[:3]
    current_grammar_errors = (current.get("grammar") or {}).get("errors", [])[:3]
    prev_vocab_suggestions = (prev.get("vocabulary") or {}).get("suggestions", [])[:3]
    current_vocab_suggestions = (current.get("vocabulary") or {}).get("suggestions", [])[:3]
    prev_words_to_practice = (prev.get("pronunciation") or {}).get("words_to_practice", [])[:5]
    current_words_to_practice = (current.get("pronunciation") or {}).get("words_to_practice", [])[:5]
    
    prompt = f"""You are an expert language coach comparing TWO attempts at the SAME question.
Provide DETAILED, ELABORATIVE feedback on improvement or decline in ALL areas.

PREVIOUS ATTEMPT:
- Overall Score: {prev_overall}%
- Grammar: {prev_grammar}% (Errors: {[e.get('you_said', '') for e in prev_grammar_errors if isinstance(e, dict)]})
- Vocabulary: {prev_vocab}% (Weak words: {[s.get('word', '') for s in prev_vocab_suggestions if isinstance(s, dict)]})
- Pronunciation: {prev_pron}% (Needs practice: {[w.get('word', w) if isinstance(w, dict) else w for w in prev_words_to_practice]})
- Fluency: {prev_fluency}% (WPM: {(prev.get('fluency') or {}).get('wpm', 0)})
- What they said: "{prev.get('transcription', '')[:200]}"

CURRENT ATTEMPT:
- Overall Score: {current_overall}%
- Grammar: {current_grammar}% ({'+' if grammar_diff > 0 else ''}{grammar_diff}%)
- Vocabulary: {current_vocab}% ({'+' if vocab_diff > 0 else ''}{vocab_diff}%)
- Pronunciation: {current_pron}% ({'+' if pron_diff > 0 else ''}{pron_diff}%)
- Fluency: {current_fluency}% ({'+' if fluency_diff > 0 else ''}{fluency_diff}%)
- What they said: "{current.get('transcription', '')[:200]}"

USER CONTEXT:
- Level: {level}
- User Type: {user_type}

Analyze EACH category's improvement and provide detailed, encouraging feedback.

Return STRICTLY valid JSON:
{{
    "overall_summary": "3-4 sentences summarizing the overall improvement journey. Be specific about what changed.",
    "grammar_analysis": {{
        "previous_score": {prev_grammar},
        "current_score": {current_grammar},
        "difference": {grammar_diff},
        "improved": {str(grammar_diff > 0).lower()},
        "feedback": "Specific feedback about grammar improvement or what still needs work. Mention specific errors fixed or remaining."
    }},
    "vocabulary_analysis": {{
        "previous_score": {prev_vocab},
        "current_score": {current_vocab},
        "difference": {vocab_diff},
        "improved": {str(vocab_diff > 0).lower()},
        "feedback": "Specific feedback about vocabulary improvement. Mention better word choices used or areas to improve."
    }},
    "pronunciation_analysis": {{
        "previous_score": {prev_pron},
        "current_score": {current_pron},
        "difference": {pron_diff},
        "improved": {str(pron_diff > 0).lower()},
        "words_improved": ["words that sound better now"],
        "still_needs_work": ["words still needing practice"],
        "feedback": "Specific feedback about pronunciation. What words improved? What still needs practice?"
    }},
    "fluency_analysis": {{
        "previous_score": {prev_fluency},
        "current_score": {current_fluency},
        "difference": {fluency_diff},
        "improved": {str(fluency_diff > 0).lower()},
        "feedback": "Specific feedback about speaking pace and flow. Did they speak more naturally?"
    }},
    "biggest_improvement": "Which area improved the most and by how much",
    "area_needing_focus": "Which area still needs the most work",
    "encouragement": "A warm, personalized encouraging message mentioning specific progress",
    "next_step_tip": "One specific, actionable tip for continued improvement"
}}

Be ELABORATIVE. Don't just say 'improved' - explain HOW and WHAT specifically."""

    try:
        llm_response = await call_llm(prompt, mode="strict_json", timeout=30, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', llm_response)
        if json_match:
            llm_data = json.loads(json_match.group())
        else:
            raise ValueError("No JSON")
    except Exception as e:
        logger.debug(f"LLM compare_attempts fallback: {e}")
        
        if overall_diff > 0:
            summary = f"Great progress! Your overall score improved from {prev_overall}% to {current_overall}% (+{overall_diff}%)."
        elif overall_diff < 0:
            summary = f"Your score changed from {prev_overall}% to {current_overall}% ({overall_diff}%). Let's work on consistency."
        else:
            summary = f"Consistent performance at {current_overall}%. Try varying your approach for improvement."
        
        area_diffs = {
            "grammar": grammar_diff,
            "vocabulary": vocab_diff,
            "pronunciation": pron_diff,
            "fluency": fluency_diff
        }

        llm_data = {
            "overall_summary": summary,
            "grammar_analysis": {"previous_score": prev_grammar, "current_score": current_grammar, "difference": grammar_diff, "improved": grammar_diff > 0, "feedback": f"Grammar {'improved' if grammar_diff > 0 else 'needs more focus'} ({'+' if grammar_diff > 0 else ''}{grammar_diff}%)"},
            "vocabulary_analysis": {"previous_score": prev_vocab, "current_score": current_vocab, "difference": vocab_diff, "improved": vocab_diff > 0, "feedback": f"Vocabulary {'improved' if vocab_diff > 0 else 'needs more focus'} ({'+' if vocab_diff > 0 else ''}{vocab_diff}%)"},
            "pronunciation_analysis": {"previous_score": prev_pron, "current_score": current_pron, "difference": pron_diff, "improved": pron_diff > 0, "words_improved": [], "still_needs_work": [], "feedback": f"Pronunciation {'improved' if pron_diff > 0 else 'needs more focus'} ({'+' if pron_diff > 0 else ''}{pron_diff}%)"},
            "fluency_analysis": {"previous_score": prev_fluency, "current_score": current_fluency, "difference": fluency_diff, "improved": fluency_diff > 0, "feedback": f"Fluency {'improved' if fluency_diff > 0 else 'needs more focus'} ({'+' if fluency_diff > 0 else ''}{fluency_diff}%)"},
            "biggest_improvement": max(area_diffs, key=area_diffs.get),
            "area_needing_focus": min(area_diffs, key=area_diffs.get),
            "encouragement": f"Keep practicing! Your overall score {'improved' if overall_diff > 0 else 'stayed consistent'}.",
            "next_step_tip": "Focus on speaking slowly and clearly."
        }
    
    return {
        "previous_overall_score": prev_overall,
        "current_overall_score": current_overall,
        "overall_improvement": overall_diff,
        "trend": trend,
        "overall_summary": llm_data.get("overall_summary", ""),
        "grammar_analysis": llm_data.get("grammar_analysis", {}),
        "vocabulary_analysis": llm_data.get("vocabulary_analysis", {}),
        "pronunciation_analysis": llm_data.get("pronunciation_analysis", {}),
        "fluency_analysis": llm_data.get("fluency_analysis", {}),
        "biggest_improvement": llm_data.get("biggest_improvement", ""),
        "area_needing_focus": llm_data.get("area_needing_focus", ""),
        "encouragement": llm_data.get("encouragement", ""),
        "next_step_tip": llm_data.get("next_step_tip", "")
    }


async def call_llm(prompt: str, mode: str = "chat", timeout: int = 30, model: str = "gpt", target_language: str = "en") -> str:
    """async llm call with proper error handling and timeout. Supports gpt (default) or qwen."""
    # Base system prompts
    base_prompts = {
        "chat": "You are a kind, human-like language tutor helping users practice conversational skills.",
        "analysis": "You are an expert language evaluator. Analyze objectively and concisely.",
        "strict_json": "You are a structured evaluator. Respond ONLY in valid JSON. No extra text."
    }
    
    # Add language instruction if not English
    lang_lower = target_language.lower() if target_language else "en"
    is_english = lang_lower in ["en", "english"]
    lang_instruction = f" IMPORTANT: Respond entirely in {target_language} language." if not is_english else ""
    
    system_prompts = {k: v + lang_instruction for k, v in base_prompts.items()}
    
    
    if model.lower() == "qwen" and QWEN_ENABLED and qwen_client is not None:
        try:
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    qwen_client.chat.completions.create,
                    model=QWEN_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompts.get(mode, system_prompts["chat"])},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=800,
                    temperature=0.7 if mode == "chat" else 0.3
                ),
                timeout=timeout
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.warning(f"Qwen call failed, falling back to GPT: {e}")
            
    
    
    try:
        response = await asyncio.wait_for(
            asyncio.to_thread(
                llm_client.chat.completions.create,
                model=AZURE_OPENAI_DEPLOYMENT,
                messages=[
                    {"role": "system", "content": system_prompts.get(mode, system_prompts["chat"])},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7 if mode == "chat" else 0.3
            ),
            timeout=timeout
        )
        return response.choices[0].message.content.strip()
    except asyncio.TimeoutError:
        logger.error(f"LLM call timed out after {timeout}s")
        return ""
    except Exception as e:
        logger.error(f"LLM call failed: {e}")
        return ""


async def translate_text(text: str, source: str, target: str) -> str:
    """translate text between languages"""
    if source == target or not text or not isinstance(text, str):
        return text if isinstance(text, str) else ""
    try:
        translator = GoogleTranslator(source=source, target=target)
        return await asyncio.to_thread(translator.translate, text)
    except Exception as e:
        logger.debug(f"Translation failed: {e}")
        return text



GRAMMAR_FIELDS = ["feedback", "filler_feedback", "errors", "word_suggestions", "corrected_sentence", "improved_sentence"]
VOCAB_FIELDS = ["feedback", "suggestions"]
PRON_FIELDS = ["feedback", "words_to_practice"]
FLUENCY_FIELDS = ["feedback"]
PERSONAL_FIELDS = ["message", "improvement_areas", "strengths"]


async def make_bilingual(value, source: str, target: str):
    """Convert a value to {target, native} structure with translations"""
    if source == target:
        return value  
    
    if isinstance(value, str):
        if not value.strip():
            return {"target": value, "native": value}
        native = await translate_text(value, source, target)
        return {"target": value, "native": native}
    
    elif isinstance(value, list):
        result = []
        for item in value:
            if isinstance(item, dict):
                translated_item = {}
                for k, v in item.items():
                    translated_item[k] = await make_bilingual(v, source, target)
                result.append(translated_item)
            elif isinstance(item, str):
                native = await translate_text(item, source, target)
                result.append({"target": item, "native": native})
            else:
                result.append(item)
        return result
    
    elif isinstance(value, dict):
        result = {}
        for k, v in value.items():
            result[k] = await make_bilingual(v, source, target)
        return result
    
    else:
        return value


async def translate_analysis(analysis: dict, source: str, target: str, fields_to_translate: list) -> dict:
    """Translate specified fields in analysis dict to target/native format"""
    if source == target:
        return analysis
    
    result = {}
    for key, value in analysis.items():
        if key in fields_to_translate:
            result[key] = await make_bilingual(value, source, target)
        else:
            result[key] = value
    
    return result

async def transcribe_audio_file(audio_file, target_lang: str = "en") -> str:
    """Helper function to transcribe audio file using Whisper with a fixed language and optional translation"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp:
        shutil.copyfileobj(audio_file.file, tmp)
        temp_upload = tmp.name
    
    audio_path = None
    try:
        
        def convert_audio():
            audio = AudioSegment.from_file(temp_upload)
            audio = audio.set_frame_rate(16000).set_channels(1)
            converted_path = temp_upload.replace('.tmp', '_converted.wav')
            audio.export(converted_path, format="wav")
            return converted_path
        
        audio_path = await asyncio.to_thread(convert_audio)
        os.unlink(temp_upload)  # Clean up the temporary file
        languages_data = load_language_mapping()
        normalized_target = languages_data.get(target_lang.lower(), target_lang.lower()) if target_lang else "en"
        
        segments, info = await asyncio.to_thread(_whisper_model.transcribe, audio_path, word_timestamps=True, language=normalized_target, task="transcribe")
        
        user_text = " ".join([seg.text for seg in segments]).strip()
        
        detected_lang = normalized_target  # We're using the target_lang directly
        logger.debug(f"Transcribed with forced language: {detected_lang}, target: {normalized_target}")
        
        if user_text and detected_lang != normalized_target:
            try:
                translated = await asyncio.to_thread(
                    GoogleTranslator(source=detected_lang, target=normalized_target).translate,
                    user_text
                )
                if translated:
                    logger.debug(f"Translated from {detected_lang} to {normalized_target}: {user_text[:50]} -> {translated[:50]}")
                    user_text = translated
            except Exception as e:
                logger.debug(f"Translation to {normalized_target} failed: {e}")
        
        print(user_text)
        print(len(user_text))
        return user_text
    except Exception as e:
        logger.debug(f"Audio transcription failed: {e}")
        return ""
    finally:
        for path in [temp_upload, audio_path]:
            if path and os.path.exists(path):
                try:
                    os.unlink(path)
                except Exception as delete_error:
                    logger.warning(f"Failed to delete file {path}: {delete_error}")

SCENARIO_KEYWORDS = {
    "restaurant": "ordering_food", "food": "ordering_food", "eat": "ordering_food", "menu": "ordering_food",
    "hotel": "hotel_checkin", "room": "hotel_checkin", "reservation": "hotel_checkin", "book": "hotel_checkin",
    "travel": "travel", "trip": "travel", "vacation": "travel", "airport": "travel", "flight": "travel",
    "shopping": "shopping", "buy": "shopping", "store": "shopping", "shop": "shopping",
    "work": "workplace", "office": "workplace", "job": "workplace", "meeting": "workplace", "colleague": "workplace",
    "doctor": "medical", "hospital": "medical", "health": "medical", "sick": "medical",
    "phone": "phone_call", "call": "phone_call", "appointment": "phone_call",
    "direction": "asking_directions", "lost": "asking_directions", "way": "asking_directions", "find": "asking_directions",
    "introduce": "self_introduction", "myself": "self_introduction", "about me": "self_introduction",
    "casual": "casual_conversation", "chat": "casual_conversation", "talk": "casual_conversation", "friend": "casual_conversation",
    "daily": "daily_routine", "everyday": "daily_routine", "routine": "daily_routine"
}


async def extract_scenario_from_text(user_text: str, model: str = "gpt") -> dict:
    """Extract conversation scenario from natural language using fuzzy matching + LLM"""
    user_lower = user_text.lower()
    
    
    for keyword, scenario in SCENARIO_KEYWORDS.items():
        if keyword in user_lower:
            return {"success": True, "scenario": scenario, "confidence": "high"}
    
    
    prompt = f"""Extract the conversation practice scenario from: "{user_text}"

IMPORTANT: Accept ANY topic the user mentions for conversation practice.
Examples: ordering food, hotel check-in, shopping, making appointments, casual talk, daily routine, travel, work, etc.

If user mentions ANY topic, extract and format it:
- Return: {{"success": true, "scenario": "extracted_scenario_in_lowercase", "confidence": "high"}}
- Example: "I want to practice ordering food" Ã¢â€ â€™ {{"success": true, "scenario": "ordering_food", "confidence": "high"}}
- Example: "let's talk about travel" Ã¢â€ â€™ {{"success": true, "scenario": "travel", "confidence": "high"}}

If completely unclear:
- Return: {{"success": false, "scenario": "casual_conversation", "confidence": "low"}}

Return ONLY valid JSON."""
    
    try:
        raw = await call_llm(prompt, mode="strict_json", timeout=10, model=model)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            result = json.loads(json_match.group())
            if result.get("scenario"):
                result["success"] = True
            return result
    except Exception:
        pass
    return {"success": True, "scenario": "casual_conversation", "confidence": "low"}


async def extract_level_from_text(user_text: str, model: str = "gpt") -> dict:
    """Extract language level from natural language - returns CEFR codes (B1, B2, C1, C2)"""
    user_lower = user_text.lower()
    
    
    for keyword, level in LEVEL_KEYWORDS.items():
        if keyword in user_lower:
            return {"success": True, "level": level, "confidence": "high"}
    
    
    cefr_codes = {
        "b1": "B1", "b2": "B2",
        "c1": "C1", "c2": "C2"
    }
    for cefr, level in cefr_codes.items():
        if cefr in user_lower:
            return {"success": True, "level": level, "confidence": "high"}
    
    
    prompt = f"""Extract the language proficiency level from: "{user_text}"

Map to these CEFR codes ONLY (B1 is the minimum, no A1/A2):
- B1 (Beginner): Can handle familiar situations, routine conversations
- B2 (Intermediate): Independent user, can discuss abstract topics
- C1 (Advanced): Fluent, can express complex ideas spontaneously
- C2 (Proficient): Native-like mastery, nuanced and precise

Return: {{"success": true, "level": "B2", "confidence": "high"}}
If unclear, default to B2: {{"success": true, "level": "B2", "confidence": "low"}}

Return ONLY valid JSON."""
    
    try:
        raw = await call_llm(prompt, mode="strict_json", timeout=10, model=model)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            return json.loads(json_match.group())
    except Exception:
        pass
    return {"success": True, "level": "B2", "confidence": "low"}


async def generate_context_aware_follow_up(user_response: str, chat_history: list, scenario: str, user_type: str, model: str = "gpt", target_language: str = "en") -> tuple:
    """Generate context-aware follow-up question with natural transitions"""
    
    recent_chat = chat_history[-6:] if chat_history else []
    chat_context = "\n".join([f"{msg['role'].upper()}: {msg['content']}" for msg in recent_chat])
    
    prompt = f"""You are {BOT_NAME}, a warm and friendly language tutor practicing {scenario} conversations.

CONVERSATION SO FAR:
{chat_context}

The learner just said: "{user_response}"

IMPORTANT RULES:
1. YOU (the bot) ALWAYS ask the questions
2. The USER ALWAYS answers/responds
3. This is a REAL CHAT - remember everything from the conversation
4. Start with an interactive reaction to their answer (be specific!)
5. Then ask a follow-up question they can ANSWER
6. NEVER ask them to ask YOU something
7. NEVER repeat questions already asked

Return STRICTLY valid JSON:
{{"question": "[your interactive reaction + follow-up question for user to answer]", "hint": "[example response they could give]"}}"""

    try:
        raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("question", "Tell me more about that."), data.get("hint", "Share more details.")
    except Exception:
        pass
    return "Tell me more about that.", "Share more details."


async def generate_retry_encouragement(scenario: str, retry_count: int, previous_score: int, user_name: str = "there", model: str = "gpt", target_language: str = "en") -> str:
    """Generate friendly, encouraging retry message using LLM"""
    prompt = f"""You are a warm, encouraging language tutor.

Context:
- Student: {user_name}
- Scenario: {scenario}
- Previous score: {previous_score}%
- Retry attempt: 

Generate a SHORT (1-2 sentences) encouraging message for retrying. Be:
- Warm and supportive (like a friend, not a teacher)
- Specific about the scenario if possible
- Use an emoji occasionally 
- Never make them feel bad about their score

Examples:
- "No worries! Let's give it another shot. Take a deep breath and try again! Ã°Å¸â€™Âª"
- "You've got this! Practice makes perfect. Let's try once more."
- "Great attitude wanting to improve! Ready when you are Ã°Å¸ËœÅ "

Return ONLY the message, no JSON."""
    
    try:
        msg = await call_llm(prompt, timeout=10, model=model, target_language=target_language)
        if msg and len(msg) < 200:  
            return msg.strip('\"\'')
    except Exception:
        pass
    
    
    fallbacks = [
        f"No problem, {user_name}! Let's try this again. Take your time! Ã°Å¸â€™Âª",
        "Great attitude! Practice makes perfect. Ready when you are Ã°Å¸ËœÅ ",
        "You've got this! Let's give it another shot.",
        "No worries! Take a breath and try again. I believe in you!"
    ]
    import random
    fallback_msg = random.choice(fallbacks)
    if target_language.lower() not in ["en", "english"]:
        return await translate_text(fallback_msg, "en", target_language)
    return fallback_msg


async def generate_skip_message(scenario: str, user_name: str = "there", model: str = "gpt", target_language: str = "en") -> str:
    """Generate friendly skip/transition message using LLM"""
    prompt = f"""You are a warm, friendly language tutor.

The student {user_name} wants to skip to the next question in {scenario} practice.

Generate a SHORT (1 sentence) friendly transition message that:
- Doesn't make them feel bad for skipping
- Keeps energy positive
- Maybe adds a small emoji

Examples:
- "Absolutely! Let's move on to something fresh Ã¢Å“Â¨"
- "Sure thing! Here's a new one for you."
- "No problem! Let's try a different question."

Return ONLY the message, no JSON."""
    
    try:
        msg = await call_llm(prompt, timeout=8, model=model, target_language=target_language)
        if msg and len(msg) < 150:
            return msg.strip('\"\'')
    except Exception:
        pass
    fallback_msg = "No problem! Let's try something new Ã°Å¸ËœÅ "
    if target_language.lower() not in ["en", "english"]:
        return await translate_text(fallback_msg, "en", target_language)
    return fallback_msg


async def analyze_grammar_llm(user_text: str, level: str = "Intermediate", user_type: str = "student", model: str = "gpt", target_language: str = "en") -> dict:
    """llm-based grammar analysis for spoken language with detailed suggestions"""
    
    level_context = ""
    if level == "Beginner":
        level_context = f"User is at Beginner level. Focus on basic grammar errors and simple corrections."
    elif level == "Intermediate":
        level_context = f"User is at Intermediate level. Check for intermediate grammar issues and provide detailed explanations."
    elif level == "Advanced":
        level_context = f"User is at Advanced level. Focus on subtle grammar nuances and advanced corrections."
    else:
        level_context = f"User is at Proficient level. Focus on native-like polish and professional refinement."
    
    user_type_context = ""
    if user_type == "professional":
        user_type_context = "This is a professional user. Provide business-appropriate grammar feedback."
    elif user_type == "student":
        user_type_context = "This is a student. Provide educational grammar feedback with clear explanations."
    
    # Language instruction for response
    lang_lower = target_language.lower() if target_language else "en"
    is_english = lang_lower in ["en", "english"]
    lang_instruction = f"IMPORTANT: Provide ALL feedback, explanations, and suggestions in {target_language} language." if not is_english else ""
    
    # Get language-specific grammar rules
    lang_rules = get_language_rules(target_language)
    lang_rules_text = ""
    if lang_rules:
        grammar_rules = lang_rules.get("grammar", {})
        common_errors = grammar_rules.get('common_errors', [])
        error_lines = []
        for e in common_errors:
            tip = f" (Tip: {e.get('tip', '')})" if e.get('tip') else ""
            error_lines.append(f"      * {e.get('error', '')}: {e.get('example', '')}{tip}")
        
        lang_rules_text = f"""
    LANGUAGE-SPECIFIC REFERENCE GUIDELINES FOR {lang_rules.get('name', target_language).upper()}:
    (Use these as REFERENCE - adapt based on actual user text, not strict rules)
    
    - Word Order: {grammar_rules.get('word_order', '')}
    - Articles: {grammar_rules.get('articles', []) if grammar_rules.get('articles') else 'No articles in this language'}
    - Cases: {grammar_rules.get('cases', grammar_rules.get('case_suffixes', 'N/A'))}
    - Verb Conjugation: {grammar_rules.get('verb_conjugation', '')}
    - Special Rules: {grammar_rules.get('special_rules', [])}
    - Common Errors to Watch For:
{chr(10).join(error_lines)}
    
    NOTE: These are reference patterns. Focus on what's actually wrong in the user's text, not forcing all these checks.
    """
    
    prompt = f"""
    Analyze grammar in this SPOKEN text: "{user_text}"
    
    USER CONTEXT:
    - Level: {level} (adapt complexity of explanations accordingly)
    - User Type: {user_type} (make feedback relevant to their context)
    - Target Language: {target_language}
    
    {lang_instruction}
    {lang_rules_text}
    
    Based on the user's level and type, provide appropriate feedback.
    
    CRITICAL: This is transcribed speech. IGNORE:
    - Punctuation/capitalization/spelling errors
    
    CHECK for:
    1. Filler words (um, uh, like, you know)
    2. Wrong prepositions
    3. Wrong verb tense
    4. Subject-verb agreement
    5. Missing/wrong articles
    6. Word order issues
    7. Missing words
    8. Weak vocabulary
    
    Return STRICTLY valid JSON:
    {{
      "score": 0-100,
      "is_correct": true/false,
      "filler_words": ["um", "like"],
      "filler_count": 0,
      
      "you_said": "{user_text}",
      "you_should_say": "the grammatically correct version",
      
      "errors": [
        {{
          "type": "verb_tense/preposition/article/subject_verb/word_order/missing_word",
          "you_said": "I goed to store",
          "should_be": "I went to the store",
          "wrong_word": "goed",
          "correct_word": "went",
          "explanation": "Go is irregular - past tense is went, not goed",
          "example_sentence": "Yesterday, I went to the park with my friends."
        }}
      ],
      
      "word_suggestions": [
        {{"you_used": "good", "use_instead": "excellent", "why": "more impactful for {user_type}", "example": "The food was excellent."}}
      ],
      
      "corrected_sentence": "sentence with grammar fixed",
      "improved_sentence": "more natural version with better words",
      "feedback": "2-3 specific sentences about their grammar, tailored to {level} level and {user_type} context"
    }}
    
    RULES:
    - Tailor feedback complexity to {level} level
    - Make suggestions relevant for {user_type}
    - For EACH error, show: you_said, should_be, wrong_word, correct_word
    - Include example_sentence showing correct usage
    - Empty arrays [] if no issues
    - ALL text feedback must be in {target_language} language

    ### TAGGING RULES (MANDATORY)
    - Use #word# format for every correction token.
    - Never leave correction tokens untagged.

    For each item in "errors":
    - "you_said" must include #wrong_word#
    - "should_be" must include #correct_word#
    - "wrong_word" must match the tagged wrong token in "you_said"
    - "correct_word" must match the tagged correct token in "should_be"
    - Tag only the exact changed token(s), not the full sentence.

    For each item in "word_suggestions":
    - If "you_used" appears in a phrase/sentence, mark it as #you_used# in that phrase.
    - If "use_instead" appears in a phrase/sentence, mark it as #use_instead# in that phrase.
    - Keep tags on exact replaced token(s).

    If multiple corrections exist, tag at least the primary corrected token for each item.
    """
    try:
        raw = await call_llm(prompt, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            if isinstance(data, dict):
                if not data.get("improved_sentence"):
                    data["improved_sentence"] = data.get("corrected_sentence", user_text)
                
                
                if "errors" in data and isinstance(data["errors"], list):
                    cleaned_errors = []
                    for error in data["errors"]:
                        if isinstance(error, dict):
                            
                            error_type = error.get("type", "").lower()
                            if error_type in ["punctuation", "capitalization", "spelling", "typo"]:
                                continue
                            
                            
                            if not error.get("better_word"):
                                error.pop("better_word", None)
                                error.pop("explanation", None)
                            cleaned_errors.append(error)
                    data["errors"] = cleaned_errors
                
                return data
    except Exception as e:
        logger.debug(f"Grammar analysis fallback: {e}")
    word_count = len(user_text.split())
    return {
        "score": 70, "is_correct": True, "filler_words": [], "filler_count": 0,
        "you_said": user_text, "you_should_say": user_text, "errors": [],
        "word_suggestions": [], "corrected_sentence": user_text, "improved_sentence": user_text,
        "feedback": f"Analyzed {word_count} words. No major grammatical issues detected."
    }


async def analyze_vocab_llm(user_text: str, user_type: str = "student", level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
    """llm-based vocabulary analysis with cefr levels and percentages"""
    
    level_context = ""
    if level == "Beginner":
        level_context = "User is at Beginner level. Suggest simple vocabulary improvements."
    elif level == "Intermediate":
        level_context = "User is at Intermediate level. Suggest intermediate-level vocabulary enhancements."
    elif level == "Advanced":
        level_context = "User is at Advanced level. Suggest sophisticated vocabulary alternatives."
    else:
        level_context = "User is at Proficient level. Suggest native-like vocabulary refinements."
    
    user_type_context = ""
    if user_type == "professional":
        user_type_context = "This is a professional user. Suggest business-appropriate vocabulary."
    elif user_type == "student":
        user_type_context = "This is a student. Suggest academic-appropriate vocabulary."
    
    # Language instruction for response
    lang_lower = target_language.lower() if target_language else "en"
    is_english = lang_lower in ["en", "english"]
    lang_instruction = f"IMPORTANT: Provide ALL feedback, explanations, and suggestions in {target_language} language." if not is_english else ""
    
    # Get language-specific vocabulary rules
    lang_rules = get_language_rules(target_language)
    lang_rules_text = ""
    if lang_rules:
        vocab_rules = lang_rules.get("vocabulary", {})
        # Build detailed vocab features
        features = []
        for k, v in vocab_rules.items():
            if k != 'formality_levels':
                features.append(f"    - {k.replace('_', ' ').title()}: {v}")
        
        lang_rules_text = f"""
    LANGUAGE-SPECIFIC VOCABULARY REFERENCE FOR {lang_rules.get('name', target_language).upper()}:
    (Use as GUIDANCE - these are typical patterns, not strict requirements)
    
    - Formality Levels: {vocab_rules.get('formality_levels', [])}
{chr(10).join(features)}
    
    NOTE: Consider these cultural/linguistic features when evaluating vocabulary, but base your analysis on the actual words used.
    """
    
    prompt = f"""
    Analyze vocabulary CEFR levels for: "{user_text}"
    
    USER CONTEXT:
    - Level: {level} (tailor suggestions to this level)
    - User Type: {user_type} (make suggestions relevant to their context)
    - Target Language: {target_language}
    
    {lang_instruction}
    {lang_rules_text}
    CRITICAL - YOU MUST FIND AND SUGGEST IMPROVEMENTS FOR WEAK/BASIC WORDS:
    Scan the transcription above and identify ANY of these weak words:
    - good, nice, bad, thing, things, stuff
    - do, did, does, doing, done
    - get, got, gets, getting  
    - make, made, makes, making
    - very, really, pretty, quite
    - big, small, little, a lot
    - said, told, asked
    - went, go, goes, going
    - want, wanted, need, needed
    - like, liked, think, thought

    For EACH weak word found, you MUST add a suggestion in the suggestions array.

    SPELLING ERRORS:
    If a word is MISSPELLED (e.g., "awareded", "recieved", "definately"):
    - Set current_level = "spelling_error"
    - Set better_word = correct spelling

    CRITICAL FORMATTING FOR SUGGESTIONS - MUST USE # MARKERS:
    - original_sentence: Copy the EXACT sentence from transcription containing the weak word, mark it with #word#
    - improved_sentence: Same sentence with better word, mark it with #better_word#
    - ALWAYS use # on both sides of the word
    - Example: original_sentence: "The food was #good#" Ã¢â€ â€™ improved_sentence: "The food was #excellent#"

    Return STRICTLY valid JSON:
    {{
      "score": 0-100,
      "overall_level": "A1/A2/B1/B2/C1/C2",
      "total_words": <word count>,
      "cefr_distribution": {{
        "A1": {{"percentage": 20, "words": ["I", "is"]}},
        "A2": {{"percentage": 30, "words": ["name", "good"]}},
        "B1": {{"percentage": 40, "words": ["actually", "however"]}},
        "B2": {{"percentage": 10, "words": ["sophisticated"]}},
        "C1": {{"percentage": 0, "words": []}},
        "C2": {{"percentage": 0, "words": []}}
      }},
      "feedback": "vocabulary feedback tailored to {level} level and {user_type} context",
      "suggestions": [
        {{"word": "good", "current_level": "A2", "better_word": "excellent", "suggested_level": "B1", "context": "appropriate for {user_type}"}},
        {{"word": "awareded", "current_level": "spelling_error", "better_word": "awarded", "suggested_level": "B1", "context": "correct spelling"}}
      ]
    }}
    
    IMPORTANT:
    - For MISSPELLED words: current_level = "spelling_error", better_word = correct spelling
    - Tailor suggestions to {level} level (don't suggest C1 words to A1 learners)
    - Make suggestions relevant for {user_type} context
    - ALL text feedback must be in {target_language} language

    ### TAGGING RULES (MANDATORY)
    - Keep the existing response structure exactly as defined.
    - Use #word# format when showing replacement context.

    For each item in "suggestions":
    - "word" is the weak/misspelled token.
    - "better_word" is the improved/correct token.
    - In the "context" text, include one short before->after example using tags:
      - weak token as #word#
      - improved token as #better_word#
    - Example context style:
      "Use in sentence: The result was #good# -> The result was #excellent#"

    If multiple replacements exist, provide tagged context for at least the primary replacement.
    Never provide untagged replacement examples in context.
    """
    for attempt in range(3):
        try:
            raw = await call_llm(prompt, model=model, target_language=target_language)
            json_match = re.search(r'\{[\s\S]*\}', raw)
            if json_match:
                data = json.loads(json_match.group())
                if isinstance(data, dict):
                    
                    default_cefr = {
                        "A1": {"percentage": 0, "words": []}, "A2": {"percentage": 0, "words": []},
                        "B1": {"percentage": 0, "words": []}, "B2": {"percentage": 0, "words": []},
                        "C1": {"percentage": 0, "words": []}, "C2": {"percentage": 0, "words": []}
                    }
                    if "cefr_distribution" not in data or not isinstance(data.get("cefr_distribution"), dict):
                        data["cefr_distribution"] = default_cefr
                    else:
                        
                        for level_key in default_cefr:
                            if level_key not in data["cefr_distribution"]:
                                data["cefr_distribution"][level_key] = default_cefr[level_key]
                            elif not isinstance(data["cefr_distribution"][level_key], dict):
                                data["cefr_distribution"][level_key] = default_cefr[level_key]
                            else:
                                
                                if "percentage" not in data["cefr_distribution"][level_key]:
                                    data["cefr_distribution"][level_key]["percentage"] = 0
                                if "words" not in data["cefr_distribution"][level_key]:
                                    data["cefr_distribution"][level_key]["words"] = []
                    return data
        except json.JSONDecodeError as e:
            logger.warning(f"[analyze_vocab_llm] JSON parse error (attempt {attempt+1}/3): {e}")
            continue  
        except Exception as e:
            logger.error(f"[analyze_vocab_llm] Error: {e}")
            break  
    
    return {
        "score": 70, "overall_level": "B1", "total_words": 0,
        "cefr_distribution": {
            "A1": {"percentage": 0, "words": []}, "A2": {"percentage": 0, "words": []},
            "B1": {"percentage": 0, "words": []}, "B2": {"percentage": 0, "words": []},
            "C1": {"percentage": 0, "words": []}, "C2": {"percentage": 0, "words": []}
        },
        "feedback": "", "suggestions": []
    }
async def analyze_pronunciation_llm(audio_path: str = None, spoken_text: str = None, level: str = "B1", user_type: str = "student", model: str = "gpt", target_language: str = "en") -> dict:
    """pronunciation analysis using Whisper word-level confidence to detect mispronounced words"""
    if not audio_path:
        return {
            "accuracy": 70, "transcription": spoken_text or "", 
            "word_pronunciation_scores": [],
            "words_to_practice": [], "well_pronounced_words": spoken_text.split() if spoken_text else [],
            "feedback": "No audio provided for pronunciation analysis",
            "tips": ["Record audio for pronunciation feedback"], 
            "mispronounced_count": 0, "level": level, "user_type": user_type
        }
    
    try:
        target_lang = target_language.lower()
        languages_data = load_language_mapping()
        normalized_target = languages_data.get(target_lang, target_lang) if target_lang in languages_data else target_lang

        async def _transcribe_pronunciation(lang_hint: str = None):
            kwargs = {"word_timestamps": True}
            if lang_hint:
                kwargs["language"] = lang_hint
            segments, info = await asyncio.to_thread(_whisper_model.transcribe, audio_path, **kwargs)
            detected = info.language if info else (lang_hint or "en")
            words = []
            text = ""
            for seg in segments:
                text += seg.text + " "
                if seg.words:
                    for w in seg.words:
                        words.append({
                            "word": w.word.strip().lower(),
                            "confidence": w.probability,
                            "start": w.start,
                            "end": w.end
                        })
            return text.strip(), words, detected

        # Always force transcription in target language (auto-detect often gets wrong language)
        transcription, words_data, detected_lang = await _transcribe_pronunciation(normalized_target)
        logger.debug(f"Pronunciation - Whisper transcribed in {normalized_target}: {transcription[:100] if transcription else 'empty'}")

        # Keep original transcription for word scores alignment
        original_transcription = transcription
        translated_transcription = None

        # Only translate if detected language doesn't match target (keep original for word scores)
        if transcription and detected_lang != normalized_target:
            try:
                translated = await asyncio.to_thread(
                    GoogleTranslator(source=detected_lang, target=normalized_target).translate,
                    transcription
                )
                if translated:
                    logger.debug(f"Pronunciation: Translated from {detected_lang} to {normalized_target}")
                    translated_transcription = translated
            except Exception as e:
                logger.debug(f"Pronunciation translation failed: {e}")

        display_transcription = translated_transcription or original_transcription
        
        if not words_data:
            return {
                "accuracy": 0, "transcription": display_transcription, 
                "word_pronunciation_scores": [],
                "words_to_practice": [], "well_pronounced_words": [],
                "feedback": "No speech detected in audio",
                "tips": ["Speak clearly into the microphone"], 
                "mispronounced_count": 0, "level": level, "user_type": user_type,
                "original_transcription": original_transcription,
                "translated_transcription": translated_transcription,
                "detected_language": detected_lang,
                "target_language": normalized_target
            }
        
        CONFIDENCE_THRESHOLD = 0.70
        
        mispronounced_words = []
        well_pronounced = []
        all_words_pronunciation = []  
        
        for wd in words_data:
            word = wd["word"].strip(".,!?")
            if len(word) < 2:  
                continue
            
            pronunciation_percentage = round(wd["confidence"] * 100, 1)
            
            if pronunciation_percentage >= 90:
                status = "excellent"
            elif pronunciation_percentage >= 70:
                status = "good"
            elif pronunciation_percentage >= 50:
                status = "needs_improvement"
            else:
                status = "poor"
            
            all_words_pronunciation.append({
                "word": word,
                "pronunciation_percentage": pronunciation_percentage,
                "status": status
            })
                
            if wd["confidence"] < CONFIDENCE_THRESHOLD:
                mispronounced_words.append({
                    "word": word,
                    "confidence": round(wd["confidence"] * 100, 1),
                    "issue": "unclear pronunciation" if wd["confidence"] < 0.5 else "slight pronunciation issue"
                })
            else:
                well_pronounced.append(word)
        
        if words_data:
            avg_confidence = sum(w["confidence"] for w in words_data) / len(words_data)
            accuracy = int(avg_confidence * 100)
        else:
            accuracy = 70
        
        # Get language-specific pronunciation rules
        lang_rules = get_language_rules(target_language)
        lang_pron_text = ""
        if lang_rules:
            pron_rules = lang_rules.get("pronunciation", {})
            lang_pron_text = f"""
LANGUAGE-SPECIFIC PRONUNCIATION RULES FOR {lang_rules.get('name', target_language).upper()}:
- Stress Pattern: {pron_rules.get('stress_pattern', '')}
- Difficult Sounds: {pron_rules.get('difficult_sounds', [])}
- Special Features: {', '.join([f'{k}: {v}' for k, v in pron_rules.items() if k not in ['stress_pattern', 'difficult_sounds']])}

Use these rules when analyzing pronunciation for this language."""
        
        llm_prompt = f"""You are a pronunciation coach.

USER CONTEXT:
- Level: {level}
- User Type: {user_type}
- Target Language: {target_language}
{lang_pron_text}

TRANSCRIPTION: "{transcription}"

PER-WORD PRONUNCIATION SCORES (confidence-based):
{all_words_pronunciation}

MISPRONOUNCED WORDS (low confidence from speech recognition):
{mispronounced_words if mispronounced_words else "None - all words were clear!"}

WELL PRONOUNCED WORDS: {well_pronounced[:10]}

OVERALL ACCURACY: {accuracy}%

For each word, analyze their pronunciation percentage and provide specific guidance.

Return STRICTLY valid JSON:
{{
    "word_analysis": [
        {{
            "word": "the word",
            "pronunciation_match": 85.5,
            "rating": "excellent/good/needs_improvement/poor",
            "phonetic_guide": "how to pronounce: ex-AM-ple",
            "improvement_tip": "specific tip if needed, or null if pronunciation is good"
        }}
    ],
    "words_to_practice": [
        {{
            "word": "the word",
            "how_to_say": "syllable breakdown with stress: ex-AM-ple",
            "tip": "specific tip to pronounce this word better"
        }}
    ],
    "well_pronounced_words": ["word1", "word2"],
    "feedback": "2-3 encouraging sentences about their pronunciation",
    "tips": ["general pronunciation tip 1", "general tip 2"]
}}"""

        try:
            llm_response = await call_llm(llm_prompt, mode="strict_json", timeout=30, model=model, target_language=target_language)
            json_match = re.search(r'\{[\s\S]*\}', llm_response)
            if json_match:
                llm_data = json.loads(json_match.group())
            else:
                raise ValueError("No JSON")
        except Exception as llm_error:
            logger.error(f"LLM pronunciation error: {llm_error}")
            
            llm_data = {
                "words_to_practice": [
                    {
                        "word": w["word"],
                        "how_to_say": f"Say '{w['word']}' more clearly",
                        "tip": f"Confidence was {w['confidence']}%. Speak slower and clearer."
                    } for w in mispronounced_words[:5]
                ],
                "well_pronounced_words": well_pronounced[:5],
                "feedback": f"Pronunciation accuracy: {accuracy}%. " + (
                    f"Focus on: {', '.join([w['word'] for w in mispronounced_words[:3]])}" 
                    if mispronounced_words else "Great clarity!"
                ),
                "tips": ["Speak slowly and clearly", "Stress syllables properly"]
            }
        
        llm_word_analysis = llm_data.get("word_analysis", [])
        
        word_pronunciation_scores = []
        llm_analysis_map = {w.get("word", "").lower(): w for w in llm_word_analysis}
        
        for wp in all_words_pronunciation:
            word_key = wp["word"].lower()
            llm_info = llm_analysis_map.get(word_key, {})
            word_pronunciation_scores.append({
                "word": wp["word"],
                "pronunciation_match_percentage": wp["pronunciation_percentage"],
                "status": wp["status"],
                "phonetic_guide": llm_info.get("phonetic_guide", ""),
                "improvement_tip": llm_info.get("improvement_tip", "")
            })
        
        return {
            "accuracy": accuracy, 
            "transcription": display_transcription,
            "original_transcription": original_transcription,
            "translated_transcription": translated_transcription,
            "detected_language": detected_lang,
            "target_language": normalized_target,
            "word_pronunciation_scores": word_pronunciation_scores,
            "words_to_practice": llm_data.get("words_to_practice", []),
            "well_pronounced_words": llm_data.get("well_pronounced_words", well_pronounced),
            "feedback": llm_data.get("feedback", "Analysis complete."),
            "tips": llm_data.get("tips", []),
            "mispronounced_count": len(mispronounced_words),
            "confidence_data": [{"word": w["word"], "confidence": w["confidence"]} for w in mispronounced_words],
            "level": level, 
            "user_type": user_type
        }
        
    except Exception as e:
        logger.error(f"Pronunciation error: {e}")
        return {
            "accuracy": 70, "transcription": spoken_text or "", 
            "word_pronunciation_scores": [],
            "words_to_practice": [], "well_pronounced_words": [],
            "feedback": f"Could not analyze pronunciation: {str(e)}",
            "tips": ["Ensure clear audio recording"],
            "mispronounced_count": 0,
            "level": level, "user_type": user_type
        }

async def generate_question_llm(level: str, scenario: str, user_name: str, target_lang: str, model: str = "gpt") -> tuple:
    """generate question and hint"""
    prompt = f"""You are a friendly {BOT_ROLE} helping {user_name} practice {scenario.replace('_', ' ')} conversations.

IMPORTANT RULES:
- YOU (the bot) ALWAYS ask the questions
- The USER ({user_name}) ALWAYS answers/responds
- Play the appropriate role for the scenario (staff, interviewer, shopkeeper, receptionist, etc.)
- The user plays the customer/guest/interviewee role
- Keep language at {target_lang} conversational level.
-response always in {target_lang} language.

SCENARIO: {scenario}
USER LEVEL: {level}

LEVEL GUIDELINES (B1 minimum - no A1/A2):
- B1: Can handle familiar situations, routine conversations, basic opinions
- B2: Independent user, can discuss abstract topics, argue a viewpoint
- C1: Fluent, can express complex ideas spontaneously, varied vocabulary
- C2: Native-like mastery, nuanced, sophisticated, precise

Generate a {level}-appropriate conversation starter for {scenario}.

Return JSON:
{{"question": "[your question to the user]", "hint": "[example response the user could give at {level} level]"}}"""
    try:
        raw = await call_llm(prompt, model=model, target_language=target_lang)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("question", "How can I help you today?"), data.get("hint", "")
    except Exception:
        pass
    return "How can I help you today?", "For example: I would like..."


async def generate_follow_up_llm(user_response: str, target_lang: str, chat_history: list, model: str = "gpt") -> tuple:
    """generate follow-up question and hint - more interactive and friendly"""
    
    recent_chat = chat_history[-6:] if chat_history else []
    chat_context = "\n".join([f"{msg['role'].upper()}: {msg['content']}" for msg in recent_chat])
    
    prompt = f"""You are a warm, friendly language tutor having a REAL conversation.

CONVERSATION SO FAR:
{chat_context}

User just said: "{user_response}"
- Keep language at {target_lang} conversational level.
-question and hint should be in {target_lang} language.


IMPORTANT RULES:
1. This is a REAL CHAT - remember everything from the conversation above
2. Your response should FLOW NATURALLY from what was discussed  
3. FIRST react to what they said (be specific - mention THEIR words!)
4. THEN ask a follow-up that RELATES to the conversation
5. Make it feel like chatting with a friend, not an interview
6. NEVER ask random unrelated questions
7. NEVER repeat questions already asked

GOOD EXAMPLES:
- If they ordered pasta: "Ooh pasta lover! Ã°Å¸ÂÂ What sauce do you usually go for?"
- If they said they like movies: "Nice! I love movies too. What genre is your favorite?"
- If they're at a hotel: "Great choice of hotel! Is this your first time visiting?"

BAD EXAMPLES (DON'T DO):
- Generic: "That's nice. What else?" (boring, not specific)
- Random: "What's your favorite sport?" (unrelated to context)

Keep language at {target_lang} conversational level.

Return JSON:
{{
    "question": "[your specific reaction] + [contextual follow-up question]",
    "hint": "Example: [sample answer they could give]"
}}"""
    try:
        raw = await call_llm(prompt, model=model, target_language=target_lang)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("question", "That's interesting! Tell me more."), data.get("hint", "Share more details.")
    except Exception:
        pass
    return "That's interesting! Tell me more about that.", "You can share more details or ask me something."


async def generate_personalized_feedback(user_type: str, overall_score: float, scores: dict, user_text: str = "",
                                          grammar: dict = None, vocabulary: dict = None,
                                          pronunciation: dict = None, model: str = "gpt", target_language: str = "en") -> dict:
    """Generate personalized feedback using LLM based on actual errors detected"""
    
    
    grammar_errors = grammar.get("errors", []) if grammar else []
    filler_words = grammar.get("filler_words", []) if grammar else []
    word_suggestions = grammar.get("word_suggestions", []) if grammar else []
    vocab_suggestions = vocabulary.get("suggestions", []) if vocabulary else []
    mispronounced = pronunciation.get("words_to_practice", []) if pronunciation else []
    
    
    errors_context = []
    if grammar_errors:
        errors_context.append(f"Grammar errors: {[e.get('you_said', '') + ' Ã¢â€ â€™ ' + e.get('should_be', '') for e in grammar_errors[:3]]}")
    if filler_words:
        errors_context.append(f"Filler words used: {filler_words[:5]}")
    if word_suggestions:
        errors_context.append(f"Weak words: {[w.get('weak_word', w.get('you_used', '')) for w in word_suggestions[:3]]}")
    if vocab_suggestions:
        errors_context.append(f"Vocabulary improvements: {[v.get('word', '') + ' Ã¢â€ â€™ ' + v.get('better_word', '') for v in vocab_suggestions[:3]]}")
    if mispronounced:
        errors_context.append(f"Pronunciation to practice: {[w.get('word', '') if isinstance(w, dict) else w for w in mispronounced[:3]]}")
    
    improvement_areas = []
    strengths = []
    perfect_areas = []
    
    
    for area, score in scores.items():
        if score is None:  
            continue
        if score >= 90:
            perfect_areas.append(area)
            strengths.append(area)
        elif score >= 75:
            strengths.append(area)
        elif score < 60:
            improvement_areas.append(area)
    
    emotion = detect_emotion(user_text)
    
    emotion_guidance = ""
    if emotion == "nervous":
        emotion_guidance = "The user seems NERVOUS. Be extra encouraging, gentle, and reassuring."
    elif emotion == "excited":
        emotion_guidance = "The user seems EXCITED. Match their energy and celebrate their effort."
    else:
        emotion_guidance = "The user seems calm/neutral. Provide balanced, constructive feedback."
    
    # Language instruction for response
    lang_lower = target_language.lower() if target_language else "en"
    is_english = lang_lower in ["en", "english"]
    lang_instruction = f"IMPORTANT: Write ALL feedback content (message, perfect_feedback, quick_tip, emotion_response) in {target_language} language. Keep JSON field names in English, only translate the VALUES." if not is_english else ""
    
    feedback_prompt = f"""You are a warm, friendly language buddy (like a supportive friend) providing personalized feedback.

USER PROFILE:
- Type: {user_type}
- Overall Score: {overall_score}/100
- Scores: Grammar={scores.get('grammar', 70)}, Vocabulary={scores.get('vocabulary', 70)}, Pronunciation={scores.get('pronunciation', 70)}, Fluency={scores.get('fluency', 70)}
- Strengths: {strengths if strengths else 'Building foundation'}
- Areas to Improve: {improvement_areas if improvement_areas else 'Minor refinements'}
- Perfect Scores: {perfect_areas if perfect_areas else 'None yet'}
- What they said: "{user_text[:150]}..."
- Detected Emotion: {emotion}

ACTUAL ERRORS DETECTED (use these for specific feedback):
{chr(10).join(errors_context) if errors_context else "No major errors detected!"}

{emotion_guidance}

{lang_instruction}

Generate a FRIENDLY, CASUAL response that feels like chatting with a supportive friend. Return STRICTLY valid JSON:
{{
    "message": "Start with a SHORT, WARM one-liner reaction (like 'Hey, nice job on that!' or 'Ooh, that was pretty good!' or 'Don't worry, you're getting there!' based on score). THEN 1-2 sentences of specific, encouraging feedback about their ACTUAL errors. Be conversational, use casual language!",
    "perfect_feedback": {{
        "pronunciation": "casual praise if pronunciation was perfect, else null",
        "grammar": "casual praise if grammar was perfect, else null",
        "vocabulary": "casual praise if vocabulary was perfect, else null",
        "fluency": "casual praise if fluency was perfect, else null"
    }},
    "quick_tip": "One friendly, actionable tip - say it like a friend would!",
    "emotion_response": "One warm sentence acknowledging how they might be feeling"
}}

TONE EXAMPLES for "message" based on score:
- Score >= 85: "Awesome! Ã°Å¸Å½â€° That was really well said! Your grammar was spot on, and..."
- Score 70-84: "Hey, nice effort! You're definitely improving. I noticed..."
- Score 50-69: "You're getting there! Don't stress, everyone struggles with..."
- Score < 50: "No worries at all! This is tricky stuff. Let's work on..."

RULES:
- ALWAYS start message with a friendly one-liner reaction
- Be like a supportive friend, NOT a formal teacher
- Use casual language (contractions like "you're", "don't", etc.)
- Reference ACTUAL errors, not generic advice
- Adapt tone based on detected emotion: {emotion}"""
    try:
        llm_response = await call_llm(feedback_prompt, mode="strict_json", timeout=20, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', llm_response)
        if json_match:
            llm_data = json.loads(json_match.group())
            message = llm_data.get("message", "")
            perfect_feedback = llm_data.get("perfect_feedback", {})
            quick_tip = llm_data.get("quick_tip", "")
            emotion_response = llm_data.get("emotion_response", "")
        else:
            raise ValueError("No valid JSON")
    except Exception:
        if overall_score >= 90:
            message = f"Impressive! You scored {overall_score}% with strong {', '.join(strengths[:2])}."
        elif overall_score >= 70:
            message = f"You're at {overall_score}%. Your {strengths[0] if strengths else 'overall communication'} is solid." + \
                     (f" Work on {improvement_areas[0]} to level up." if improvement_areas else "")
        else:
            message = f"You're building at {overall_score}%. Focus on {improvement_areas[0] if improvement_areas else 'fluency'} first."
        perfect_feedback = {area: f"Excellent {area}!" for area in perfect_areas}
        quick_tip = f"Practice your {improvement_areas[0] if improvement_areas else 'speaking'} daily."
        emotion_response = ""
    
    return {
        "user_type": user_type, "message": message, "improvement_areas": improvement_areas,
        "strengths": strengths, "perfect_areas": perfect_areas,
        "perfect_feedback": perfect_feedback, "quick_tip": quick_tip,
        "emotion": emotion, "emotion_response": emotion_response
    }


async def generate_session_summary_llm(user_name: str, scenario: str, final_scores: dict, 
                                       chat_history: list, total_turns: int, average_wpm: int, model: str = "gpt", target_language: str = "en") -> dict:
    """Generate elaborative LLM-based session summary"""
    
    
    strengths = [area for area, score in final_scores.items() if score is not None and score >= 80]
    weaknesses = [area for area, score in final_scores.items() if score is not None and score < 70]
    overall = int(sum(v for v in final_scores.values() if v is not None) / max(1, len([v for v in final_scores.values() if v is not None]))) if final_scores else 0
    
    prompt = f"""You are a supportive language coach providing a comprehensive session summary.

SESSION DATA:

- Student Name: {user_name}
- Scenario Practiced: {scenario}
- Total Turns: {total_turns}
- Final Scores: Grammar={final_scores.get('grammar', 0)}, Vocabulary={final_scores.get('vocabulary', 0)}, Pronunciation={final_scores.get('pronunciation', 0)}, Fluency={final_scores.get('fluency', 0)}
- Overall Score: {overall}/100
- Average WPM: {average_wpm}
- Strengths: {strengths if strengths else 'Building foundation'}
- Areas for Improvement: {weaknesses if weaknesses else 'Minor refinements'}

Recent conversation:
{json.dumps(chat_history[-6:], indent=2)}

Generate an encouraging, comprehensive session summary. Return STRICTLY valid JSON:
{{
    "summary": "3-4 sentence personalized summary of their session performance",
    "key_achievements": ["achievement 1", "achievement 2"],
    "focus_areas": ["specific area to focus on", "another focus area"],
    "next_steps": ["actionable next step 1", "actionable next step 2"],
    "encouragement": "1-2 sentences of motivation for next session"
}}

Be specific to their scenario ({scenario}) and reference their actual progress."""

    try:
        llm_content = await call_llm(prompt, mode="strict_json", timeout=25, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', llm_content)
        if json_match:
            return json.loads(json_match.group())
    except Exception:
        pass
    
    return {
        "summary": f"{user_name}, you completed {total_turns} turns practicing {scenario} with an overall score of {overall}%.",
        "key_achievements": [f"Strong {strengths[0]}" if strengths else "Completed conversation practice"],
        "focus_areas": weaknesses[:2] if weaknesses else ["Continue building vocabulary"],
        "next_steps": ["Practice daily for 10-15 minutes", f"Focus on {weaknesses[0] if weaknesses else 'pronunciation'}"],
        "encouragement": "Great effort! Consistency is key to language mastery."
    }


@router.post("/practice")
async def practice_fluent_lang(
    request: Request,
    name: str = Form(...),
    native_language: str = Form(...),
    target_language: str = Form(default="en"),
    level: Optional[str] = Form(default=None),  
    scenario: Optional[str] = Form(default=None),  
    user_type: str = Form(default="student"),
    audio_file: Optional[UploadFile] = File(default=None),
    text_input: Optional[str] = Form(default=None),
    session_id: Optional[str] = Form(default=None),
    skip_retry: bool = Form(default=False),
    model: Optional[str] = Form(default="gpt"),
    voice_id: Optional[str] = Form(default=None, description="Custom TTS voice ID (e.g., 'en-US-JennyNeural'). If not provided, auto-selects based on language."),
    current_user: User = Depends(get_current_user),
):
    """
    fluent language practice api - CONVERSATIONAL ONBOARDING
    
    flow:
    1. first call (no audio/text, no scenario/level): Bot greets and asks for scenario
    2. user provides scenario: Bot asks for level
    3. user provides level: practice begins with first question
    4. subsequent calls: normal practice with analysis
    5. termination phrase: ends session with summary
    """
    try:
        user_id = current_user.id if current_user else None
        audio_path = None
        user_text = ""
        
        if not session_id or session_id.strip() == "" or session_id == "string":
            session_id = str(uuid.uuid4())
        
        
        session = await db.get_user_session(session_id)
        session_exists = session is not None
        native_language = session.get("native_language", native_language) if session else native_language
        target_language = session.get("target_language", target_language) if session else target_language
        
        # Normalize language names to ISO codes (englishen, telugute)
        native_language = normalize_language_code(native_language, default="en")
        target_language = normalize_language_code(target_language, default="en")
        
        # Update session with normalized codes if they differ
        if session_exists:
            if session.get("native_language") != native_language or session.get("target_language") != target_language:
                session["native_language"] = native_language
                session["target_language"] = target_language
                await db.update_session(session_id, session)
        
        
        if session_exists and session.get("status") == "completed":
            error_msg = await translate_text("This session has ended. Please start a new conversation.", "en", native_language)
            return {"status": "error", "session_id": session_id, "error": error_msg}
        
        
        if not session_exists:
            
            
            if scenario:
                initial_state = "collecting_level"  
            else:
                initial_state = "welcome"  
            
            session = {
                "state": initial_state,
                "name": name, 
                "level": None,  
                "scenario": scenario,  
                "native_language": native_language, 
                "target_language": target_language,
                "user_type": user_type, 
                "chat_history": [],
                "scores": {"grammar": 0, "vocabulary": 0, "pronunciation": 0, "fluency": 0, "total_wpm": 0, "count": 0, "audio_count": 0},
                "current_question": None, "current_hint": None, "turn_number": 0,
                "last_overall_score": None, "retry_count": 0,
                "attempts": [], "turn_history": [],
                "onboarding_retry": 0
            }
            await db.create_session(
                session_id=session_id,
                session_type="fluent",
                data=session,
                user_id=user_id,
                user_name=name
            )
            
            
            if scenario:
                ask_level = f"Great! We'll practice {scenario.replace('_', ' ')}. What's your English level? Beginner, Intermediate, Advanced, or Proficient?"
                ask_level_target, ask_level_native = await asyncio.gather(
                    translate_text(ask_level, "en", target_language),
                    translate_text(ask_level, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": ask_level})
                await db.update_session(session_id, session)
                
                ask_level_audio = await generate_tts_url(request, ask_level_target, target_language, voice_id=voice_id)
                
                return {
                    "status": "onboarding",
                    "step": "collecting_level",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "scenario": scenario,
                    "message": {"target": ask_level_target, "native": ask_level_native},
                    "audio_url": ask_level_audio
                }

        
        
        current_state = session.get("state", "practicing")
        
        
        
        
        if current_state == "welcome" and not audio_file and not text_input:
            greeting = f"Hi {name}! I'm {BOT_NAME} Ã°Å¸â„¢â€š What would you like to practice today? For example: ordering food, hotel check-in, casual conversation, or anything else!"
            
            greeting_target, greeting_native = await asyncio.gather(
                translate_text(greeting, "en", target_language),
                translate_text(greeting, "en", native_language)
            )
            
            session["state"] = "collecting_scenario"
            session["chat_history"].append({"role": "assistant", "content": greeting})
            await db.update_session(session_id, session)
            
            greeting_audio = await generate_tts_url(request, greeting_target, target_language, voice_id=voice_id)
            
            return {
                "status": "onboarding",
                "step": "collecting_scenario",
                "session_id": session_id,
                "target_lang": target_language,
                "native_lang": native_language,
                "transcription": user_text,
                "message": {"target": greeting_target, "native": greeting_native},
                "audio_url": greeting_audio
            }
        
        
        
        
        if current_state == "collecting_scenario":
            user_text = text_input or ""
            if audio_file:
                user_text = await transcribe_audio_file(audio_file, target_language)

            
            if not user_text.strip():
                error_msg = await translate_text("No speech detected. Please tell me what you'd like to practice.", "en", native_language)
                return {"status": "error", "session_id": session_id, "error": error_msg}
            
            session["chat_history"].append({"role": "user", "content": user_text})
            
            
            extraction = await extract_scenario_from_text(user_text, model=model)
            
            if extraction.get("success") and extraction.get("scenario"):
                scenario = extraction["scenario"]
                session["scenario"] = scenario
                session["state"] = "collecting_level"
                session["onboarding_retry"] = 0
                
                
                ask_level = f"Great choice! We'll practice {scenario.replace('_', ' ')}. What's your level? Beginner, Intermediate, Advanced, or Proficient?"
                ask_level_target, ask_level_native = await asyncio.gather(
                    translate_text(ask_level, "en", target_language),
                    translate_text(ask_level, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": ask_level})
                await db.update_session(session_id, session)
                
                ask_level_audio = await generate_tts_url(request, ask_level_target, target_language, voice_id=voice_id)
                print(user_text)
                print(target_language)
                return {
                    "status": "onboarding",
                    "step": "collecting_level", 
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "scenario": scenario,
                    "message": {"target": ask_level_target, "native": ask_level_native},
                    "audio_url": ask_level_audio
                }
            else:
                
                session["onboarding_retry"] = session.get("onboarding_retry", 0) + 1
                retry_msg = "Could you be more specific? For example: ordering food, shopping, hotel check-in, asking directions, or casual chat?"
                retry_target, retry_native = await asyncio.gather(
                    translate_text(retry_msg, "en", target_language),
                    translate_text(retry_msg, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": retry_msg})
                await db.update_session(session_id, session)
                
                return {
                    "status": "onboarding",
                    "step": "collecting_scenario",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "retry": True,
                    "message": {"target": retry_target, "native": retry_native}
                }
        
        
        
        
        if current_state == "collecting_level":
            user_text = text_input or ""
            if audio_file:
                user_text = await transcribe_audio_file(audio_file, target_language)
            
            if not user_text.strip():
                error_msg = await translate_text("No speech detected. Please tell me your level.", "en", native_language)
                return {"status": "error", "session_id": session_id, "error": error_msg}
            
            session["chat_history"].append({"role": "user", "content": user_text})
            
            
            extraction = await extract_level_from_text(user_text, model=model)
            level = extraction.get("level", "B1")
            session["level"] = level
            session["state"] = "practicing"
            session["onboarding_retry"] = 0
            
            
            scenario = session.get("scenario", "casual_conversation")
            question, hint = await generate_question_llm(level, scenario, name, target_language, model=model)
            
            
            level_display = LEVEL_DISPLAY.get(level, level)
            start_msg = f"Perfect! Let's start practicing {scenario.replace('_', ' ')} at {level_display} level."
            
            start_target, start_native, q_native, h_native = await asyncio.gather(
                translate_text(start_msg, "en", target_language),
                translate_text(start_msg, "en", native_language),
                translate_text(question, target_language, native_language),
                translate_text(hint, target_language, native_language)
            )
            
            session["current_question"] = question
            session["current_hint"] = hint
            session["chat_history"].append({"role": "assistant", "content": question})
            await db.update_session(session_id, session)
            
            message_audio = await generate_tts_url(request, start_target, target_language, voice_id=voice_id)
            question_audio = await generate_tts_url(request, question, target_language, voice_id=voice_id)
            
            return {
                "status": "practice_started",
                "session_id": session_id,
                "target_lang": target_language,
                "native_lang": native_language,
                "level": level_display,
                "scenario": scenario,
                "transcription": user_text,
                "message": {"target": start_target, "native": start_native},
                "message_audio": message_audio,
                "next_question": {"target": question, "native": q_native},
                "hint": {"target": hint, "native": h_native},
                "audio_url": question_audio
            }
        
        
        
        
        if skip_retry and not audio_file and not text_input:
            
            session["waiting_retry_decision"] = False
            session["retry_count"] = 0
            session["retry_clarify_count"] = 0  
            scenario = session.get("scenario", "casual_conversation")
            session_user_type = session.get("user_type", user_type)  
            follow_up, hint = await generate_context_aware_follow_up("", session["chat_history"], scenario, session_user_type, model=model, target_language=target_language)
            session["current_question"] = follow_up
            session["current_hint"] = hint
            session["chat_history"].append({"role": "assistant", "content": follow_up})
            
            
            
            await db.update_session(session_id, session)
            
            # Translate skip messages to native language
            skipped_msg = await translate_text("Skipped", "en", native_language)
            skipped_next_msg = await translate_text("Skipped. Let's try the next question!", "en", native_language)
            
            follow_up_audio = await generate_tts_url(request, follow_up, target_language, voice_id=voice_id)
            
            return {
                "status": "continue", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "transcription": "(skipped)",
                "next_question": {"target": follow_up, "native": await translate_text(follow_up, target_language, native_language)},
                "hint": {"target": hint, "native": await translate_text(hint, target_language, native_language)},
                "grammar": {"score": 0, "is_correct": True, "you_said": "", "you_should_say": "", "errors": [], "word_suggestions": [], "corrected_sentence": "", "improved_sentence": "", "feedback": skipped_msg},
                "vocabulary": {"score": 0, "overall_level": "skipped", "cefr_distribution": {}, "feedback": skipped_msg, "suggestions": []},
                "pronunciation": {"accuracy": 0, "total_words": 0, "words_to_practice": [], "well_pronounced_words": [], "feedback": skipped_msg, "practice_sentence": "", "tips": []},
                "fluency": {"score": 0, "wpm": 0, "speed_status": "skipped", "original_text": "", "corrected_text": "", "improved_sentence": ""},
                "personalized_feedback": {"user_type": user_type, "message": skipped_next_msg, "improvement_areas": [], "strengths": [], "perfect_areas": [], "perfect_feedback": {}, "quick_tip": ""},
                "overall_score": 0, "passing_score": PASSING_SCORE, "should_retry": False, "turn_number": session["turn_number"],
                "audio_url": follow_up_audio
            }
        
        
        if not audio_file and not text_input and current_state == "practicing" and session.get("turn_number", 0) == 0:
            scenario = session.get("scenario", "casual_conversation")
            level = session.get("level", "B1")
            greeting = f"Hey {name}! I am {BOT_NAME}. I am your {BOT_ROLE}. Let's practice {scenario.replace('_', ' ')}!"
            question, hint = await generate_question_llm(level, scenario, name, target_language, model=model)
            
            
            greeting_target, greeting_native, question_native, hint_native = await asyncio.gather(
                translate_text(greeting, "en", target_language),
                translate_text(greeting, "en", native_language),
                translate_text(question, target_language, native_language),
                translate_text(hint, target_language, native_language)
            )
            
            session["current_question"] = question
            session["current_hint"] = hint
            session["chat_history"].append({"role": "assistant", "content": question})
            
            
            await db.update_session(session_id, session)
            
            question_audio = await generate_tts_url(request, question, target_language, voice_id=voice_id)
            
            return {
                "status": "conversation_started", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "greeting": {"target": greeting_target, "native": greeting_native},
                "next_question": {"target": question, "native": question_native},
                "hint": {"target": hint, "native": hint_native},
                "audio_url": question_audio
            }
        
        user_text = text_input or ""
        audio_analysis = None
        audio_path = None
        is_audio_input = audio_file is not None  

        
        if audio_file:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp:
                shutil.copyfileobj(audio_file.file, tmp)
                temp_upload = tmp.name
            
            try:
                
                def convert_audio():
                    audio = AudioSegment.from_file(temp_upload)
                    audio = audio.set_frame_rate(16000).set_channels(1)
                    converted_path = temp_upload.replace('.tmp', '_converted.wav')
                    audio.export(converted_path, format="wav")
                    return converted_path
                
                audio_path = await asyncio.to_thread(convert_audio)
                os.unlink(temp_upload)  
            except Exception:
                audio_path = temp_upload
            finally:
                
                
                if audio_path != temp_upload and os.path.exists(temp_upload):
                    try:
                        os.unlink(temp_upload)
                    except Exception:
                        pass
            
            
            session_level_for_audio = session.get("level", "B1")
            audio_analysis = await asyncio.to_thread(analyze_speaking_advanced, audio_path, session_level_for_audio, None, target_language)
            if audio_analysis.get("success") and audio_analysis.get("transcription"):
                user_text = audio_analysis.get("transcription")
            elif not user_text:
                # Fallback to speech_to_text - convert language name to ISO code
                try:
                    languages_data = load_language_mapping()
                    iso_code = languages_data.get(target_language.lower(), target_language.lower())
                    user_text = await asyncio.to_thread(speech_to_text, audio_path, iso_code)
                except Exception:
                    pass

        
        if not user_text or not user_text.strip():
            error_msg = await translate_text("No speech detected. Please try again.", "en", native_language)
            return {"status": "error", "session_id": session_id, "error": error_msg}
        
        user_text = user_text.strip()
        session["chat_history"].append({"role": "user", "content": user_text})
        
        
        
        
        if session.get("waiting_retry_decision"):
            user_choice = user_text.lower().strip()
            
            
            cleaned_choice = user_choice.rstrip('.,!?')
            if cleaned_choice in TERMINATION_PHRASES:
                
                session["waiting_retry_decision"] = False
                count = max(1, session["scores"]["count"])
                audio_count = session["scores"].get("audio_count", 0)
                if not audio_count and (
                    session["scores"].get("pronunciation", 0) > 0 or session["scores"].get("fluency", 0) > 0
                ):
                    audio_count = count
                pronunciation_avg = int(session["scores"]["pronunciation"] / audio_count) if audio_count > 0 else 0
                fluency_avg = int(session["scores"]["fluency"] / audio_count) if audio_count > 0 else 0
                final_scores = {
                    "grammar": int(session["scores"]["grammar"] / count),
                    "vocabulary": int(session["scores"]["vocabulary"] / count),
                    "pronunciation": pronunciation_avg if audio_count > 0 else None,
                    "fluency": fluency_avg if audio_count > 0 else None
                }
                
                if audio_count > 0:
                    overall = int(sum(v for v in final_scores.values() if v is not None) / 4)
                else:
                    overall = int((final_scores["grammar"] + final_scores["vocabulary"]) / 2)
                average_wpm = int(session["scores"].get("total_wpm", 0) / audio_count) if audio_count > 0 else 0
                
                improvement_areas = [area for area, score in final_scores.items() if score is not None and score < 70]
                strengths = [area for area, score in final_scores.items() if score is not None and score >= 80]
                
                
                final_feedback_data = {
                    "final_scores": final_scores,
                    "overall_score": overall,
                    "average_wpm": average_wpm,
                    "strengths": strengths,
                    "improvement_areas": improvement_areas,
                    "total_turns": session.get("turn_number", 0)
                }
                
                
                await db.complete_session(session_id, final_feedback=final_feedback_data, overall_score=overall)
                
                return {
                    "status": "conversation_ended",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "final_scores": final_scores,
                    "overall_score": overall,
                    "passing_score": PASSING_SCORE,
                    "average_wpm": average_wpm,
                    "wpm_status": "slow" if average_wpm < 110 else "normal" if average_wpm <= 160 else "fast",
                    "strengths": strengths,
                    "improvement_areas": improvement_areas,
                    "total_turns": session.get("turn_number", 0),
                    "message": {
                        "target": await translate_text("Session ended. Great practice!", "en", target_language) if target_language.lower() not in ["en", "english"] else "Session ended. Great practice!",
                        "native": await translate_text("Session ended. Great practice!", "en", native_language)
                    }
                }
            
            is_english = target_language.lower() in ["en", "english"]
            if is_english:
                retry_keywords = ["yes", "retry", "practice", "again", "try", "redo", "repeat", "once more", "one more"]
                skip_keywords = ["no", "skip", "next", "move", "forward", "pass", "don't want", "not now", "let's move", "move on", "go ahead"]
                wants_retry = any(keyword in user_choice for keyword in retry_keywords)
                wants_skip = any(keyword in user_choice for keyword in skip_keywords)
            else:
                cleaned_choice_numeric = re.sub(r"[\s\W_]+", "", user_choice)
                wants_retry = cleaned_choice_numeric == "1"
                wants_skip = cleaned_choice_numeric == "2"
            
            if wants_retry:
                
                session["waiting_retry_decision"] = False
                session["retry_clarify_count"] = 0
                session["is_retry_attempt"] = True  
                current_q = session.get("current_question", "")
                current_h = session.get("current_hint", "")
                session["chat_history"].append({"role": "assistant", "content": current_q})
                await db.update_session(session_id, session)
                
                
                
                retry_msg = await generate_retry_encouragement(
                    scenario=session.get("scenario", "conversation"),
                    retry_count=session.get("retry_count", 0),
                    previous_score=session.get("last_overall_score", 50),
                    user_name=session.get("name", "there"),
                    model=model,
                    target_language=target_language
                )
                q_native, h_native, retry_msg_native = await asyncio.gather(
                    translate_text(current_q, target_language, native_language),
                    translate_text(current_h, target_language, native_language),
                    translate_text(retry_msg, target_language, native_language)
                )
                
                question_audio = await generate_tts_url(request, current_q, target_language, voice_id=voice_id)
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "next_question": {"target": current_q, "native": q_native},
                    "hint": {"target": current_h, "native": h_native},
                    "message": {"target": retry_msg, "native": retry_msg_native},
                    "turn_number": session.get("turn_number", 0),
                    "audio_url": question_audio
                }
            elif wants_skip:
                
                session["waiting_retry_decision"] = False
                session["retry_clarify_count"] = 0
                session["retry_count"] = 0
                session["is_retry_attempt"] = False  
                session["last_overall_score"] = None  
                scenario = session.get("scenario", "casual_conversation")
                follow_up, hint = await generate_context_aware_follow_up("", session["chat_history"], scenario, user_type, model=model, target_language=target_language)
                session["current_question"] = follow_up
                session["current_hint"] = hint
                session["chat_history"].append({"role": "assistant", "content": follow_up})
                
                await db.update_session(session_id, session)
                
                
                skip_msg = await generate_skip_message(
                    scenario=scenario,
                    user_name=session.get("name", "there"),
                    model=model,
                    target_language=target_language
                )
                skip_msg_native, follow_up_native, hint_native = await asyncio.gather(
                    translate_text(skip_msg, target_language, native_language),
                    translate_text(follow_up, target_language, native_language),
                    translate_text(hint, target_language, native_language)
                )
                
                follow_up_audio = await generate_tts_url(request, follow_up, target_language, voice_id=voice_id)
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "message": {"target": skip_msg, "native": skip_msg_native},
                    "next_question": {"target": follow_up, "native": follow_up_native},
                    "hint": {"target": hint, "native": hint_native},
                    "turn_number": session["turn_number"],
                    "audio_url": follow_up_audio
                }
            else:
                
                clarify_count = session.get("retry_clarify_count", 0) + 1
                session["retry_clarify_count"] = clarify_count
                
                if clarify_count >= 3:
                    
                    session["waiting_retry_decision"] = False
                    session["retry_clarify_count"] = 0
                    scenario = session.get("scenario", "casual_conversation")
                    follow_up, hint = await generate_context_aware_follow_up("", session["chat_history"], scenario, user_type, model=model, target_language=target_language)
                    session["current_question"] = follow_up
                    session["current_hint"] = hint
                    session["chat_history"].append({"role": "assistant", "content": follow_up})
                    
                    await db.update_session(session_id, session)
                    
                    auto_skip_audio = await generate_tts_url(request, follow_up, target_language, voice_id=voice_id)
                    
                    return {
                        "status": "auto_skipped",
                        "session_id": session_id,
                        "target_lang": target_language,
                        "native_lang": native_language,
                        "message": {
                            "target": await translate_text("Moving to the next question.", "en", target_language) if target_language.lower() not in ["en", "english"] else "Moving to the next question.",
                            "native": await translate_text("Moving to the next question.", "en", native_language)
                        },
                        "next_question": {"target": follow_up, "native": await translate_text(follow_up, target_language, native_language)},
                        "hint": {"target": hint, "native": await translate_text(hint, target_language, native_language)},
                        "turn_number": session["turn_number"],
                        "audio_url": auto_skip_audio
                    }
                else:
                    
                    level = session.get("level", "B1")
                    scenario = session.get("scenario", "casual_conversation")
                    
                    
                    if is_audio_input:
                        grammar, vocabulary, pronunciation = await asyncio.gather(
                            analyze_grammar_llm(user_text, level=level, user_type=user_type, model=model, target_language=target_language),
                            analyze_vocab_llm(user_text, level=level, user_type=user_type, model=model, target_language=target_language),
                            analyze_pronunciation_llm(audio_path=audio_path, spoken_text=user_text, level=level, user_type=user_type, model=model, target_language=target_language)
                        )
                        
                        try:
                            audio_for_duration = AudioSegment.from_file(audio_path)
                            audio_duration = len(audio_for_duration) / 1000
                        except Exception:
                            word_count = len(user_text.split())
                            audio_duration = max(1, word_count / 2.5)
                        fluency = await analyze_fluency_metrics(user_text, audio_duration)
                    else:
                        
                        grammar, vocabulary = await asyncio.gather(
                            analyze_grammar_llm(user_text, level=level, user_type=user_type, model=model, target_language=target_language),
                            analyze_vocab_llm(user_text, level=level, user_type=user_type, model=model, target_language=target_language)
                        )
                        pronunciation = None
                        fluency = None
                    
                    
                    if is_audio_input:
                        scores = {
                            "grammar": grammar.get("score", 70),
                            "vocabulary": vocabulary.get("score", 70),
                            "pronunciation": pronunciation.get("score", pronunciation.get("accuracy", 70)) if pronunciation else 0,
                            "fluency": fluency.get("score", 70) if fluency else 0
                        }
                        
                        overall_score = int(scores["pronunciation"] * 0.30 + scores["grammar"] * 0.30 + scores["vocabulary"] * 0.20 + scores["fluency"] * 0.20)
                    else:
                        scores = {
                            "grammar": grammar.get("score", 70),
                            "vocabulary": vocabulary.get("score", 70),
                            "pronunciation": None,
                            "fluency": None
                        }
                        
                        overall_score = int(scores["grammar"] * 0.50 + scores["vocabulary"] * 0.50)
                    
                    personalized_feedback = await generate_personalized_feedback(
                        user_type, overall_score, scores, user_text,
                        grammar=grammar, vocabulary=vocabulary, pronunciation=pronunciation, model=model,
                        target_language=session.get("target_language", "en")
                    )
                    
                    is_english = target_language.lower() in ["en", "english"]
                    if clarify_count == 1:
                        if is_english:
                            clarify_msg = "I didn't quite catch that. Say 'yes' to try again, or 'no' to skip to the next question."
                        else:
                            clarify_msg = "I didn't quite catch that. Type 1 to retry, 2 to skip to the next question."
                    else:
                        if is_english:
                            clarify_msg = "Please say 'yes' to retry the same question, or 'no' to move on."
                        else:
                            clarify_msg = "Please type 1 to retry the same question, or 2 to move on."
                    
                    await db.update_session(session_id, session)
                    
                    
                    if is_audio_input and pronunciation:
                        (grammar_t, vocab_t, pron_t, feedback_t, clarify_target, clarify_native) = await asyncio.gather(
                            translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                            translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                            translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS),
                            translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS),
                            translate_text(clarify_msg, "en", target_language),
                            translate_text(clarify_msg, "en", native_language)
                        )
                    else:
                        (grammar_t, vocab_t, feedback_t, clarify_target, clarify_native) = await asyncio.gather(
                            translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                            translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                            translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS),
                            translate_text(clarify_msg, "en", target_language),
                            translate_text(clarify_msg, "en", native_language)
                        )
                        pron_t = None
                    
                    return {
                        "status": "clarify_retry",
                        "session_id": session_id,
                        "target_lang": target_language,
                        "native_lang": native_language,
                        "transcription": user_text,
                        "message": {"target": clarify_target, "native": clarify_native},
                        "grammar": grammar_t,
                        "vocabulary": vocab_t,
                        "pronunciation": pron_t,
                        "fluency": fluency,
                        "personalized_feedback": feedback_t,
                        "overall_score": overall_score,
                        "clarify_count": clarify_count,
                        "turn_number": session.get("turn_number", 0)
                    }

        
        cleaned_text = user_text.lower().strip().rstrip('.,!?')
        is_termination = cleaned_text in TERMINATION_PHRASES
        
        if is_termination:
            count = max(1, session["scores"]["count"])
            audio_count = max(1, session["scores"].get("audio_count", 0))  
            
            
            has_audio_turns = session["scores"].get("audio_count", 0) > 0  
            
            if has_audio_turns:
                final_scores = {
                    "grammar": int(session["scores"]["grammar"] / count),
                    "vocabulary": int(session["scores"]["vocabulary"] / count),
                    "pronunciation": int(session["scores"]["pronunciation"] / audio_count),  
                    "fluency": int(session["scores"]["fluency"] / audio_count)  
                }
                
                overall = int(
                    final_scores["pronunciation"] * 0.30 +
                    final_scores["grammar"] * 0.30 +
                    final_scores["vocabulary"] * 0.20 +
                    final_scores["fluency"] * 0.20
                )
                average_wpm = int(session["scores"].get("total_wpm", 0) / audio_count) if audio_count > 0 else 0
            else:
                
                final_scores = {
                    "grammar": int(session["scores"]["grammar"] / count),
                    "vocabulary": int(session["scores"]["vocabulary"] / count),
                    "pronunciation": None,
                    "fluency": None
                }
                
                overall = int(
                    final_scores["grammar"] * 0.50 +
                    final_scores["vocabulary"] * 0.50
                )
                average_wpm = 0

            
            
            if average_wpm < 110:
                wpm_status = "Slow - Try to speak a bit faster"
            elif average_wpm > 160:
                wpm_status = "Fast - Try to slow down for clarity"
            else:
                wpm_status = "Natural - Great speaking pace!"
            
            improvement_areas = []
            strengths = []
            for area, score in final_scores.items():
                if score is None:  
                    continue
                if score >= 85:
                    strengths.append(area)
                elif score < 70:
                    improvement_areas.append(area)
            
            
            turn_history_summary = []
            wpm_per_turn = []
            vocab_overall = {
                "A1": {"count": 0, "words": []},
                "A2": {"count": 0, "words": []},
                "B1": {"count": 0, "words": []},
                "B2": {"count": 0, "words": []},
                "C1": {"count": 0, "words": []},
                "C2": {"count": 0, "words": []}
            }
            for i, attempt in enumerate(session.get("attempts", []), 1):
                
                pron_data = attempt.get("pronunciation") or {}
                fluency_data = attempt.get("fluency") or {}
                vocab_data = attempt.get("vocabulary") or {}
                
                turn_wpm = fluency_data.get("wpm", 0) if fluency_data else 0
                wpm_per_turn.append({"turn": i, "wpm": turn_wpm})
                
                cefr_dist = vocab_data.get("cefr_distribution", {}) if vocab_data else {}
                for level in ["A1", "A2", "B1", "B2", "C1", "C2"]:
                    level_data = cefr_dist.get(level, {})
                    if isinstance(level_data, dict):
                        words = level_data.get("words", [])
                        if isinstance(words, list):
                            safe_words = [w for w in words if isinstance(w, str)]
                            vocab_overall[level]["words"].extend(safe_words)
                            vocab_overall[level]["count"] = len(set(vocab_overall[level]["words"]))
                
                turn_history_summary.append({
                    "turn": i,
                    "grammar": attempt.get("grammar", {}).get("score", 0),
                    "vocabulary": attempt.get("vocabulary", {}).get("score", 0),
                    "pronunciation": pron_data.get("accuracy", 0) if pron_data else 0,
                    "fluency": fluency_data.get("score", 0) if fluency_data else 0,
                    "wpm": turn_wpm,
                    "overall": attempt.get("overall_score", 0),
                    "transcription": attempt.get("transcription", "")[:50]
                })
            
            total_vocab_words = sum(len(set(vocab_overall[level]["words"])) for level in vocab_overall)
            for level in vocab_overall:
                vocab_overall[level]["words"] = list(set(vocab_overall[level]["words"]))
                vocab_overall[level]["count"] = len(vocab_overall[level]["words"])
                vocab_overall[level]["percentage"] = round((vocab_overall[level]["count"] / total_vocab_words * 100), 1) if total_vocab_words > 0 else 0
            
            final_feedback_prompt = f"""You are {session.get('name', 'friend')}'s warm, encouraging language coach. Generate a HIGHLY PERSONALIZED and INTERACTIVE final session summary.

SESSION DATA:
- Student Name: {session['name']}
- User Type: {session.get('user_type', 'student')}
- Level: {session.get('level', 'B1')}
- Scenario: {session.get('scenario', 'conversation')}
- Total Turns: {session.get('turn_number', 0)}
- Final Scores: Grammar={final_scores['grammar']}%, Vocabulary={final_scores['vocabulary']}%, Pronunciation={final_scores['pronunciation'] if final_scores['pronunciation'] is not None else 'N/A'}%, Fluency={final_scores['fluency'] if final_scores['fluency'] is not None else 'N/A'}%
- Overall Score: {overall}/100
- Average WPM: {average_wpm}
- Strengths: {strengths if strengths else 'Building foundation'}
- Areas to Improve: {improvement_areas if improvement_areas else 'Minor refinements'}

TURN-BY-TURN PERFORMANCE (analyze progression):
{json.dumps(turn_history_summary, indent=2)}

CONVERSATION EXCERPTS:
{session.get('chat_history', [])[-6:]}

REQUIREMENTS:
1. Be WARM and CONVERSATIONAL - address {session['name']} directly
2. Reference SPECIFIC phrases they said during the session
3. Explain WHY scores changed between turns (e.g., "Your grammar jumped from 80% to 95% in Turn 3 when you used complex sentences")
4. Give ACTIONABLE, specific tips (not generic advice)
5. Celebrate their wins enthusiastically!

Return STRICTLY valid JSON:
{{
    "detailed_feedback": {{
        "grammar": {{"score": {final_scores['grammar']}, "status": "Excellent/Good/Needs Work", "feedback": "2-3 sentences explaining grammar performance with specific examples from their responses, mention what they did well and one specific thing to improve", "trend": "improved/declined/stable"}},
        "vocabulary": {{"score": {final_scores['vocabulary']}, "status": "Excellent/Good/Needs Work", "feedback": "2-3 sentences about vocabulary richness, mention specific words they used well or could upgrade", "trend": "improved/declined/stable"}},
        "pronunciation": {{"score": {final_scores['pronunciation'] if final_scores['pronunciation'] is not None else '"N/A"'}, "status": "Excellent/Good/Needs Work", "feedback": "2-3 sentences about clarity and specific words they pronounced well or struggled with", "trend": "improved/declined/stable"}},
        "fluency": {{"score": {final_scores['fluency'] if final_scores['fluency'] is not None else '"N/A"'}, "status": "Excellent/Good/Needs Work", "feedback": "2-3 sentences about speaking pace ({average_wpm} WPM), hesitations, and natural flow", "trend": "improved/declined/stable"}}
    }},
    "turn_comparison": {{
        "best_turn": <number>,
        "worst_turn": <number>,
        "biggest_improvement": "Specific improvement like 'Grammar jumped from X% to Y% when you started using complex sentences'",
        "area_with_most_growth": "<area name>"
    }},
    "overall_analysis": "3-4 warm, personalized sentences comparing {session['name']}'s start vs end performance. Reference specific things they said. Example: 'Hey {session['name']}! You started a bit nervous in Turn 1, but by Turn 3 you were nailing those complex sentences! Your vocabulary really shined when you described...'",
    "suggestions": ["Very specific actionable suggestion with example exercise", "Another practical tip they can do today"],
    "tip": "One fun, memorable tip personalized to their weakest area - make it encouraging!"
}}"""

            try:
                llm_final_content = await call_llm(final_feedback_prompt, mode="strict_json", timeout=30, model=model)
                json_match = re.search(r'\{[\s\S]*\}', llm_final_content)
                if json_match:
                    final_data = json.loads(json_match.group())
                    detailed_feedback = final_data.get("detailed_feedback", {})
                    turn_comparison = final_data.get("turn_comparison", {})
                    analysis_text = final_data.get("overall_analysis", "")
                    final_message = final_data.get("final_message", "")
                    suggestions = final_data.get("suggestions", [])
                    tip = final_data.get("tip", "")
                else:
                    raise ValueError("No valid JSON")
            except Exception:
                first_turn = turn_history_summary[0] if turn_history_summary else {}
                last_turn = turn_history_summary[-1] if turn_history_summary else {}
                
                
                grammar_change = last_turn.get("grammar", 0) - first_turn.get("grammar", 0)
                vocab_change = last_turn.get("vocabulary", 0) - first_turn.get("vocabulary", 0)
                
                detailed_feedback = {
                    "grammar": {
                        "score": final_scores["grammar"], 
                        "status": "Excellent" if final_scores["grammar"] >= 85 else "Good" if final_scores["grammar"] >= 70 else "Needs Work", 
                        "feedback": f"Great job, {session['name']}! Your grammar averaged {final_scores['grammar']}% across {session.get('turn_number', 0)} turns. " + 
                                   (f"You improved by {grammar_change}% from start to finish!" if grammar_change > 0 else "Keep practicing sentence structure for even better results."),
                        "trend": "improved" if grammar_change > 0 else "declined" if grammar_change < 0 else "stable"
                    },
                    "vocabulary": {
                        "score": final_scores["vocabulary"], 
                        "status": "Excellent" if final_scores["vocabulary"] >= 85 else "Good" if final_scores["vocabulary"] >= 70 else "Needs Work", 
                        "feedback": f"Your vocabulary scored {final_scores['vocabulary']}%! " +
                                   ("You used rich, varied words throughout - impressive!" if final_scores["vocabulary"] >= 85 else "Try incorporating more B2/C1 level words to sound more natural."),
                        "trend": "improved" if vocab_change > 0 else "declined" if vocab_change < 0 else "stable"
                    },
                }
                
                if final_scores["pronunciation"] is not None:
                    detailed_feedback["pronunciation"] = {
                        "score": final_scores["pronunciation"], 
                        "status": "Excellent" if final_scores["pronunciation"] >= 85 else "Good" if final_scores["pronunciation"] >= 70 else "Needs Work", 
                        "feedback": f"Pronunciation at {final_scores['pronunciation']}%! " +
                                   ("Your clarity was excellent - native speakers would understand you easily!" if final_scores["pronunciation"] >= 85 else 
                                    "Focus on clearly pronouncing consonant sounds and word endings for better clarity."),
                        "trend": "stable"
                    }
                if final_scores["fluency"] is not None:
                    speed_desc = "perfect pace" if 110 <= average_wpm <= 160 else "a bit slow - try to relax and speak faster" if average_wpm < 110 else "quite fast - try pausing between ideas"
                    detailed_feedback["fluency"] = {
                        "score": final_scores["fluency"], 
                        "status": "Excellent" if final_scores["fluency"] >= 85 else "Good" if final_scores["fluency"] >= 70 else "Needs Work", 
                        "feedback": f"You spoke at {average_wpm} words per minute - {speed_desc}! " +
                                   ("Great natural rhythm!" if final_scores["fluency"] >= 85 else "Practice speaking in longer phrases without hesitation."),
                        "trend": "stable"
                    }
                
                best_turn = max(range(len(turn_history_summary)), key=lambda i: turn_history_summary[i].get("overall", 0)) + 1 if turn_history_summary else 1
                worst_turn = min(range(len(turn_history_summary)), key=lambda i: turn_history_summary[i].get("overall", 0)) + 1 if turn_history_summary else 1
                
                turn_comparison = {
                    "best_turn": best_turn, 
                    "worst_turn": worst_turn, 
                    "biggest_improvement": f"Your best performance was in Turn {best_turn} with {turn_history_summary[best_turn-1].get('overall', 0) if turn_history_summary else 0}%!" if turn_history_summary else "N/A", 
                    "area_with_most_growth": strengths[0] if strengths else "overall"
                }
                
                analysis_text = f"Hey {session['name']}! Ã°Å¸Å½â€° You completed {session.get('turn_number', 0)} practice turns with an overall score of {overall}%. " + \
                               (f"Your strongest areas were {', '.join(strengths)} - amazing work! " if strengths else "You're building a solid foundation. ") + \
                               (f"For next time, let's focus on improving your {', '.join(improvement_areas)} - you've got this!" if improvement_areas else "Keep up the great momentum!")
                
                final_message = f"Awesome session, {session['name']}! You scored {overall}% - be proud of your progress!"
                
                suggestions = [
                    f"Practice {improvement_areas[0]} by recording yourself and comparing with native speakers" if improvement_areas else "Challenge yourself with longer, more complex sentences",
                    f"Try shadowing exercises - listen to English content and repeat immediately" if average_wpm < 110 else "Read aloud for 10 minutes daily to maintain your great pace"
                ]
                
                tip = f"Quick tip for {session['name']}: " + (f"Focus on {improvement_areas[0]} by practicing tongue twisters!" if improvement_areas and improvement_areas[0] == "pronunciation" else 
                      f"Boost your {improvement_areas[0] if improvement_areas else 'speaking'} by having 5-minute English conversations with yourself daily - it really works!")
            
            
            final_feedback_data = {
                "final_scores": final_scores,
                "overall_score": overall,
                "average_wpm": average_wpm,
                "wpm_per_turn": wpm_per_turn,
                "vocab_overall": vocab_overall,
                "detailed_feedback": detailed_feedback,
                "turn_comparison": turn_comparison,
                "strengths": strengths,
                "improvement_areas": improvement_areas,
                "overall_analysis": analysis_text,
                "suggestions": suggestions,
                "tip": tip,
                "turn_history": turn_history_summary
            }
            await db.complete_session(session_id, final_feedback=final_feedback_data, overall_score=overall)
            
            turn_feedback = []
            grammar_mistakes = []
            vocab_suggestions = []
            pronunciation_issues = []
            
            for i, attempt in enumerate(session.get("attempts", []), 1):
                turn_feedback.append({
                    "turn": i,
                    "transcription": attempt.get("transcription", ""),
                    "grammar": attempt.get("grammar", {}),
                    "vocabulary": attempt.get("vocabulary", {}),
                    "pronunciation": attempt.get("pronunciation"),
                    "fluency": attempt.get("fluency"),
                    "personalized_feedback": attempt.get("personalized_feedback", {}),
                    "improvement": attempt.get("improvement"),
                    "overall_score": attempt.get("overall_score", attempt.get("average_score", 0))
                })
                
                gram = attempt.get("grammar") or {}
                if isinstance(gram, dict):
                    for err in gram.get("errors", []):
                        if isinstance(err, dict):
                            grammar_mistakes.append({
                                "wrong": err.get("you_said", err.get("wrong_word", "")),
                                "correct": err.get("should_be", err.get("correct_word", ""))
                            })
                
                vocab = attempt.get("vocabulary") or {}
                if isinstance(vocab, dict):
                    for sug in vocab.get("suggestions", []):
                        if isinstance(sug, dict):
                            vocab_suggestions.append({
                                "weak_word": sug.get("word", ""),
                                "better_options": sug.get("better_word", "")
                            })
                
                pron = attempt.get("pronunciation") or {}
                if isinstance(pron, dict):
                    for word_issue in pron.get("words_to_practice", []):
                        if isinstance(word_issue, dict):
                            pronunciation_issues.append({
                                "word": word_issue.get("word", ""),
                                "issue": word_issue.get("issue", ""),
                                "how_to_say": word_issue.get("how_to_say", "")
                            })
            
            summary = {
                "grammar": {
                    "total_errors": len(grammar_mistakes),
                    "errors": grammar_mistakes
                },
                "vocabulary": {
                    "total_suggestions": len(vocab_suggestions),
                    "suggestions": vocab_suggestions
                },
                "pronunciation": {
                    "total_issues": len(pronunciation_issues),
                    "issues": pronunciation_issues
                }
            }
            
            # Translate end-of-session strings to native language
            final_message_native = await translate_text(final_message, "en", native_language)
            analysis_native = await translate_text(analysis_text, "en", native_language)
            tip_native = await translate_text(tip, "en", native_language)
            suggestions_native = [await translate_text(s, "en", native_language) for s in suggestions]
            
            return {
                "status": "conversation_ended", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "final_scores": final_scores, "overall_score": overall, "passing_score": PASSING_SCORE,
                "average_wpm": average_wpm, "wpm_per_turn": wpm_per_turn, "wpm_status": wpm_status,
                "vocab_overall": vocab_overall,
                "detailed_feedback": detailed_feedback, "turn_comparison": turn_comparison,
                "strengths": strengths, "improvement_areas": improvement_areas,
                "overall_analysis": analysis_native, "suggestions": suggestions_native,
                "total_turns": session.get("turn_number", 0), "message": final_message_native, "tip": tip_native,
                "turn_history": turn_history_summary,
                "turn_feedback": turn_feedback,
                "summary": summary
            }

        
        session_level = session.get("level", "B1")
        session_user_type = session.get("user_type", user_type)
        
        
        if is_audio_input:
            grammar, vocabulary, pronunciation = await asyncio.gather(
                analyze_grammar_llm(user_text, level=session_level, user_type=session_user_type, model=model, target_language=session.get("target_language", "en")),
                analyze_vocab_llm(user_text, user_type=session_user_type, level=session_level, model=model, target_language=session.get("target_language", "en")),
                analyze_pronunciation_llm(audio_path=audio_path, spoken_text=user_text, level=session_level, user_type=session_user_type, model=model, target_language=session.get("target_language", "en"))
            )
        else:
            
            grammar, vocabulary = await asyncio.gather(
                analyze_grammar_llm(user_text, level=session_level, user_type=session_user_type, model=model, target_language=session.get("target_language", "en")),
                analyze_vocab_llm(user_text, user_type=session_user_type, level=session_level, model=model, target_language=session.get("target_language", "en"))
            )
            pronunciation = None
        
        
        if is_audio_input:
            if audio_analysis and audio_analysis.get("success"):
                fluency_data = audio_analysis.get("fluency", {})
                fluency = {
                    "score": fluency_data.get("score", 70), "wpm": fluency_data.get("wpm", 100),
                    "speed_status": "slow" if fluency_data.get("wpm", 100) < 100 else "normal" if fluency_data.get("wpm", 100) < 160 else "fast",
                    "pause_count": fluency_data.get("pause_count", 0),
                    "hesitation_count": len(grammar.get("filler_words", []))
                }
            else:
                word_count = len(user_text.split())
                audio_duration_seconds = 5
                if audio_path:
                    try:
                        audio_for_duration = AudioSegment.from_file(audio_path)
                        audio_duration_seconds = len(audio_for_duration) / 1000
                    except Exception:
                        audio_duration_seconds = 5
                
                fluency = await analyze_fluency_metrics(user_text, audio_duration_seconds)
            
            fluency["original_text"] = user_text
            fluency["corrected_text"] = grammar.get("corrected_sentence", user_text)
            fluency["improved_sentence"] = grammar.get("improved_sentence", user_text)
            fluency["filler_words_removed"] = grammar.get("filler_words", [])
        else:
            fluency = None  
        
        
        if is_audio_input:
            scores = {
                "grammar": grammar.get("score", 70), "vocabulary": vocabulary.get("score", 70),
                "pronunciation": pronunciation.get("accuracy", 70) if pronunciation else 0, "fluency": fluency.get("score", 70) if fluency else 0
            }
            
            overall_score = int(scores["pronunciation"] * 0.30 + scores["grammar"] * 0.30 + scores["vocabulary"] * 0.20 + scores["fluency"] * 0.20)
        else:
            scores = {
                "grammar": grammar.get("score", 70), "vocabulary": vocabulary.get("score", 70),
                "pronunciation": None, "fluency": None
            }
            
            overall_score = int(scores["grammar"] * 0.50 + scores["vocabulary"] * 0.50)
        
        
        session["scores"]["grammar"] += scores["grammar"]
        session["scores"]["vocabulary"] += scores["vocabulary"]
        if is_audio_input:
            session["scores"]["pronunciation"] += scores["pronunciation"]
            session["scores"]["fluency"] += scores["fluency"]
            session["scores"]["total_wpm"] += fluency.get("wpm", 100) if fluency else 100
            session["scores"]["audio_count"] = session["scores"].get("audio_count", 0) + 1  
        session["scores"]["count"] += 1
        session["turn_number"] += 1


        personalized_feedback = await generate_personalized_feedback(
            user_type, overall_score, scores, user_text,
            grammar=grammar, vocabulary=vocabulary, pronunciation=pronunciation, model=model,
            target_language=session.get("target_language", "en")
        )
        
        native_language = session.get("native_language", "hi")
        target_language = session.get("target_language", "en")
        
        
        if is_audio_input and pronunciation:
            grammar_translated, vocab_translated, pron_translated, feedback_translated = await asyncio.gather(
                translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS),
                translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS)
            )
            fluency_translated = await translate_analysis(fluency, target_language, native_language, FLUENCY_FIELDS) if fluency else fluency
        else:
            grammar_translated, vocab_translated, feedback_translated = await asyncio.gather(
                translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS)
            )
            pron_translated = None
            fluency_translated = fluency

        
        current_attempt = {
            "pronunciation": pron_translated,
            "grammar": grammar_translated,
            "vocabulary": vocab_translated,
            "fluency": fluency_translated,
            "personalized_feedback": feedback_translated,
            "overall_score": overall_score,
            "average_score": overall_score,
            "transcription": user_text,
            "turn_number": session["turn_number"]
        }
        session["attempts"].append(current_attempt)
        
        
        is_retrying = session.get("retry_count", 0) > 0 or session.get("is_retry_attempt", False)
        session["is_retry_attempt"] = False  
        improvement = await compare_attempts(session["attempts"], level=session_level, user_type=session_user_type, target_language=target_language) if is_retrying else {}
        
        prev_score = session.get("last_overall_score")
        if is_retrying and prev_score is not None:
            diff = overall_score - prev_score
            improvement["overall_previous_score"] = prev_score
            improvement["overall_current_score"] = overall_score
            improvement["overall_difference"] = diff
            improvement["overall_improved"] = diff > 0
            if diff > 0:
                msg = f"You improved from {prev_score}% to {overall_score}%! (+{diff}%)"
            elif diff < 0:
                msg = f"Score changed from {prev_score}% to {overall_score}% ({diff}%)"
            else:
                msg = f"Score unchanged at {overall_score}%"
            improvement["overall_message"] = await translate_text(msg, "en", native_language)
        
        # Update stored attempt with improvement data
        if session["attempts"]:
            session["attempts"][-1]["improvement"] = improvement
        
        session["last_overall_score"] = overall_score
        should_retry = overall_score < PASSING_SCORE and not skip_retry
        
        if should_retry:
            session["retry_count"] = session.get("retry_count", 0) + 1
        else:
            session["retry_count"] = 0
        
        if should_retry:
            current_q = session.get("current_question", "")
            current_h = session.get("current_hint", "")
            
            
            is_english = target_language.lower() in ["en", "english"]
            if is_english:
                retry_prompt_en = "I see there's room for improvement. Would you like to retry? Say 'yes' to try again or 'no' to skip."
                retry_prompt_target = retry_prompt_en
            else:
                retry_prompt_en = "I see there's room for improvement. Type 1 to retry, 2 to skip."
                retry_prompt_target = await translate_text(retry_prompt_en, "en", target_language)
            
            
            q_native, h_native, retry_prompt_native = await asyncio.gather(
                translate_text(current_q, target_language, native_language),
                translate_text(current_h, target_language, native_language),
                translate_text(retry_prompt_en, "en", native_language)
            )
            
            
            session["waiting_retry_decision"] = True
            await db.update_session(session_id, session)
            
            retry_audio = await generate_tts_url(request, retry_prompt_target, target_language, voice_id=voice_id)
            
            return {
                "status": "feedback", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "transcription": user_text,
                "grammar": grammar_translated, "vocabulary": vocab_translated, 
                "pronunciation": pron_translated, "fluency": fluency_translated,
                "personalized_feedback": feedback_translated, "overall_score": overall_score,
                "passing_score": PASSING_SCORE, "should_retry": True,
                "retry_prompt": {"target": retry_prompt_target, "native": retry_prompt_native},
                "retry_count": session.get("retry_count", 1), "improvement": improvement, "turn_number": session["turn_number"],
                "next_question": {"target": current_q, "native": q_native},
                "hint": {"target": current_h, "native": h_native},
                "audio_url": retry_audio
            }

        else:
            
            session["last_overall_score"] = None
            session["is_retry_attempt"] = False
            follow_up, hint = await generate_follow_up_llm(user_text, target_language, session["chat_history"], model=model)
            session["current_question"] = follow_up
            session["current_hint"] = hint
            session["chat_history"].append({"role": "assistant", "content": follow_up})
            
            
            follow_up_native, hint_native = await asyncio.gather(
                translate_text(follow_up, target_language, native_language),
                translate_text(hint, target_language, native_language)
            )
            
            await db.update_session(session_id, session, overall_score=overall_score)
            
            follow_up_audio = await generate_tts_url(request, follow_up, target_language, voice_id=voice_id)
            
            return {
                "status": "continue", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "transcription": user_text,
                "grammar": grammar_translated, "vocabulary": vocab_translated,
                "pronunciation": pron_translated, "fluency": fluency_translated,
                "personalized_feedback": feedback_translated, "overall_score": overall_score,
                "passing_score": PASSING_SCORE, "should_retry": False, "turn_number": session["turn_number"],
                "improvement": improvement,  
                "next_question": {"target": follow_up, "native": follow_up_native},
                "hint": {"target": hint, "native": hint_native},
                "audio_url": follow_up_audio
            }
    
    except Exception as e:
        logger.exception(f"Error in practice_fluent_lang: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        
        if audio_path and os.path.exists(audio_path):
            try:
                os.unlink(audio_path)
            except Exception:
                pass


@router.get("/sessions")
async def list_fluent_sessions():
    """list active fluent sessions from database"""
    sessions_list = await db.list_sessions(session_type="fluent")
    return {"active_sessions": len(sessions_list), "sessions": sessions_list}


@router.get("/sessions/{session_id}")
async def get_fluent_session(session_id: str):
    """get fluent session data from database"""
    session_data = await db.get_user_session(session_id)
    if session_data:
        return {"status": "success", "session_id": session_id, "data": session_data}
    raise HTTPException(status_code=404, detail="Session not found")


@router.get("/feedback/{session_id}")
async def get_fluent_feedback(session_id: str):
    """
    Get detailed per-turn feedback for a fluent session.
    
    Returns structured grammar, vocabulary, pronunciation, and fluency feedback for each turn.
    Also includes a summary of all errors/corrections (wrong/correct pairs).
    """
    feedback = await db.get_session_feedback(session_id)
    if not feedback:
        raise HTTPException(status_code=404, detail="Session not found")
    if feedback["session_type"] != "fluent":
        raise HTTPException(status_code=400, detail="Not a fluent session")
    
    # Extract summary of all errors/corrections from turn feedback
    grammar_errors = []
    vocabulary_suggestions = []
    pronunciation_issues = []
    
    turn_feedback = feedback.get("turn_feedback", [])
    
    for turn in turn_feedback:
        # Grammar errors
        grammar = turn.get("grammar") or {}
        for err in grammar.get("errors", []):
            if isinstance(err, dict):
                grammar_errors.append({
                    "wrong": err.get("you_said", err.get("wrong_word", "")),
                    "correct": err.get("should_be", err.get("correct_word", ""))
                })
        
        # Vocabulary suggestions
        vocab = turn.get("vocabulary") or {}
        for sug in vocab.get("suggestions", []):
            if isinstance(sug, dict):
                vocabulary_suggestions.append({
                    "weak_word": sug.get("word", sug.get("weak_word", "")),
                    "better_options": sug.get("better_options", sug.get("better_word", []))
                })
        
        # Pronunciation issues
        pron = turn.get("pronunciation") or {}
        if isinstance(pron, dict):
            for word in pron.get("words_to_practice", []):
                if isinstance(word, dict):
                    pronunciation_issues.append({"word": word.get("word", ""), "issue": word.get("issue", "needs practice")})
                elif isinstance(word, str):
                    pronunciation_issues.append({"word": word, "issue": "needs practice"})
    
    # Remove duplicates
    seen = set()
    unique_grammar = [g for g in grammar_errors if g.get("wrong") and (g["wrong"], g["correct"]) not in seen and not seen.add((g["wrong"], g["correct"]))]
    
    seen = set()
    unique_vocab = [v for v in vocabulary_suggestions if v.get("weak_word") and v["weak_word"] not in seen and not seen.add(v["weak_word"])]
    
    seen = set()
    unique_pron = [p for p in pronunciation_issues if p.get("word") and p["word"] not in seen and not seen.add(p["word"])]
    
    # Add summary to feedback response
    feedback["summary"] = {
        "grammar": {"total_errors": len(unique_grammar), "errors": unique_grammar},
        "vocabulary": {"total_suggestions": len(unique_vocab), "suggestions": unique_vocab},
        "pronunciation": {"total_issues": len(unique_pron), "issues": unique_pron}
    }
    
    # Aggregate vocab CEFR words and WPM per turn
    wpm_per_turn = []
    vocab_overall = {
        "A1": {"count": 0, "words": []},
        "A2": {"count": 0, "words": []},
        "B1": {"count": 0, "words": []},
        "B2": {"count": 0, "words": []},
        "C1": {"count": 0, "words": []},
        "C2": {"count": 0, "words": []}
    }
    
    for i, turn in enumerate(turn_feedback, 1):
        # Track WPM per turn
        fluency_data = turn.get("fluency") or {}
        turn_wpm = fluency_data.get("wpm", 0) if fluency_data else 0
        wpm_per_turn.append({"turn": i, "wpm": turn_wpm})
        
        # Aggregate CEFR vocabulary words
        vocab_data = turn.get("vocabulary") or {}
        cefr_dist = vocab_data.get("cefr_distribution", {}) if vocab_data else {}
        for level in ["A1", "A2", "B1", "B2", "C1", "C2"]:
            level_data = cefr_dist.get(level, {})
            if isinstance(level_data, dict):
                words = level_data.get("words", [])
                if isinstance(words, list):
                    safe_words = [w for w in words if isinstance(w, str)]
                    vocab_overall[level]["words"].extend(safe_words)
                    vocab_overall[level]["count"] = len(set(vocab_overall[level]["words"]))
    
    # Deduplicate vocab words and calculate percentages
    total_vocab_words = sum(len(set(vocab_overall[level]["words"])) for level in vocab_overall)
    for level in vocab_overall:
        vocab_overall[level]["words"] = list(set(vocab_overall[level]["words"]))
        vocab_overall[level]["count"] = len(vocab_overall[level]["words"])
        vocab_overall[level]["percentage"] = round((vocab_overall[level]["count"] / total_vocab_words * 100), 1) if total_vocab_words > 0 else 0
    
    feedback["wpm_per_turn"] = wpm_per_turn
    feedback["vocab_overall"] = vocab_overall
    
    return feedback







@router.get("/feedback_summary/{session_id}")
async def get_fluent_feedback_summary(session_id: str):
    """
    Get simplified feedback summary - just wrong/correct pairs.
    
    Extracts grammar errors, vocabulary suggestions, and pronunciation issues
    from all turns in a clean format without explanations.
    """
    feedback = await db.get_session_feedback(session_id)
    if not feedback:
        raise HTTPException(status_code=404, detail="Session not found")
    if feedback["session_type"] != "fluent":
        raise HTTPException(status_code=400, detail="Not a fluent session")
    
    # Extract all errors/corrections from turn feedback
    grammar_errors = []
    vocabulary_suggestions = []
    pronunciation_issues = []
    
    turn_feedback = feedback.get("turn_feedback", [])
    
    for turn in turn_feedback:
        # Grammar errors - extract wrong/correct
        grammar = turn.get("grammar", {})
        errors = grammar.get("errors", [])
        for err in errors:
            if isinstance(err, dict):
                grammar_errors.append({
                    "wrong": err.get("you_said", err.get("wrong_word", "")),
                    "correct": err.get("should_be", err.get("correct_word", ""))
                })
        
        # Vocabulary suggestions - extract weak word/better options
        vocab = turn.get("vocabulary", {})
        suggestions = vocab.get("suggestions", [])
        for sug in suggestions:
            if isinstance(sug, dict):
                vocabulary_suggestions.append({
                    "weak_word": sug.get("word", sug.get("weak_word", "")),
                    "better_options": sug.get("better_options", sug.get("better_word", []))
                })
        
        # Pronunciation issues - extract words to practice
        pron = turn.get("pronunciation", {})
        words_to_practice = pron.get("words_to_practice", [])
        for word in words_to_practice:
            if isinstance(word, dict):
                pronunciation_issues.append({
                    "word": word.get("word", ""),
                    "issue": word.get("issue", "needs practice")
                })
            elif isinstance(word, str):
                pronunciation_issues.append({
                    "word": word,
                    "issue": "needs practice"
                })
    
    # Remove duplicates
    seen_grammar = set()
    unique_grammar = []
    for g in grammar_errors:
        key = (g.get("wrong", ""), g.get("correct", ""))
        if key not in seen_grammar and key[0]:
            seen_grammar.add(key)
            unique_grammar.append(g)
    
    seen_vocab = set()
    unique_vocab = []
    for v in vocabulary_suggestions:
        key = v.get("weak_word", "")
        if key not in seen_vocab and key:
            seen_vocab.add(key)
            unique_vocab.append(v)
    
    seen_pron = set()
    unique_pron = []
    for p in pronunciation_issues:
        key = p.get("word", "")
        if key not in seen_pron and key:
            seen_pron.add(key)
            unique_pron.append(p)
    
    return {
        "session_id": session_id,
        "total_turns": len(turn_feedback),
        "grammar": {
            "total_errors": len(unique_grammar),
            "errors": unique_grammar
        },
        "vocabulary": {
            "total_suggestions": len(unique_vocab),
            "suggestions": unique_vocab
        },
        "pronunciation": {
            "total_issues": len(unique_pron),
            "issues": unique_pron
        }
    }

@router.get("/user_sessions")
async def get_fluent_sessions_by_user(
    scenario: Optional[str] = None,
    current_user: User = Depends(get_current_user)
):
    """
  
    Optionally filter by scenario (e.g., 'ordering_food', 'hotel_checkin', 'travel').
    Returns sessions with session_ids included.
    """
    user_id = current_user.id
    sessions = await db.get_sessions_by_user_id(user_id, session_type="fluent")

    # Keep only completed sessions (ended via action=end -> complete_session sets status=completed)
    filtered_sessions = []
    for session in sessions:
        session_data = await db.get_user_session(session.get("session_id"))
        if not session_data:
            continue

        if session_data.get("status") != "completed":
            continue

        session_scenario = session_data.get("scenario", "unknown")
        if scenario and session_scenario != scenario:
            continue

        session["scenario"] = session_scenario
        filtered_sessions.append(session)

    sessions = filtered_sessions
    
    for idx, session in enumerate(sessions, 1):
        session["session_number"] = f"Session {idx}"
    
    session_ids = [s.get("session_id") for s in sessions]
    
    return {
        "user_id": user_id,
        "total_sessions": len(sessions),
        "filter": {"scenario": scenario} if scenario else None,
        "session_ids": session_ids,
        "sessions": sessions
    }


@router.get("/scenarios")
async def get_user_scenarios_from_db(current_user: User = Depends(get_current_user)):
    """
    Get distinct scenarios practiced by the current user from DB session data.
    """
    user_id = current_user.id if current_user else None
    sessions = await db.get_sessions_by_user_id(user_id, session_type="fluent")
    scenario_set = set()
    for session in sessions:
        session_data = await db.get_user_session(session.get("session_id"))
        if not session_data:
            continue
        if session_data.get("status") != "completed":
            continue
        session_scenario = session_data.get("scenario")
        if session_scenario:
            scenario_set.add(session_scenario)
    scenarios = sorted(scenario_set)
    return {
        "status": "success",
        "user_id": user_id,
        "total_scenarios": len(scenarios),
        "scenarios": scenarios
    }
@router.get("/session_ids_by_scenario")
async def get_fluent_session_ids_by_scenario(
    scenario: str,
    current_user: User = Depends(get_current_user)
):
    """
    Get session IDs for fluent sessions filtered by scenario for the current user.
    """
    user_id = current_user.id if current_user else None
    sessions = await db.get_sessions_by_user_id(user_id, session_type="fluent")

    ids = []
    for s in sessions:
        data = await db.get_user_session(s.get("session_id"))
        if data and data.get("status") == "completed" and data.get("scenario") == scenario:
            ids.append(s.get("session_id"))

    return {"user_id": user_id, "scenario": scenario, "session_ids": ids}

@router.get("/scenarios_filtered")
async def get_user_scenarios_from_db(current_user: User = Depends(get_current_user)):
    """
    Get distinct scenarios practiced by the current user from DB session data.
    Excludes scenarios that match context_names from ChatManagement table.
    """
    from sqlalchemy import text
    import asyncio
    
    user_id = current_user.id if current_user else None
    sessions = await db.get_sessions_by_user_id(user_id, session_type="fluent")
    scenario_set = set()
    for session in sessions:
        session_data = await db.get_user_session(session.get("session_id"))
        if not session_data:
            continue
        if session_data.get("status") != "completed":
            continue
        session_scenario = session_data.get("scenario")
        if session_scenario:
            scenario_set.add(session_scenario)
    scenarios = sorted(scenario_set)
    
    # Get context_names from ChatManagement (sync db) to filter out
    def get_context_names_sync():
        sync_db = SessionLocal()
        try:
            result = sync_db.execute(text("SELECT DISTINCT context_name FROM chat_management WHERE context_name IS NOT NULL"))
            return [r[0] for r in result.fetchall() if r[0]]
        finally:
            sync_db.close()
    
    try:
        loop = asyncio.get_event_loop()
        context_names = await loop.run_in_executor(None, get_context_names_sync)
        # Filter out scenarios that match any context_name (case-insensitive)
        context_names_lower = [cn.lower() for cn in context_names]
        filtered_scenarios = [s for s in scenarios if s.lower() not in context_names_lower]
    except Exception:
        # If ChatManagement table doesn't exist or query fails, return all scenarios
        filtered_scenarios = scenarios
    
    return {
        "status": "success",
        "user_id": user_id,
        "total_scenarios": len(filtered_scenarios),
        "scenarios": filtered_scenarios
    }---------------------------------------------------------
import asyncio
import json
import logging
import os
import re
import shutil
import tempfile
import uuid
from typing import Optional

from fastapi import APIRouter, Form, File, UploadFile, HTTPException, Request, Depends
from faster_whisper import WhisperModel
from deep_translator import GoogleTranslator
from openai import AzureOpenAI
from pydub import AudioSegment
from logger_setup import logger
from utils.tts_utils import generate_tts_url


# from models import agent_db as db

from models import User
from db.agents_db import chat_session_db as db
from utils.agents_utils import load_language_mapping, normalize_language_code
from utils.user_details import get_current_user

 
AZURE_OPENAI_VERSION = "2025-01-01-preview"

llm_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)


# from utils.common_utils import llm_client

# AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")

QWEN_ENABLED = False
qwen_client = None  
QWEN_MODEL_NAME = "Qwen/Qwen3-0.6B"  

_whisper_model = WhisperModel("large-v3", compute_type="int8")

router = APIRouter()

BOT_NAME = "Clara"
PASSING_SCORE = 50
TERMINATION_PHRASES = ["exit", "stop", "end", "finish", "quit", "done", "bye", "goodbye"]

def normalize_user_type(user_type: Optional[str]) -> str:
    """Normalize user_type to 'student' or 'professional'."""
    if not user_type:
        return "student"
    value = user_type.strip().lower()
    student_values = {
        "student", "fresher", "freshers", "college", "campus", "intern",
        "internship", "new grad", "newgrad", "graduate", "entry", "entry-level"
    }
    professional_values = {
        "professional", "experienced", "exp", "pro", "working", "industry"
    }
    if value in student_values:
        return "student"
    if value in professional_values:
        return "professional"
    if any(token in value for token in ["student", "fresher", "college", "campus", "intern", "new grad", "graduate", "entry"]):
        return "student"
    return "professional"

INTERVIEW_SCENARIOS = {
    "marketing": "Marketing Executive HR Interview",
    "sales": "Sales Representative HR Interview",
    "software": "Software Engineer HR Interview (Non-Technical)",
    "business_analyst": "Business Analyst HR Interview",
    "self_intro": "Self Introduction",
    "college_interview": "College Admission Interview",
    "job_interview": "General Job Interview",
    "professor_talk": "Talk with Professor",
    "behavioral": "Behavioral Interview",
    "technical": "Technical Interview"
}


GRAMMAR_FIELDS = ["feedback", "filler_feedback", "errors", "word_suggestions", "corrected_sentence", "improved_sentence", "strengths"]
VOCAB_FIELDS = ["feedback", "suggestions", "word_levels"]
PRON_FIELDS = ["feedback", "words_to_practice"]
FLUENCY_FIELDS = ["feedback"]
EVAL_FIELDS = ["clarity", "structure", "relevance", "confidence", "issue_summary", "improved_answer"]
PERSONAL_FIELDS = ["message", "improvement_areas", "strengths"]

async def call_llm(prompt: str, mode: str = "chat", timeout: int = 30, model: str = "gpt", target_language: str = "en") -> str:
    """async llm call with proper error handling and timeout. Supports gpt (default) or qwen."""
    base_prompts = {
        "chat": "You are a kind, human-like conversational interview coach.",
        "analysis": "You are an expert language evaluator. Analyze objectively and concisely.",
        "strict_json": "You are a structured evaluator. Respond ONLY in valid JSON. No extra text."
    }
    
    lang_lower = target_language.lower() if target_language else "en"
    is_english = lang_lower in ["en", "english"]
    lang_instruction = f" IMPORTANT: Respond entirely in {target_language} language." if not is_english else ""
    system_prompts = {k: v + lang_instruction for k, v in base_prompts.items()}
    
    
    requested_model = (model or "gpt").strip()
    requested_model_lower = requested_model.lower()

    if requested_model_lower == "qwen" and QWEN_ENABLED and qwen_client is not None:
        try:
            
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    qwen_client.chat.completions.create,
                    model=QWEN_MODEL_NAME,
                    messages=[
                        {"role": "system", "content": system_prompts.get(mode, system_prompts["chat"])},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=800,
                    temperature=0.7 if mode == "chat" else 0.3
                ),
                timeout=timeout
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.warning(f"Qwen call failed, falling back to GPT: {e}")
            
    
    
    try:
        response = await asyncio.wait_for(
            asyncio.to_thread(
                llm_client.chat.completions.create,
                model=AZURE_OPENAI_DEPLOYMENT if requested_model_lower in {"", "gpt", "qwen"} else requested_model,
                messages=[
                    {"role": "system", "content": system_prompts.get(mode, system_prompts["chat"])},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7 if mode == "chat" else 0.3
            ),
            timeout=timeout
        )
        return response.choices[0].message.content.strip()
    except asyncio.TimeoutError:
        logger.error(f"LLM call timed out after {timeout}s")
        return ""
    except Exception as e:
        logger.error(f"LLM call failed: {e}")
        return ""


async def translate_text(text: str, source: str, target: str) -> str:
    """translate text between languages"""
    if source == target or not text or not isinstance(text, str):
        return text if isinstance(text, str) else ""
    try:
        translator = GoogleTranslator(source=source, target=target)
        return await asyncio.to_thread(translator.translate, text)
    except Exception as e:
        logger.debug(f"Translation failed: {e}")
        return text


async def translate_if_needed(text: str, target_language: str) -> str:
    """Translate English fallback text into target language when needed."""
    if not isinstance(text, str):
        return text
    if not target_language or target_language.lower() in ["en", "english"]:
        return text
    return await translate_text(text, "en", target_language)


async def translate_values(value, target_language: str):
    """Translate all string values in nested structures to target language."""
    if not target_language or target_language.lower() in ["en", "english"]:
        return value
    if isinstance(value, str):
        return await translate_text(value, "en", target_language)
    if isinstance(value, list):
        return [await translate_values(v, target_language) for v in value]
    if isinstance(value, dict):
        return {k: await translate_values(v, target_language) for k, v in value.items()}
    return value


async def make_bilingual(value, source: str, target: str):
    """Convert a value to {target, native} structure with translations"""
    if source == target:
        return value  
    
    if isinstance(value, str):
        if not value.strip():
            return {"target": value, "native": value}
        native = await translate_text(value, source, target)
        return {"target": value, "native": native}
    
    elif isinstance(value, list):
        result = []
        for item in value:
            if isinstance(item, dict):
                
                translated_item = {}
                for k, v in item.items():
                    translated_item[k] = await make_bilingual(v, source, target)
                result.append(translated_item)
            elif isinstance(item, str):
                native = await translate_text(item, source, target)
                result.append({"target": item, "native": native})
            else:
                result.append(item)
        return result
    
    elif isinstance(value, dict):
        
        result = {}
        for k, v in value.items():
            result[k] = await make_bilingual(v, source, target)
        return result
    
    else:
        return value


async def translate_analysis(analysis: dict, source: str, target: str, fields_to_translate: list) -> dict:
    """Translate specified fields in analysis dict to target/native format"""
    if source == target:
        return analysis  
    
    result = {}
    for key, value in analysis.items():
        if key in fields_to_translate:
            result[key] = await make_bilingual(value, source, target)
        else:
            result[key] = value  
    return result

# BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
# language_codes_path = os.path.join(BASE_DIR, "language-codes.json")

# def load_language_mapping():
#     try:
#         if not os.path.exists(language_codes_path):
#             logger.error(f"File not found - {language_codes_path}")
            
#         with open(language_codes_path, "r") as f:
#             language_codes = json.load(f)
#             print("Language codes loaded:", language_codes)
#             return language_codes
#     except:
#         logger.error("Error loading language mapping.")
#         return {}


async def transcribe_audio_file(audio_file: UploadFile, target_lang: str = "en") -> str:
    """Transcribe audio forcing target language (no auto-detect)."""
    try:
        audio_file.file.seek(0)
    except Exception:
        pass
    with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp:
        shutil.copyfileobj(audio_file.file, tmp)
        temp_upload = tmp.name
    
    audio_path = None
    try:
        audio = AudioSegment.from_file(temp_upload)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio_path = temp_upload.replace('.tmp', '_converted.wav')
        audio.export(audio_path, format="wav")

        # Normalize target language code using load_language_mapping (consistent with fluent_api_v2.py)
        languages_data = load_language_mapping()
        normalized_target = languages_data.get(target_lang.lower(), target_lang.lower()) if target_lang else "en"

        # Force Whisper to transcribe in the target language
        logger.debug(f"Transcribing audio with forced language: {normalized_target}")
        segments, info = await asyncio.to_thread(
            _whisper_model.transcribe, audio_path, task="transcribe", language=normalized_target
        )
        user_text = " ".join([seg.text for seg in segments]).strip()
        logger.debug(f"Whisper transcribed in {normalized_target}: {user_text[:100] if user_text else 'empty'}")

        return user_text
    except Exception as e:
        logger.debug(f"Audio transcription failed: {e}")
        return ""
    finally:
        
        if os.path.exists(temp_upload):
            try:
                os.unlink(temp_upload)
            except Exception:
                pass
        if audio_path and os.path.exists(audio_path):
            try:
                os.unlink(audio_path)
            except Exception:
                pass

TYPE_KEYWORDS = {
    "hr": "hr", "human resource": "hr", "behavioral": "behavioral", "behavior": "behavioral",
    "technical": "technical", "tech": "technical", "managerial": "managerial", "management": "managerial",
    "general": "general", "normal": "general"
}


# async def extract_role_from_text(user_text: str, model: str = "gpt") -> dict:
#     """Extract job role from natural language using LLM only - accepts ANY role"""
    
#     prompt = f"""Extract the job role/position from this text: "{user_text}"

# If a job role/position is mentioned (e.g., "software engineer", "electrical engineer", "teacher", "chef", "pilot", etc.), 
# extract it EXACTLY as the user said it and capitalize properly.

# Return JSON: {{"success": true, "role": "Exact Job Title"}}
# If no job role is mentioned: {{"success": false, "role": null}}

# Return ONLY valid JSON."""
    
#     try:
#         raw = await call_llm(prompt, mode="strict_json", timeout=10, model=model)
#         json_match = re.search(r'\{[\s\S]*\}', raw)
#         if json_match:
#             result = json.loads(json_match.group())
#             if result.get("success") and result.get("role"):
#                 return result
#     except:
#         pass
    
#     return {"success": False, "role": None}


import shutil
ffmpeg = shutil.which("ffmpeg")

async def extract_role_from_text(user_text: str, model: str = "gpt") -> dict:
   """Extract job role from natural language using LLM - accepts ANY role from audio"""
   user_lower = user_text.lower().strip()
   # If text is empty or too short
   if not user_lower or len(user_lower) < 2:
       return {"success": False, "role": None}
       
   prompt = f"""You are extracting a JOB ROLE/POSITION from user's SPEECH/AUDIO transcription.
        USER SAID: "{user_text}"
        YOUR TASK: Extract the JOB ROLE or POSITION they mentioned.
        CRITICAL RULES:
        1. Extract WHATEVER job role/position the user mentioned - it can be ANY job
        2. The user's audio might have transcription errors - understand the intent
        3. Capitalize the job title properly (e.g., "Software Engineer", "Data Scientist")
        4. Accept ANY job: traditional roles, modern roles, creative roles, anything
        EXAMPLES:
        - "software engineer" â†’ "Software Engineer"
        - "I want to practice for data scientist role" â†’ "Data Scientist"
        - "marketing" â†’ "Marketing Manager"
        - "teacher" â†’ "Teacher"
        - "chef" â†’ "Chef"
        - "machine learning engineer" â†’ "Machine Learning Engineer"
        - "product manager" â†’ "Product Manager"
        - "nurse" â†’ "Nurse"
        - "electrical engineer" â†’ "Electrical Engineer"
        - "content writer" â†’ "Content Writer"
        - "UI UX designer" â†’ "UI/UX Designer"
        - "devops" â†’ "DevOps Engineer"
        - "full stack developer" â†’ "Full Stack Developer"
        - "hr" â†’ "HR Manager"
        - "sales" â†’ "Sales Executive"
        - "accountant" â†’ "Accountant"
        - ANY job mentioned â†’ extract and capitalize properly
        Return ONLY this JSON format:
        {{"success": true, "role": "Properly Capitalized Job Title"}}
        If NO job role is mentioned at all:
        {{"success": false, "role": null}}
        DO NOT explain. Return ONLY the JSON.
    """
   try:
       raw = await call_llm(prompt, mode="strict_json", timeout=15, model=model)
       json_match = re.search(r'\{[\s\S]*\}', raw)
       if json_match:
           result = json.loads(json_match.group())
           if result.get("success") and result.get("role"):
               return result
   except Exception as e:
       logger.exception(f"LLM role extraction failed: {e}")

   # Fallback: Try to extract role from user's words directly
   # Remove common filler words and non-meaningful sounds
   filler_words = {"i", "want", "to", "practice", "for", "the", "a", "an", "role", "position", "job", "interview", "as"}
   non_meaningful_sounds = {"hmm", "hm", "um", "uh", "uhh", "er", "err", "ah", "ahh", "oh", "okay", "ok", "yes", "no", "yeah", "yep", "nope", "like", "well", "so", "just", "maybe", "hmmmm", "ummm", "uhhh"}
   words = [w for w in re.findall(r'[a-z]+', user_lower)
            if w not in filler_words and w not in non_meaningful_sounds and len(w) > 2]
   if words:
       # Capitalize each word and join as role
       role = " ".join(word.capitalize() for word in words[:4])  # Take up to 4 words
       return {"success": True, "role": role}

   # No meaningful role found - return False so user can be asked to clarify
   return {"success": False, "role": None}


async def extract_interview_type_from_text(user_text: str, model: str = "gpt") -> dict:
    """Extract interview type from natural language - accepts ANY type"""
    user_lower = user_text.lower()
    
    
    for keyword, itype in TYPE_KEYWORDS.items():
        if keyword in user_lower:
            return {"success": True, "type": itype, "confidence": "high"}
    
    
    prompt = f"""Extract the interview type from: "{user_text}"

IMPORTANT: Accept ANY type of interview the user mentions, not just predefined ones.
Examples: hr, behavioral, technical, managerial, sales, marketing, customer service, finance, product management, design, data science, etc.

If user mentions ANY interview type, extract and format it:
- Return: {{"success": true, "type": "extracted_type_in_lowercase", "confidence": "high"}}
- Example: "I want a sales interview" â†’ {{"success": true, "type": "sales", "confidence": "high"}}
- Example: "customer service role" â†’ {{"success": true, "type": "customer_service", "confidence": "high"}}

If the text is completely unclear or no interview type is mentioned at all:
- Return: {{"success": false, "type": "general", "confidence": "low"}}

Return ONLY valid JSON."""
    
    try:
        raw = await call_llm(prompt, mode="strict_json", timeout=10, model=model)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            result = json.loads(json_match.group())
            
            if result.get("type"):
                result["success"] = True
            return result
    except Exception:
        pass
    
    return {"success": True, "type": "general", "confidence": "low"}


async def check_answer_relevance(question: str, answer: str, model: str = "gpt", target_language: str = "en") -> dict:
    """Check if answer is relevant to question, generate friendly redirect if not"""
    
    if len(answer.split()) < 5:
        return {"relevant": True}
    
    prompt = f"""You are an interview coach. Check if this answer is COMPLETELY IRRELEVANT to the question.

Question: "{question}"
Answer: "{answer}"
Target Language: "{target_language}"

IMPORTANT RULES:
1. Be VERY LENIENT - only mark as irrelevant if the answer is about a COMPLETELY DIFFERENT TOPIC
2. If the answer even SLIGHTLY relates to the question, mark it as relevant
3. Personal stories, examples, or tangential answers should be marked RELEVANT
4. Only mark irrelevant if user talks about something totally unrelated (e.g., asked about skills but talks about weather)
5. If the answer is irrelevant, write the redirect message in the Target Language specified above

If relevant (even slightly), return: {{"relevant": true}}
If COMPLETELY UNRELATED (different topic entirely), return: {{"relevant": false, "redirect": "friendly 1-line message in the target language"}}

Return ONLY valid JSON."""
    
    try:
        raw = await call_llm(prompt, mode="strict_json", timeout=10, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            result = json.loads(json_match.group())
            
            if not result.get("relevant", True) and not result.get("redirect"):
                return {"relevant": True}
            return result
    except Exception:
        pass
    return {"relevant": True}  


async def compare_attempts(attempts: list, level: str = "B1", user_type: str = "professional", model: str = "gpt", target_language: str = "en") -> dict:
    """
    Compare interview attempts using LLM for detailed, elaborative feedback on ALL aspects:
    grammar, vocabulary, pronunciation, fluency, and answer quality.
    """
    if len(attempts) < 2:
        summary = "This is your first attempt. Let's see how you do!"
        if target_language and target_language != "en":
            try:
                summary = await translate_text(summary, "en", target_language)
            except Exception as e:
                logger.debug(f"Compare attempts fallback translation failed: {e}")
        return {
            "overall_improvement": 0,
            "trend": "first_attempt",
            "overall_summary": summary,
            "details": {}
        }
    
    prev = attempts[-2]
    current = attempts[-1]
    
    
    prev_grammar = (prev.get("grammar") or {}).get("score", 0) or 0
    current_grammar = (current.get("grammar") or {}).get("score", 0) or 0
    
    prev_vocab = (prev.get("vocabulary") or {}).get("score", 0) or 0
    current_vocab = (current.get("vocabulary") or {}).get("score", 0) or 0
    
    prev_pron = (prev.get("pronunciation") or {}).get("accuracy", 0) or 0
    current_pron = (current.get("pronunciation") or {}).get("accuracy", 0) or 0
    
    prev_fluency = (prev.get("fluency") or {}).get("score", 0) or 0
    current_fluency = (current.get("fluency") or {}).get("score", 0) or 0
    
    prev_answer = (prev.get("answer_evaluation") or {}).get("score", 0) or 0
    current_answer = (current.get("answer_evaluation") or {}).get("score", 0) or 0
    
    prev_overall = prev.get("overall_score", 0) or 0
    current_overall = current.get("overall_score", 0) or 0
    
    
    grammar_diff = round(current_grammar - prev_grammar, 1)
    vocab_diff = round(current_vocab - prev_vocab, 1)
    pron_diff = round(current_pron - prev_pron, 1)
    fluency_diff = round(current_fluency - prev_fluency, 1)
    answer_diff = round(current_answer - prev_answer, 1)
    overall_diff = round(current_overall - prev_overall, 1)
    
    
    if overall_diff > 10:
        trend = "significantly_improved"
    elif overall_diff > 0:
        trend = "improved"
    elif overall_diff < -10:
        trend = "declined"
    elif overall_diff < 0:
        trend = "slightly_declined"
    else:
        trend = "no_change"
    
    prompt = f"""You are an expert interview coach comparing TWO attempts at the SAME question.
Respond in the target language: {target_language}.
Provide DETAILED, ELABORATIVE feedback on improvement or decline in ALL areas.

PREVIOUS ATTEMPT:
- Overall Score: {prev_overall}%
- Grammar: {prev_grammar}%
- Vocabulary: {prev_vocab}%
- Pronunciation: {prev_pron}%
- Fluency: {prev_fluency}%
- Answer Quality: {prev_answer}%
- What they said: "{prev.get('transcription', '')[:200]}"

CURRENT ATTEMPT:
- Overall Score: {current_overall}%
- Grammar: {current_grammar}% ({'+' if grammar_diff > 0 else ''}{grammar_diff}%)
- Vocabulary: {current_vocab}% ({'+' if vocab_diff > 0 else ''}{vocab_diff}%)
- Pronunciation: {current_pron}% ({'+' if pron_diff > 0 else ''}{pron_diff}%)
- Fluency: {current_fluency}% ({'+' if fluency_diff > 0 else ''}{fluency_diff}%)
- Answer Quality: {current_answer}% ({'+' if answer_diff > 0 else ''}{answer_diff}%)
- What they said: "{current.get('transcription', '')[:200]}"

USER CONTEXT:
- Level: {level}
- User Type: {user_type}

Analyze EACH category's improvement and provide detailed, professional feedback.

Return STRICTLY valid JSON:
{{
    "overall_summary": "3-4 sentences summarizing the overall improvement journey in a professional tone.",
    "grammar_analysis": {{
        "previous_score": {prev_grammar}, "current_score": {current_grammar}, "difference": {grammar_diff},
        "improved": {str(grammar_diff > 0).lower()},
        "feedback": "Specific feedback about grammar improvement."
    }},
    "vocabulary_analysis": {{
        "previous_score": {prev_vocab}, "current_score": {current_vocab}, "difference": {vocab_diff},
        "improved": {str(vocab_diff > 0).lower()},
        "feedback": "Specific feedback about vocabulary usage."
    }},
    "pronunciation_analysis": {{
        "previous_score": {prev_pron}, "current_score": {current_pron}, "difference": {pron_diff},
        "improved": {str(pron_diff > 0).lower()},
        "feedback": "Specific feedback about pronunciation."
    }},
    "fluency_analysis": {{
        "previous_score": {prev_fluency}, "current_score": {current_fluency}, "difference": {fluency_diff},
        "improved": {str(fluency_diff > 0).lower()},
        "feedback": "Specific feedback about speaking pace."
    }},
    "answer_analysis": {{
        "previous_score": {prev_answer}, "current_score": {current_answer}, "difference": {answer_diff},
        "improved": {str(answer_diff > 0).lower()},
        "feedback": "Specific feedback about answer quality, structure, and relevance."
    }},
    "biggest_improvement": "Which area improved the most",
    "area_needing_focus": "Which area still needs work",
    "encouragement": "Professional, encouraging message",
    "next_step_tip": "One specific tip for continued improvement"
}}"""

    try:
        llm_response = await call_llm(prompt, mode="strict_json", timeout=30, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', llm_response)
        if json_match:
            llm_data = json.loads(json_match.group())
        else:
            raise ValueError("No JSON")
    except Exception as e:
        logger.debug(f"LLM compare_attempts fallback: {e}")
        if overall_diff > 0:
            summary = f"Great progress! Your overall score improved from {prev_overall}% to {current_overall}% (+{overall_diff}%)."
        elif overall_diff < 0:
            summary = f"Your score changed from {prev_overall}% to {current_overall}% ({overall_diff}%). Let's work on consistency."
        else:
            summary = f"Consistent performance at {current_overall}%. Try varying your approach for improvement."
        
        area_diffs = {
            "grammar": grammar_diff,
            "vocabulary": vocab_diff,
            "pronunciation": pron_diff,
            "fluency": fluency_diff,
            "answer quality": answer_diff
        }

        llm_data = {
            "overall_summary": summary,
            "grammar_analysis": {"previous_score": prev_grammar, "current_score": current_grammar, "difference": grammar_diff, "improved": grammar_diff > 0, "feedback": f"Grammar {'improved' if grammar_diff > 0 else 'needs focus'}"},
            "vocabulary_analysis": {"previous_score": prev_vocab, "current_score": current_vocab, "difference": vocab_diff, "improved": vocab_diff > 0, "feedback": f"Vocabulary {'improved' if vocab_diff > 0 else 'needs focus'}"},
            "pronunciation_analysis": {"previous_score": prev_pron, "current_score": current_pron, "difference": pron_diff, "improved": pron_diff > 0, "feedback": f"Pronunciation {'improved' if pron_diff > 0 else 'needs focus'}"},
            "fluency_analysis": {"previous_score": prev_fluency, "current_score": current_fluency, "difference": fluency_diff, "improved": fluency_diff > 0, "feedback": f"Fluency {'improved' if fluency_diff > 0 else 'needs focus'}"},
            "answer_analysis": {"previous_score": prev_answer, "current_score": current_answer, "difference": answer_diff, "improved": answer_diff > 0, "feedback": f"Answer quality {'improved' if answer_diff > 0 else 'needs focus'}"},
            "biggest_improvement": max(area_diffs, key=area_diffs.get),
            "area_needing_focus": min(area_diffs, key=area_diffs.get),
            "encouragement": f"Keep practicing! Your overall score {'improved' if overall_diff > 0 else 'stayed consistent'}.",
            "next_step_tip": "Focus on structuring your answers clearly."
        }
        if target_language and target_language.lower() not in ["en", "english"]:
            llm_data = await translate_values(llm_data, target_language)
    
    return {
        "previous_overall_score": prev_overall,
        "current_overall_score": current_overall,
        "overall_improvement": overall_diff,
        "trend": trend,
        "overall_summary": llm_data.get("overall_summary", ""),
        "grammar_analysis": llm_data.get("grammar_analysis", {}),
        "vocabulary_analysis": llm_data.get("vocabulary_analysis", {}),
        "pronunciation_analysis": llm_data.get("pronunciation_analysis", {}),
        "fluency_analysis": llm_data.get("fluency_analysis", {}),
        "answer_analysis": llm_data.get("answer_analysis", {}),
        "biggest_improvement": llm_data.get("biggest_improvement", ""),
        "area_needing_focus": llm_data.get("area_needing_focus", ""),
        "encouragement": llm_data.get("encouragement", ""),
        "next_step_tip": llm_data.get("next_step_tip", "")
    }


async def generate_interactive_follow_up(user_response: str, chat_history: list, role: str, scenario: str, user_type: str = "student", model: str = "gpt", target_language: str = "en") -> tuple:
    """Generate interactive follow-up question with natural transitions"""
    
    recent_history = chat_history[-6:] if len(chat_history) > 6 else chat_history
    user_type = normalize_user_type(user_type)
    
    prompt = f"""You are {BOT_NAME}, a warm and engaging interview coach conducting a {scenario} interview for a {role} position.

    Respond in the target language: {target_language}.
    Candidate type: {user_type} (student/fresher vs professional/experienced)

    The candidate just said: "{user_response}"

Recent conversation context:
{[msg.get('content', '')[:100] for msg in recent_history[-4:]]}

CRITICAL RULES for your follow-up:
1. NEVER start with generic phrases like "That's interesting", "Great answer", "I see"
2. START by referencing something SPECIFIC they said (a keyword, example, or detail)
    3. Ask a PROBING follow-up that digs deeper or explores a new angle
    4. Include ONE encouraging word naturally (e.g., "I love that you mentioned...", "It's impressive how...")
    5. Make it conversational - like a real interview, not a quiz
    6. STRICT: If student/fresher, focus on college projects, internships, coursework, campus activities; do NOT assume work experience
    7. STRICT: If professional, focus on work experience, impact, leadership, production systems, stakeholder management

    VARIETY - Use different question types:
    - "Building on what you said about X, how would you..."
- "You mentioned X - can you walk me through a specific time when..."
- "That's a thoughtful approach to X. What challenges did you face with..."
- "I'm curious about the X you mentioned. How did that experience shape..."

Return STRICTLY valid JSON:
{{"question": "Your engaging, specific follow-up (reference their answer!)", "hint": "One practical tip for answering"}}"""

    fallback_question, fallback_hint, fallback_question_alt, fallback_hint_alt = await asyncio.gather(
        translate_if_needed("Tell me more about that.", target_language),
        translate_if_needed("Share more details.", target_language),
        translate_if_needed("Tell me more about that experience.", target_language),
        translate_if_needed("Elaborate on a specific example.", target_language)
    )
    try:
        raw = await call_llm(prompt, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("question", fallback_question), data.get("hint", fallback_hint)
    except Exception:
        pass
    return fallback_question_alt, fallback_hint_alt

async def generate_interview_question(scenario: str, role: str, level: str, user_name: str, user_type: str = "student", model: str = "gpt", target_language: str = "en", turn_number: int = 0) -> tuple:
    """generate interview question with hint - first question is always an opener"""
    scenario_name = INTERVIEW_SCENARIOS.get(scenario, scenario)
    user_type = normalize_user_type(user_type)
    
    # First question should always be a standard opener
    if turn_number == 0:
        prompt = f"""You are {BOT_NAME}, a warm interview coach.

Respond in the target language: {target_language}.

    Interview scenario: {scenario_name}
    Role: {role}
    Candidate: {user_name}
    Candidate type: {user_type} (student/fresher vs professional/experienced)

    This is the FIRST question of the interview. Ask a classic opening question like:
    - "Tell me about yourself"
    - "Walk me through your background"
    - "What brings you here today?"
    STRICT: If student/fresher, ask about academic background, college projects, internships, or coursework
    STRICT: If professional, ask about recent roles, impact, and relevant experience

    Make it warm and welcoming. Keep it short and natural.

Return STRICTLY valid JSON:
{{"question": "your opening question", "hint": "suggested answer approach - mention key experiences and why you're interested in this role"}}
"""
    else:
        # Later questions should be type-specific
        prompt = f"""You are {BOT_NAME}, a warm interview coach.

Respond in the target language: {target_language}.

    Interview scenario: {scenario_name}
    Role: {role}
    Level: {level}
    Candidate: {user_name}
    Candidate type: {user_type} (student/fresher vs professional/experienced)
    Question Number: {turn_number + 1}

    Ask ONE natural interview question appropriate for this {scenario_name}.
    - For HR interviews: Ask about motivation, career goals, cultural fit, salary expectations
    - For Technical interviews: Ask about technical skills, problem-solving, coding concepts relevant to {role}
    - For Behavioral interviews: Ask situational questions (STAR method) about past experiences
    - For other types: Ask relevant domain-specific questions
    STRICT: If student/fresher, focus on college projects, internships, coursework, campus leadership, hackathons; avoid years of work experience
    STRICT: If professional, focus on work experience, impact, leadership, production systems, stakeholder management

    Provide ONE short hint for the candidate.

Return STRICTLY valid JSON:
{{"question": "your interview question", "hint": "suggested answer approach"}}
"""
    if user_type == "student":
        fallback_question, fallback_hint, fallback_question_alt, fallback_hint_alt = await asyncio.gather(
            translate_if_needed("Tell me about yourself and your academic background.", target_language),
            translate_if_needed("Mention your degree, projects, internships, and why you're interested in this role.", target_language),
            translate_if_needed("Can you walk me through your academic background?", target_language),
            translate_if_needed("Share your key projects or campus experiences and what you learned.", target_language)
        )
    else:
        fallback_question, fallback_hint, fallback_question_alt, fallback_hint_alt = await asyncio.gather(
            translate_if_needed("Tell me about yourself and your recent experience.", target_language),
            translate_if_needed("Summarize your recent role, key impact, and why you're interested in this role.", target_language),
            translate_if_needed("Can you walk me through your recent work experience?", target_language),
            translate_if_needed("Share your key accomplishments and how they relate to this role.", target_language)
        )
    try:
        raw = await call_llm(prompt, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data.get("question", fallback_question), data.get("hint", fallback_hint)
    except Exception as e:
        logger.debug(f"Question generation fallback: {e}")
    return fallback_question_alt, fallback_hint_alt


async def evaluate_answer(question: str, answer: str, level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
    """evaluate interview answer quality"""
    prompt = f"""Evaluate this interview answer:

Question: {question}
Answer: {answer}
Level: {level}

Respond in the target language: {target_language}.

Return STRICTLY valid JSON:
{{
  "clarity": "Clear | Somewhat Clear | Vague",
  "structure": "Well Structured | Needs Improvement | Disorganized",
  "relevance": "Relevant | Partially Relevant | Off-topic",
  "confidence": "Confident | Neutral | Hesitant",
  "issue_summary": "brief specific feedback about the answer",
  "improved_answer": "a better version of their answer",
  "score": 0-100
}}
"""
    try:
        raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            return data
    except Exception as e:
        logger.debug(f"Answer evaluation fallback: {e}")
    fallback = {
        "clarity": "Clear",
        "structure": "Well Structured",
        "relevance": "Relevant",
        "confidence": "Neutral",
        "issue_summary": "Good answer overall.",
        "improved_answer": answer,
        "score": 50
    }
    if target_language and target_language != "en":
        try:
            for key in ["clarity", "structure", "relevance", "confidence", "issue_summary"]:
                fallback[key] = await translate_text(fallback[key], "en", target_language)
        except Exception as e:
            logger.debug(f"Answer evaluation fallback translation failed: {e}")
    return fallback


async def detect_emotion(user_text: str, model: str = "gpt", target_language: str = "en") -> dict:
    """detect emotion from user response"""
    prompt = f"""Analyze the emotional tone of this interview answer:

Answer: "{user_text}"
Target Language: "{target_language}"

Return STRICTLY valid JSON with the explanation written in the Target Language:
{{
  "emotion": "confident | hesitant | nervous | neutral | excited",
  "confidence_level": "high | medium | low",
  "explanation": "brief reason in target language"
}}
"""
    try:
        raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            return json.loads(json_match.group())
    except Exception as e:
        logger.debug(f"Emotion detection fallback: {e}")
    explanation = await translate_if_needed("Tone appears neutral.", target_language)
    return {"emotion": "neutral", "confidence_level": "medium", "explanation": explanation}


# async def analyze_grammar_llm(user_text: str, level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
#     """llm-based grammar analysis for spoken interview answers"""
#     prompt = f"""You are an expert English grammar coach analyzing SPOKEN interview responses.
# 
# Respond in the target language: {target_language}.
# 
# SPOKEN TEXT: "{user_text}"
# USER LEVEL: {level}
# 
# IMPORTANT RULES:
# 1. This is TRANSCRIBED SPEECH - IGNORE punctuation, capitalization, and minor spelling
# 2. Focus ONLY on grammatical structure and word choice
# 3. Be encouraging but honest
# 
# ANALYZE FOR:
# 
# 1. FILLER WORDS (detect ALL of these if present):
#    - um, uh, uhh, er, err, ah, ahh
#    - like (when not used correctly), you know, I mean, basically, actually, literally
#    - so, well (when used as fillers at start)
#    - kind of, sort of (when overused)
# 
# 2. GRAMMAR ERRORS (check each carefully):
#    - VERB TENSE: "I go yesterday" â†’ "I went yesterday"
#    - SUBJECT-VERB AGREEMENT: "He don't know" â†’ "He doesn't know"
#    - ARTICLES: "I am engineer" â†’ "I am an engineer"
#    - PREPOSITIONS: "I am good in coding" â†’ "I am good at coding"
#    - WORD ORDER: "Always I work hard" â†’ "I always work hard"
#    - PRONOUNS: "Me and him went" â†’ "He and I went"
#    - PLURALS: "I have many experience" â†’ "I have much experience"
#    - COMPARATIVES: "more better" â†’ "better"
# 
# 3. WORD SUGGESTIONS:
#    - Find weak/basic words and suggest stronger alternatives
#    - Example: "good" â†’ "excellent/outstanding"
#    - Example: "bad" â†’ "challenging/difficult"
#    - Example: "thing" â†’ "aspect/factor/element"
#    - Example: "do" â†’ "accomplish/execute/perform"
# 
# CRITICAL: 
# - "corrected_sentence" = Fix ONLY grammar errors
# - "improved_sentence" = Fix grammar errors AND USE all word suggestions to make it professional
# 
# SCORING GUIDE (CRITICAL - follow exactly):
# - 95-100: Perfect grammar, no errors, no filler words
# - 85-94: Minor issues only (1-2 fillers OR 1 minor error)
# - 70-84: Some issues (2-3 errors or multiple fillers)
# - 50-69: Significant issues (4+ errors)
# - Below 50: Major problems throughout
# 
# Return STRICTLY valid JSON (no extra text):
# {{
#   "score": <0-100 integer based on SCORING GUIDE above>,
#   "is_correct": <true if no major errors, false otherwise>,
#   
#   "filler_words": ["list", "of", "detected", "fillers"],
#   "filler_count": <number>,
#   "filler_feedback": "<specific advice on reducing fillers>",
#   
#   "errors": [
#     {{
#       "type": "verb_tense | article | subject_verb | preposition | word_order | pronoun | plural | comparative",
#       "you_said": "<exact phrase user said>",
#       "should_be": "<corrected phrase>",
#       "better_word": "<if applicable, show better word IN CONTEXT: 'I have excellent skills' instead of just 'excellent'>",
#       "explanation": "<brief, friendly explanation>"
#     }}
#   ],
#   
#   "word_suggestions": [
#     {{
#       "weak_word": "<basic word user used>",
#       "better_options": ["option1", "option2"],
#       "example": "<show how to use in THEIR sentence with better word>"
#     }}
#   ],
#   
#   "corrected_sentence": "<grammatically correct version - fix errors only>",
#   "improved_sentence": "<USE ALL word_suggestions to make it professional and polished>",
#   
#   "strengths": ["<what they did well grammatically>"],
#   "feedback": "<2-3 sentences: acknowledge positives, then specific improvement tips>"
# }}
# """
#     try:
#         raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
#         json_match = re.search(r'\{[\s\S]*\}', raw)
#         if json_match:
#             data = json.loads(json_match.group())
#             
#             data.setdefault("filler_words", [])
#             data.setdefault("filler_count", len(data.get("filler_words", [])))
#             data.setdefault("filler_feedback", "")
#             data.setdefault("errors", [])
#             data.setdefault("word_suggestions", [])
#             data.setdefault("strengths", [])
#             if not data.get("improved_sentence"):
#                 data["improved_sentence"] = data.get("corrected_sentence", user_text)
#             
#             
#             error_count = len(data.get("errors", []))
#             filler_count = len(data.get("filler_words", []))
#             current_score = data.get("score", 75)
#             
#             
#             if error_count == 0 and filler_count <= 1 and current_score < 90:
#                 data["score"] = 95 - (filler_count * 3)  
#             elif error_count == 1 and current_score < 80:
#                 data["score"] = 85 - (filler_count * 2)
#             elif error_count >= 4 and current_score > 70:
#                 data["score"] = min(current_score, 65)
#             
#             return data
#     except Exception as e:
#         logger.debug(f"Grammar analysis fallback: {e}")
#     return {
#         "score": 90, "is_correct": True, "filler_words": [], "filler_count": 0,
#         "filler_feedback": "", "errors": [], "word_suggestions": [],
#         "corrected_sentence": user_text, "improved_sentence": user_text,
#         "strengths": ["Good sentence structure"], "feedback": "No major grammatical issues detected. Keep up the good work!"
#     }



# async def analyze_vocab_llm(user_text: str, level: str = "Intermediate", model: str = "gpt") -> dict:
#     """llm-based vocabulary analysis with cefr levels"""
#     prompt = f"""Analyze vocabulary CEFR levels for this interview answer: "{user_text}"
 
# Level: {level}
 
# CRITICAL - SPELLING ERRORS:
# If a word is MISSPELLED (e.g., "awareded", "recieved", "definately"):
# - Do NOT assign it a high CEFR level like C2
# - Include it in "suggestions" with the CORRECT SPELLING as "better_word"
 
# Calculate percentage of words at each CEFR level. Percentages should sum to 100.
 
# IMPORTANT: In the "feedback" field, DO NOT mention "A1", "A2", "B1", "B2", "C1", "C2" directly.
# Instead use:
# - A1/A2 words = "basic words" or "simple vocabulary"
# - B1/B2 words = "intermediate words" or "good vocabulary"
# - C1/C2 words = "advanced words" or "sophisticated vocabulary"
 
# CRITICAL FOR SUGGESTIONS:
# - "original_sentence": Extract the EXACT phrase from the user's transcription that contains the weak word
# - "improved_sentence": Show the SAME phrase with the better word substituted
 
# Return STRICTLY valid JSON:
# {{
#   "score": 0-100,
#   "overall_level": "A1/A2/B1/B2/C1/C2",
#   "total_words": <word count>,
#   "cefr_distribution": {{
#     "A1": {{"percentage": 20, "words": ["I", "is"]}},
#     "A2": {{"percentage": 30, "words": ["work", "name"]}},
#     "B1": {{"percentage": 40, "words": ["experience"]}},
#     "B2": {{"percentage": 10, "words": ["sophisticated"]}},
#     "C1": {{"percentage": 0, "words": []}},
#     "C2": {{"percentage": 0, "words": []}}
#   }},
#   "professional_words_used": ["list", "of", "professional", "terms"],
#   "suggestions": [
#     {{"word": "good", "current_level": "A2", "better_word": "excellent", "suggested_level": "B1", "original_sentence": "<extract from user's actual text>", "improved_sentence": "<same phrase with better word>"}}
#   ],
#   "feedback": "Feedback using 'basic', 'intermediate', 'advanced' - NOT A1/B1/C1 labels"
# }}
 
# IMPORTANT: For MISSPELLED words, set current_level = "spelling_error" and better_word = correct spelling
# """
#     try:
#         raw = await call_llm(prompt, mode="strict_json", model=model)
#         json_match = re.search(r'\{[\s\S]*\}', raw)
#         if json_match:
#             return json.loads(json_match.group())
#     except Exception as e:
#         logger.debug(f"Vocabulary analysis fallback: {e}")
#     return {
#         "score": 80, "overall_level": "B1", "total_words": len(user_text.split()),
#         "cefr_distribution": {
#             "A1": {"percentage": 0, "words": []}, "A2": {"percentage": 0, "words": []},
#             "B1": {"percentage": 0, "words": []}, "B2": {"percentage": 0, "words": []},
#             "C1": {"percentage": 0, "words": []}, "C2": {"percentage": 0, "words": []}
#         },
#         "professional_words_used": [], "suggestions": [],
#         "feedback": "Vocabulary analysis could not be completed."
#     }




async def analyze_grammar_llm(user_text: str, level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
    """llm-based grammar analysis for spoken interview answers"""
    prompt = f"""You are an expert English grammar coach analyzing SPOKEN interview responses.

Respond in the target language: {target_language}.

SPOKEN TEXT: "{user_text}"
USER LEVEL: {level}

IMPORTANT RULES:
1. This is TRANSCRIBED SPEECH - IGNORE punctuation, capitalization, and minor spelling
2. Focus ONLY on grammatical structure and word choice
3. Be encouraging but honest

ANALYZE FOR:

1. FILLER WORDS (detect ALL of these if present):
   - um, uh, uhh, er, err, ah, ahh
   - like (when not used correctly), you know, I mean, basically, actually, literally
   - so, well (when used as fillers at start)
   - kind of, sort of (when overused)

2. GRAMMAR ERRORS (check each carefully):
   - VERB TENSE: "I go yesterday" â†’ "I went yesterday"
   - SUBJECT-VERB AGREEMENT: "He don't know" â†’ "He doesn't know"
   - ARTICLES: "I am engineer" â†’ "I am an engineer"
   - PREPOSITIONS: "I am good in coding" â†’ "I am good at coding"
   - WORD ORDER: "Always I work hard" â†’ "I always work hard"
   - PRONOUNS: "Me and him went" â†’ "He and I went"
   - PLURALS: "I have many experience" â†’ "I have much experience"
   - COMPARATIVES: "more better" â†’ "better"

3. WORD SUGGESTIONS:
   - Find weak/basic words and suggest stronger alternatives
   - Example: "good" â†’ "excellent/outstanding"
   - Example: "bad" â†’ "challenging/difficult"
   - Example: "thing" â†’ "aspect/factor/element"
   - Example: "do" â†’ "accomplish/execute/perform"
STRICT OUTPUT FORMAT:
For each error, **mark the incorrect word(s) with `#wrong word#`** and the correct word(s) with **`#correct word#`**, **regardless of the target language**.

For example:
   - "I #wrong word#goed# to store" â†’ "I #correct word#went# to the store"
   - "He #wrong word#don't# know" â†’ "He #correct word#doesn't# know"
   - "I am #wrong word#good# at coding" â†’ "I am #correct word#good# at coding"

### For all languages, apply the same analysis rules:
1. **Filler Words**: Detect filler words based on the target language, and mark them as `#wrong word#`. Provide feedback on how to reduce them.
2. **Grammar Errors**: Check for common grammar mistakes like verb tense, subject-verb agreement, articles, etc., and mark the wrong words with `#wrong word#`, and the correct form with `#correct word#`.
3. **Word Suggestions**: Suggest stronger or more professional vocabulary, marking the weak word as `#wrong word#` and the suggestion as `#correct word#`.

CRITICAL: 
- "corrected_sentence" = Fix ONLY grammar errors
- "improved_sentence" = Fix grammar errors AND USE all word suggestions to make it professional

SCORING GUIDE (CRITICAL - follow exactly):
- 95-100: Perfect grammar, no errors, no filler words
- 85-94: Minor issues only (1-2 fillers OR 1 minor error)
- 70-84: Some issues (2-3 errors or multiple fillers)
- 50-69: Significant issues (4+ errors)
- Below 50: Major problems throughout

Return STRICTLY valid JSON (no extra text):
{{
  "score": <0-100 integer based on SCORING GUIDE above>,
  "is_correct": <true if no major errors, false otherwise>,

  "filler_words": ["list", "of", "detected", "fillers"],
  "filler_count": <number>,
  "filler_feedback": "<specific advice on reducing fillers>",

  "errors": [
    {{
      "type": "verb_tense | article | subject_verb | preposition | word_order | pronoun | plural | comparative",
      "you_said": "I #goed# to store",
      "should_be": "I #went# to the store",
      "wrong_word": "goed",
      "correct_word": "went",
      "explanation": "Go is irregular - past tense is went, not goed",
      "example_sentence": "Yesterday, I went to the park with my friends."
    }}
  ],

  "word_suggestions": [
    {{
      "you_used": "good",
      "use_instead": "excellent",
      "why": "more impactful for professional context",
      "original_sentence": "The results were #good#",
      "improved_sentence": "The results were #excellent#",
      "example_sentence": "The project outcomes were excellent."
    }}
  ],

  "corrected_sentence": "<THE WHOLE TRANSCRIPTION with ONLY grammar errors fixed>",
  "improved_sentence": "<THE WHOLE TRANSCRIPTION with grammar fixed + vocabulary enhanced>",

  "strengths": ["<what they did well grammatically>"],
  "feedback": "<2-3 sentences: acknowledge positives, then specific improvement tips>"
}}

CRITICAL FORMATTING RULES:
- For errors: you_said and should_be are ONLY the specific sentence/line from transcription containing the error
- Mark the wrong word with #word# in you_said
- Mark the correct word with #word# in should_be
- For word_suggestions: original_sentence and improved_sentence are ONLY the specific phrase containing the weak word
- Mark weak word with #word# in original_sentence, better word with #word# in improved_sentence
- example_sentence is a NEW sentence showing correct usage (not from transcription)
- corrected_sentence = THE WHOLE TRANSCRIPTION with all grammar fixes applied
- improved_sentence = THE WHOLE TRANSCRIPTION with grammar fixed AND vocabulary enhanced
- Empty arrays [] if no issues

### TAGGING RULES (MANDATORY)
- Use #word# format for every correction token.
- Never leave correction tokens untagged.

For each item in "errors":
- "you_said" must include #wrong_word#
- "should_be" must include #correct_word#
- Tag only the exact incorrect/correct token(s), not the whole sentence.

For each item in "word_suggestions":
- "original_sentence" must include #weak_word#
- "improved_sentence" must include #better_word#
- Tag only the exact replaced token(s).

If multiple changes exist, tag at least the primary changed token.
"""
    try:
        raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())

            # Normalize word_suggestions keys for consistent API response
            for item in data.get("word_suggestions", []):
                if not isinstance(item, dict):
                    continue
                if not item.get("weak_word"):
                    item["weak_word"] = item.get("you_used") or item.get("word") or ""
                if not item.get("better_options"):
                    better = item.get("use_instead") or item.get("better_word")
                    item["better_options"] = [better] if better else []

            data.setdefault("filler_words", [])
            data.setdefault("filler_count", len(data.get("filler_words", [])))
            data.setdefault("filler_feedback", "")
            data.setdefault("errors", [])
            data.setdefault("word_suggestions", [])
            data.setdefault("strengths", [])
            if not data.get("improved_sentence"):
                data["improved_sentence"] = data.get("corrected_sentence", user_text)


            error_count = len(data.get("errors", []))
            filler_count = len(data.get("filler_words", []))
            current_score = data.get("score", 75)


            if error_count == 0 and filler_count <= 1 and current_score < 90:
                data["score"] = 95 - (filler_count * 3)  
            elif error_count == 1 and current_score < 80:
                data["score"] = 85 - (filler_count * 2)
            elif error_count >= 4 and current_score > 70:
                data["score"] = min(current_score, 65)

            return data
    except Exception as e:
        logger.debug(f"Grammar analysis fallback: {e}")
    fallback_strengths = ["Good sentence structure"]
    fallback_feedback = "No major grammatical issues detected. Keep up the good work!"
    if target_language and target_language.lower() not in ["en", "english"]:
        fallback_strengths = await translate_values(fallback_strengths, target_language)
        fallback_feedback = await translate_if_needed(fallback_feedback, target_language)
    return {
        "score": 90, "is_correct": True, "filler_words": [], "filler_count": 0,
        "filler_feedback": "", "errors": [], "word_suggestions": [],
        "corrected_sentence": user_text, "improved_sentence": user_text,
        "strengths": fallback_strengths, "feedback": fallback_feedback
    }


async def analyze_vocab_llm(user_text: str, level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
    """llm-based vocabulary analysis with cefr levels"""
    prompt = f"""Analyze vocabulary CEFR levels for this interview answer: "{user_text}"

Respond in the target language: {target_language}.

Level: {level}

CRITICAL - VOCABULARY SUGGESTIONS ARE MANDATORY:
You MUST find and suggest improvements for weak/basic words like:
- good â†’ excellent/outstanding
- bad â†’ challenging/difficult  
- thing â†’ aspect/factor/element
- do â†’ accomplish/execute/perform
- get â†’ obtain/acquire/receive
- make â†’ create/develop/establish
- very â†’ extremely/highly/remarkably
- nice â†’ pleasant/wonderful/delightful
- big â†’ substantial/significant
- small â†’ minor/minimal

SPELLING ERRORS:
If a word is MISSPELLED (e.g., "awareded", "recieved", "definately"):
- Set current_level = "spelling_error"
- Set better_word = correct spelling

Calculate percentage of words at each CEFR level. Percentages should sum to 100.
Count ALL words in the text for total_words.
Give same analysis for all languages - do NOT adjust CEFR levels based on language
IMPORTANT: In the "feedback" field, DO NOT mention "A1", "A2", "B1", "B2", "C1", "C2" directly.
Instead use:
- A1/A2 words = "basic words" or "simple vocabulary"
- B1/B2 words = "intermediate words" or "good vocabulary"
- C1/C2 words = "advanced words" or "sophisticated vocabulary"

Return STRICTLY valid JSON:
{{
  "score": 0-100,
  "overall_level": "A1/A2/B1/B2/C1/C2",
  "total_words": <actual word count>,
  "cefr_distribution": {{
    "A1": {{"percentage": 20, "words": ["I", "is", "the"]}},
    "A2": {{"percentage": 30, "words": ["work", "name", "good"]}},
    "B1": {{"percentage": 40, "words": ["experience", "actually"]}},
    "B2": {{"percentage": 10, "words": ["sophisticated"]}},
    "C1": {{"percentage": 0, "words": []}},
    "C2": {{"percentage": 0, "words": []}}
  }},
  "professional_words_used": ["list", "of", "professional", "terms"],
  "suggestions": [
    {{
      "word": "good",
      "current_level": "A2",
      "better_word": "excellent",
      "suggested_level": "B1",
      "context": "appropriate for professional interview",
      "original_sentence": "I had a #good# experience",
      "improved_sentence": "I had an #excellent# experience",
      "example_sentence": "The results of the project were excellent."
    }}
  ],
  "feedback": "Feedback using 'basic', 'intermediate', 'advanced' - NOT A1/B1/C1 labels"
}}

CRITICAL FORMATTING RULES:
- original_sentence: Extract ONLY the specific sentence/line from user's transcription containing the weak word (NOT the whole transcription)
- Mark the weak word with #word# in original_sentence
- improved_sentence: Same sentence/line with the better word substituted
- Mark the better word with #word# in improved_sentence
- example_sentence: A NEW sentence showing correct usage (not from transcription, no # needed)
- ALWAYS include suggestions if any weak/basic words (A1/A2 level) are found
- For MISSPELLED words: current_level = "spelling_error", better_word = correct spelling
- Provide at least 2-3 suggestions if weak words exist

### TAGGING RULES (MANDATORY)
- Use #word# format for every vocabulary replacement token.
- Never leave replacement tokens untagged.

For each item in "suggestions":
- "original_sentence" must include #weak_or_misspelled_word#
- "improved_sentence" must include #better_or_correct_word#
- Tag only the exact replaced token(s), not the whole sentence.

If multiple replacements exist, tag at least the primary replacement token.
"""
    try:
        raw = await call_llm(prompt, mode="strict_json", model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            data = json.loads(json_match.group())
            # Ensure CEFR distribution has all levels
            default_cefr = {
                "A1": {"percentage": 0, "words": []}, "A2": {"percentage": 0, "words": []},
                "B1": {"percentage": 0, "words": []}, "B2": {"percentage": 0, "words": []},
                "C1": {"percentage": 0, "words": []}, "C2": {"percentage": 0, "words": []}
            }
            if "cefr_distribution" not in data or not isinstance(data.get("cefr_distribution"), dict):
                data["cefr_distribution"] = default_cefr
            else:
                for level_key in default_cefr:
                    if level_key not in data["cefr_distribution"]:
                        data["cefr_distribution"][level_key] = default_cefr[level_key]
            return data
    except Exception as e:
        logger.debug(f"Vocabulary analysis fallback: {e}")
    fallback_feedback = "Vocabulary analysis could not be completed."
    if target_language and target_language.lower() not in ["en", "english"]:
        fallback_feedback = await translate_if_needed(fallback_feedback, target_language)
    return {
        "score": 80, "overall_level": "B1", "total_words": len(user_text.split()),
        "cefr_distribution": {
            "A1": {"percentage": 0, "words": []}, "A2": {"percentage": 0, "words": []},
            "B1": {"percentage": 0, "words": []}, "B2": {"percentage": 0, "words": []},
            "C1": {"percentage": 0, "words": []}, "C2": {"percentage": 0, "words": []}
        },
        "professional_words_used": [], "suggestions": [],
        "feedback": fallback_feedback
    }


async def analyze_pronunciation_llm(audio_path: str = None, spoken_text: str = None, level: str = "Intermediate", model: str = "gpt", target_language: str = "en") -> dict:
    """pronunciation analysis using whisper word-level confidence"""
    
    if not audio_path:
        fallback_feedback = "No audio provided for pronunciation analysis"
        fallback_tips = ["Record audio for pronunciation feedback"]
        if target_language and target_language.lower() not in ["en", "english"]:
            fallback_feedback = await translate_if_needed(fallback_feedback, target_language)
            fallback_tips = await translate_values(fallback_tips, target_language)
        return {
            "accuracy": 75, "transcription": spoken_text or "",
            "word_pronunciation_scores": [],
            "words_to_practice": [], "well_pronounced_words": spoken_text.split() if spoken_text else [],
            "feedback": fallback_feedback,
            "tips": fallback_tips,
            "mispronounced_count": 0
        }
    
    try:
        normalized_target = normalize_language_code(target_language, default="en")

        async def _transcribe_pronunciation(lang_hint: str = None):
            kwargs = {"word_timestamps": True}
            if lang_hint:
                kwargs["language"] = lang_hint
            segments, info = await asyncio.to_thread(_whisper_model.transcribe, audio_path, **kwargs)
            detected = info.language if info else (lang_hint or "en")
            words = []
            text = ""
            for seg in segments:
                text += seg.text + " "
                if seg.words:
                    for w in seg.words:
                        words.append({
                            "word": w.word.strip().lower(),
                            "confidence": w.probability,
                            "start": w.start,
                            "end": w.end
                        })
            return text.strip(), words, detected

        transcription, words_data, detected_lang = await _transcribe_pronunciation(normalized_target)
        display_transcription = transcription

        if not words_data:
            fallback_feedback = "No speech detected in audio"
            fallback_tips = ["Speak clearly into the microphone"]
            if target_language and target_language.lower() not in ["en", "english"]:
                fallback_feedback = await translate_if_needed(fallback_feedback, target_language)
                fallback_tips = await translate_values(fallback_tips, target_language)
            return {
                "accuracy": 0, "transcription": display_transcription,
                "word_pronunciation_scores": [],
                "words_to_practice": [], "well_pronounced_words": [],
                "feedback": fallback_feedback,
                "tips": fallback_tips,
                "mispronounced_count": 0
            }
        
        CONFIDENCE_THRESHOLD = 0.70
        mispronounced_words = []
        well_pronounced = []
        word_pronunciation_scores = []
        
        for wd in words_data:
            word = wd["word"].strip(".,!?")
            if len(word) < 2:
                continue
            
            pronunciation_percentage = round(wd["confidence"] * 100, 1)
            
            if pronunciation_percentage >= 90:
                status = "excellent"
            elif pronunciation_percentage >= 70:
                status = "good"
            elif pronunciation_percentage >= 50:
                status = "needs_improvement"
            else:
                status = "poor"
            
            word_pronunciation_scores.append({
                "word": word,
                "pronunciation_match_percentage": pronunciation_percentage,
                "status": status
            })
            
            if wd["confidence"] < CONFIDENCE_THRESHOLD:
                mispronounced_words.append({
                    "word": word,
                    "confidence": pronunciation_percentage,
                    "issue": "unclear pronunciation" if wd["confidence"] < 0.5 else "slight pronunciation issue"
                })
            else:
                well_pronounced.append(word)
        
        avg_confidence = sum(w["confidence"] for w in words_data) / len(words_data) if words_data else 0.7
        accuracy = int(avg_confidence * 100)
        
        
        llm_prompt = f"""You are a pronunciation coach for interview preparation.

Respond in the target language: {normalized_target}.

TRANSCRIPTION: "{display_transcription}"
MISPRONOUNCED WORDS: {mispronounced_words if mispronounced_words else "None - all words were clear!"}
WELL PRONOUNCED: {well_pronounced[:10]}
ACCURACY: {accuracy}%

Return STRICTLY valid JSON:
{{
    "words_to_practice": [
        {{"word": "the word", "how_to_say": "syllable breakdown: ex-AM-ple", "tip": "specific tip"}}
    ],
    "feedback": "2-3 encouraging sentences about their pronunciation for interview",
    "tips": ["general pronunciation tip 1", "general tip 2"]
}}
"""
        try:
            llm_response = await call_llm(llm_prompt, mode="strict_json", timeout=30, model=model, target_language=target_language)
            llm_data = json.loads(re.search(r'\{[\s\S]*\}', llm_response).group())
        except Exception as llm_error:
            logger.debug(f"LLM pronunciation tips fallback: {llm_error}")
            llm_data = {
                "words_to_practice": [{"word": w["word"], "how_to_say": f"Say '{w['word']}' clearly", "tip": "Speak slower"} for w in mispronounced_words[:5]],
                "feedback": f"Pronunciation accuracy: {accuracy}%.",
                "tips": ["Speak slowly and clearly", "Practice word stress"]
            }
            if target_language and target_language.lower() not in ["en", "english"]:
                llm_data["feedback"] = await translate_if_needed(llm_data.get("feedback", ""), target_language)
                llm_data["tips"] = await translate_values(llm_data.get("tips", []), target_language)
                translated_words = []
                for item in llm_data.get("words_to_practice", []):
                    if isinstance(item, dict):
                        item = item.copy()
                        item["how_to_say"] = await translate_if_needed(item.get("how_to_say", ""), target_language)
                        item["tip"] = await translate_if_needed(item.get("tip", ""), target_language)
                    translated_words.append(item)
                llm_data["words_to_practice"] = translated_words
        
        default_feedback = await translate_if_needed("Analysis complete.", target_language)
        return {
            "accuracy": accuracy,
            "transcription": display_transcription,
            "word_pronunciation_scores": word_pronunciation_scores,
            "words_to_practice": llm_data.get("words_to_practice", []),
            "well_pronounced_words": well_pronounced,
            "feedback": llm_data.get("feedback", default_feedback),
            "tips": llm_data.get("tips", []),
            "mispronounced_count": len(mispronounced_words)
        }
        
    except Exception as e:
        logger.error(f"Pronunciation error: {e}")
        fallback_feedback = f"Could not analyze pronunciation: {str(e)}"
        fallback_tips = ["Ensure clear audio recording"]
        if target_language and target_language.lower() not in ["en", "english"]:
            fallback_feedback = await translate_if_needed(fallback_feedback, target_language)
            fallback_tips = await translate_values(fallback_tips, target_language)
        return {
            "accuracy": 75, "transcription": spoken_text or "",
            "word_pronunciation_scores": [],
            "words_to_practice": [], "well_pronounced_words": [],
            "feedback": fallback_feedback,
            "tips": fallback_tips,
            "mispronounced_count": 0
        }


def calculate_fluency(word_count: int, audio_duration: float) -> dict:
    """calculate fluency metrics"""
    if audio_duration <= 0:
        return {
            "score": 60,
            "wpm": 0,
            "speed_status": "too_slow",
            "audio_duration_seconds": 0
        }

    wpm = int((word_count / audio_duration) * 60)
    
    if wpm < 80:
        score = 40 + (wpm / 80) * 30
        speed_status = "too_slow"
    elif wpm < 110:
        score = 70 + ((wpm - 80) / 30) * 20
        speed_status = "slow"
    elif wpm <= 160:
        score = 90 + ((wpm - 110) / 50) * 10
        speed_status = "normal"
    elif wpm <= 180:
        score = 100 - ((wpm - 160) / 20) * 15
        speed_status = "fast"
    else:
        score = max(60, 85 - ((wpm - 180) * 0.5))
        speed_status = "too_fast"
    
    return {
        "score": max(0, min(100, int(round(score)))),
        "wpm": wpm,
        "speed_status": speed_status,
        "audio_duration_seconds": round(audio_duration, 1)
    }


async def analyze_fluency_metrics(user_text: str, audio_duration: float) -> dict:
    """async wrapper for fluency metrics from text and duration"""
    word_count = len(re.findall(r"\b\w+\b", user_text or ""))
    return calculate_fluency(word_count, audio_duration)


async def generate_personalized_feedback(overall_score: float, scores: dict, emotion: dict, user_name: str,
                                          grammar: dict = None, vocabulary: dict = None, 
                                          pronunciation: dict = None, answer_eval: dict = None, model: str = "gpt",
                                          target_language: str = "en") -> dict:
    """Generate personalized interview feedback using LLM based on actual errors"""
    
    
    grammar_errors = [
        e for e in (grammar.get("errors", []) if grammar else [])
        if isinstance(e, dict)
    ]
    filler_words = grammar.get("filler_words", []) if grammar else []
    word_suggestions = [
        w for w in (grammar.get("word_suggestions", []) if grammar else [])
        if isinstance(w, dict)
    ]
    vocab_suggestions = [
        v for v in (vocabulary.get("suggestions", []) if vocabulary else [])
        if isinstance(v, dict)
    ]
    mispronounced = pronunciation.get("words_to_practice", []) if pronunciation else []
    answer_issues = answer_eval.get("issue_summary", "") if answer_eval else ""
    
    
    errors_context = []
    if grammar_errors:
        errors_context.append(f"Grammar errors: {[e.get('you_said', '') + ' â†’ ' + e.get('should_be', '') for e in grammar_errors[:3]]}")
    if filler_words:
        errors_context.append(f"Filler words used: {filler_words[:5]}")
    if word_suggestions:
        errors_context.append(f"Weak words: {[w.get('weak_word', '') for w in word_suggestions[:3]]}")
    if vocab_suggestions:
        errors_context.append(f"Vocabulary improvements: {[v.get('word', '') + ' â†’ ' + v.get('better_word', '') for v in vocab_suggestions[:3]]}")
    if mispronounced:
        errors_context.append(f"Pronunciation to practice: {[w.get('word', '') if isinstance(w, dict) else w for w in mispronounced[:3]]}")
    if answer_issues:
        errors_context.append(f"Answer feedback: {answer_issues}")
    
    
    improvement_areas = []
    strengths = []
    for area, score in scores.items():
        if score is None:  
            continue
        if score >= 75:
            strengths.append(area)
        elif score < 65:
            improvement_areas.append(area)
    
    improvement_areas_display = improvement_areas
    strengths_display = strengths
    if target_language and target_language != "en":
        try:
            if improvement_areas:
                improvement_areas_display = list(await asyncio.gather(
                    *[translate_text(a, "en", target_language) for a in improvement_areas]
                ))
            if strengths:
                strengths_display = list(await asyncio.gather(
                    *[translate_text(s, "en", target_language) for s in strengths]
                ))
        except Exception as e:
            logger.debug(f"Personalized feedback list translation failed: {e}")

    if errors_context:
        prompt = f"""You are a professional interview coach providing constructive feedback to candidate {user_name}.

Respond in the target language: {target_language}.

SCORES:
- Grammar: {scores.get('grammar', 0)}%
- Vocabulary: {scores.get('vocabulary', 0)}%
- Pronunciation: {scores.get('pronunciation', 0)}%
- Fluency: {scores.get('fluency', 0)}%
- Answer Quality: {scores.get('answer_evaluation', 0)}%
- Overall: {overall_score}%

ACTUAL ERRORS/ISSUES FOUND:
{chr(10).join(errors_context)}

EMOTION DETECTED: {emotion.get('emotion', 'neutral')}

Generate PROFESSIONAL but ENGAGING feedback. Be encouraging yet constructive.

Return STRICTLY valid JSON:
{{
    "message": "Start with a polished, professional one-liner that acknowledges their performance (like 'That was a well-structured response.' or 'Good points raised there.' or 'I can see you're putting thought into this.'). THEN 1-2 sentences of specific, constructive feedback about their ACTUAL errors. Keep it professional but warm.",
    "improvement_areas": {json.dumps(improvement_areas_display)},
    "strengths": {json.dumps(strengths_display)},
    "emotion": "{emotion.get('emotion', 'neutral')}",
    "quick_tip": "ONE specific, actionable tip - professional tone"
}}

TONE EXAMPLES for "message" based on score:
- Score >= 85: "That was an excellent response. Your articulation was clear and..."
- Score 70-84: "Good effort on that answer. I noticed some strong points, though..."
- Score 50-69: "You're on the right track. Let's work on..."
- Score < 50: "I appreciate your attempt. Here's how we can strengthen..."

RULES:
- Professional tone (like a supportive hiring manager)
- NOT overly formal or stiff - be human and warm
- Reference ACTUAL errors constructively
- Acknowledge good attempts even when score is low"""
        
        try:
            raw = await call_llm(prompt, mode="strict_json", timeout=15, model=model, target_language=target_language)
            json_match = re.search(r'\{[\s\S]*\}', raw)
            if json_match:
                result = json.loads(json_match.group())
                
                result.setdefault("improvement_areas", improvement_areas_display)
                result.setdefault("strengths", strengths_display)
                result.setdefault("emotion", emotion.get("emotion", "neutral"))
                return result
        except Exception as e:
            logger.debug(f"LLM personalized feedback fallback: {e}")
    
    
    if overall_score >= 95:
        message = f"ðŸŒŸ Outstanding interview performance, {user_name}! You're interview-ready!"
    elif overall_score >= 85:
        message = f"Excellent job, {user_name}! Your communication skills are impressive."
    elif overall_score >= 70:
        message = f"Good effort, {user_name}! Focus on {', '.join(improvement_areas) if improvement_areas else 'minor details'} to improve."
    else:
        message = f"Keep practicing, {user_name}! Work on: {', '.join(improvement_areas) if improvement_areas else 'overall delivery'}."
    
    if emotion.get("confidence_level") == "low" or emotion.get("emotion") == "nervous":
        message += " Remember to take a breath and project confidence."
    
    quick_tip = f"Practice your {improvement_areas[0] if improvement_areas else 'interview skills'} regularly."
    if target_language and target_language != "en":
        try:
            message = await translate_text(message, "en", target_language)
            quick_tip = await translate_text(quick_tip, "en", target_language)
        except Exception as e:
            logger.debug(f"Personalized feedback fallback translation failed: {e}")

    return {
        "message": message,
        "improvement_areas": improvement_areas_display,
        "strengths": strengths_display,
        "emotion": emotion.get("emotion", "neutral"),
        "quick_tip": quick_tip
    }


async def generate_session_summary_llm(user_name: str, scenario: str, final_scores: dict, 
                                        chat_history: list, total_turns: int, average_wpm: int, 
                                        turn_history: list = None, model: str = "gpt",
                                        target_language: str = "en") -> dict:
    """Generate elaborative LLM-based session summary with per-turn WPM analysis"""
    
    
    conversation_summary = []
    for i, msg in enumerate(chat_history[-10:]):  
        role = "Clara" if msg["role"] == "assistant" else user_name
        conversation_summary.append(f"{role}: {msg['content'][:100]}...")
    
    
    turn_wpm_summary = ""
    if turn_history:
        turn_entries = [f"Turn {t.get('turn', i+1)}: {t.get('wpm', 0)} WPM, Score: {t.get('overall_score', 0)}%" 
                       for i, t in enumerate(turn_history)]
        turn_wpm_summary = "\n".join(turn_entries)
    
    prompt = f"""You are an expert interview coach providing a detailed session summary.

Respond in the target language: {target_language}.

CANDIDATE: {user_name}
SCENARIO: {scenario}
TOTAL QUESTIONS: {total_turns}
AVERAGE SPEAKING SPEED: {average_wpm} words per minute

FINAL SCORES:
- Grammar: {final_scores.get('grammar', 0)}%
- Vocabulary: {final_scores.get('vocabulary', 0)}%  
- Pronunciation: {final_scores.get('pronunciation', 0)}%
- Fluency: {final_scores.get('fluency', 0)}%

PER-TURN PERFORMANCE:
{turn_wpm_summary if turn_wpm_summary else "No turn data available"}

RECENT CONVERSATION:
{chr(10).join(conversation_summary)}

Generate a detailed, personalized, and encouraging session summary. Analyze WPM trend across turns.

Return STRICTLY valid JSON:
{{
    "overall_assessment": "3-4 sentences summarizing the candidate's overall interview performance, mentioning WPM trends",
    "grammar_feedback": {{
        "score": {final_scores.get('grammar', 0)},
        "status": "Excellent/Good/Needs Work",
        "what_went_well": "specific positive observation",
        "improvement_tip": "specific actionable tip",
        "example": "example of correct usage or common mistake to avoid"
    }},
    "vocabulary_feedback": {{
        "score": {final_scores.get('vocabulary', 0)},
        "status": "Excellent/Good/Needs Work",
        "what_went_well": "specific positive observation",
        "improvement_tip": "specific actionable tip",
        "suggested_words": ["professional word 1", "professional word 2", "professional word 3"]
    }},
    "pronunciation_feedback": {{
        "score": {final_scores.get('pronunciation', 0)},
        "status": "Excellent/Good/Needs Work",
        "what_went_well": "specific positive observation",
        "improvement_tip": "specific actionable tip",
        "practice_words": ["word to practice 1", "word to practice 2"]
    }},
    "fluency_feedback": {{
        "score": {final_scores.get('fluency', 0)},
        "status": "Excellent/Good/Needs Work",
        "what_went_well": "specific positive observation",
        "improvement_tip": "specific actionable tip for speaking pace",
        "wpm_trend": "analysis of WPM across turns - improving/declining/stable"
    }},
    "interview_skills": {{
        "confidence": "observation about confidence level",
        "structure": "observation about answer structure",
        "relevance": "observation about answer relevance"
    }},
    "action_plan": [
        "specific action item 1 for next week",
        "specific action item 2 for next week",
        "specific action item 3 for next week"
    ],
    "encouragement": "2-3 encouraging sentences personalized for the candidate",
    "next_practice_topics": ["topic 1", "topic 2", "topic 3"]
}}
"""
    try:
        raw = await call_llm(prompt, mode="strict_json", timeout=25, model=model, target_language=target_language)
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            return json.loads(json_match.group())
    except Exception as e:
        logger.debug(f"Session summary LLM fallback: {e}")
    
    
    fallback = {
        "overall_assessment": f"Great effort, {user_name}! You completed {total_turns} questions in your {scenario} practice.",
        "grammar_feedback": {"score": final_scores.get("grammar", 0), "status": "Good", "what_went_well": "Good sentence structure", "improvement_tip": "Practice complex sentences", "example": "Use varied sentence structures"},
        "vocabulary_feedback": {"score": final_scores.get("vocabulary", 0), "status": "Good", "what_went_well": "Used relevant terms", "improvement_tip": "Expand professional vocabulary", "suggested_words": ["synergy", "leverage", "optimize"]},
        "pronunciation_feedback": {"score": final_scores.get("pronunciation", 0), "status": "Good", "what_went_well": "Clear articulation", "improvement_tip": "Practice difficult words", "practice_words": ["particularly", "specifically"]},
        "fluency_feedback": {"score": final_scores.get("fluency", 0), "status": "Good", "what_went_well": "Consistent pace", "improvement_tip": "Maintain steady rhythm", "wpm_trend": "stable"},
        "interview_skills": {"confidence": "Showed good confidence", "structure": "Answers were organized", "relevance": "Stayed on topic"},
        "action_plan": ["Practice speaking for 10 mins daily", "Record and review your answers", "Prepare examples for common questions"],
        "encouragement": f"Keep up the great work, {user_name}! Regular practice will help you ace your interviews.",
        "next_practice_topics": ["Tell me about yourself", "Why should we hire you?", "Describe a challenge you overcame"]
    }
    if target_language and target_language.lower() not in ["en", "english"]:
        fallback = await translate_values(fallback, target_language)
    return fallback
async def handle_session_termination(session: dict, session_id: str, model: str = "gpt") -> dict:
    """
    Helper function to handle session termination - eliminates duplicate code.
    Returns the termination response with LLM-generated summary.
    """
    count = max(1, session["scores"]["count"])
    audio_count = session["scores"].get("audio_count", 0)
    if not audio_count and (
        session["scores"].get("pronunciation", 0) > 0 or session["scores"].get("fluency", 0) > 0
    ):
        audio_count = count
    
    
    has_audio_turns = session["scores"].get("pronunciation", 0) > 0 or session["scores"].get("fluency", 0) > 0
    
    if has_audio_turns:
        pronunciation_avg = int(session["scores"]["pronunciation"] / audio_count) if audio_count > 0 else 0
        fluency_avg = int(session["scores"]["fluency"] / audio_count) if audio_count > 0 else 0
        final_scores = {
            "grammar": int(session["scores"]["grammar"] / count),
            "vocabulary": int(session["scores"]["vocabulary"] / count),
            "pronunciation": pronunciation_avg,
            "fluency": fluency_avg
        }
        avg_answer_score = int(session["scores"].get("answer", 50 * count) / count)
        overall = int(
            final_scores["grammar"] * 0.25 +
            final_scores["vocabulary"] * 0.25 +
            avg_answer_score * 0.25 +
            final_scores["pronunciation"] * 0.15 +
            final_scores["fluency"] * 0.10
        )
        average_wpm = int(session["scores"].get("total_wpm", 0) / audio_count) if audio_count > 0 else 0
    else:
        
        final_scores = {
            "grammar": int(session["scores"]["grammar"] / count),
            "vocabulary": int(session["scores"]["vocabulary"] / count),
            "pronunciation": None,
            "fluency": None
        }
        avg_answer_score = int(session["scores"].get("answer", 50 * count) / count)
        
        overall = int(
            final_scores["grammar"] * 0.33 +
            final_scores["vocabulary"] * 0.33 +
            avg_answer_score * 0.34
        )
        average_wpm = 0

    
    improvement_areas = [area for area, score in final_scores.items() if score is not None and score < 70]
    strengths = [area for area, score in final_scores.items() if score is not None and score >= 80]
    
    
    turn_history = session.get("turn_history", [])
    
    # Aggregate vocab CEFR words and WPM per turn
    wpm_per_turn = []
    vocab_overall = {
        "A1": {"count": 0, "words": []},
        "A2": {"count": 0, "words": []},
        "B1": {"count": 0, "words": []},
        "B2": {"count": 0, "words": []},
        "C1": {"count": 0, "words": []},
        "C2": {"count": 0, "words": []}
    }
    
    for attempt in session.get("attempts", []):
        # Track WPM per turn
        fluency_data = attempt.get("fluency") or {}
        turn_wpm = fluency_data.get("wpm", 0) if fluency_data else 0
        wpm_per_turn.append({"turn": len(wpm_per_turn) + 1, "wpm": turn_wpm})
        
        # Aggregate CEFR vocabulary words
        vocab_data = attempt.get("vocabulary") or {}
        cefr_dist = vocab_data.get("cefr_distribution", {}) if vocab_data else {}
        for level in ["A1", "A2", "B1", "B2", "C1", "C2"]:
            level_data = cefr_dist.get(level, {})
            if isinstance(level_data, dict):
                words = level_data.get("words", [])
                if isinstance(words, list):
                    safe_words = [w for w in words if isinstance(w, str)]
                    vocab_overall[level]["words"].extend(safe_words)
                    vocab_overall[level]["count"] = len(set(vocab_overall[level]["words"]))
    
    # Deduplicate vocab words and calculate percentages
    total_vocab_words = sum(len(set(vocab_overall[level]["words"])) for level in vocab_overall)
    for level in vocab_overall:
        vocab_overall[level]["words"] = list(set(vocab_overall[level]["words"]))
        vocab_overall[level]["count"] = len(vocab_overall[level]["words"])
        vocab_overall[level]["percentage"] = round((vocab_overall[level]["count"] / total_vocab_words * 100), 1) if total_vocab_words > 0 else 0
    
    
    llm_summary = await generate_session_summary_llm(
        user_name=session["name"],
        scenario=session.get("scenario", "interview"),
        final_scores=final_scores,
        chat_history=session["chat_history"],
        total_turns=session.get("turn_number", 0),
        average_wpm=average_wpm,
        turn_history=turn_history,
        model=model,
        target_language=session.get("target_language", "en")
    )
    
    # Build turn_feedback for termination response (same format as /interview_feedback)
    turn_feedback = []
    # Aggregate grammar mistakes and vocabulary suggestions from all turns
    grammar_mistakes = []
    vocab_suggestions = []
    pronunciation_issues = []
    
    for i, attempt in enumerate(session.get("attempts", []), 1):
        turn_feedback.append({
            "turn": i,
            "transcription": attempt.get("transcription", ""),
            "grammar": attempt.get("grammar", {}),
            "vocabulary": attempt.get("vocabulary", {}),
            "pronunciation": attempt.get("pronunciation"),
            "fluency": attempt.get("fluency"),
            "answer_evaluation": attempt.get("answer_evaluation", {}),
            "personalized_feedback": attempt.get("personalized_feedback", {}),
            "improvement": attempt.get("improvement"),
            "overall_score": attempt.get("overall_score", 0)
        })
        
        # Collect grammar errors (wrong â†’ correct)
        gram = attempt.get("grammar") or {}
        if isinstance(gram, dict):
            for err in gram.get("errors", []):
                if isinstance(err, dict):
                    grammar_mistakes.append({
                        "wrong": err.get("you_said", err.get("wrong_word", "")),
                        "correct": err.get("should_be", err.get("correct_word", ""))
                    })
        
        # Collect vocabulary suggestions (weak word â†’ better word)
        vocab = attempt.get("vocabulary") or {}
        if isinstance(vocab, dict):
            for sug in vocab.get("suggestions", []):
                if isinstance(sug, dict):
                    better = sug.get("better_word", "")
                    if isinstance(better, list):
                        better_options = better
                    elif better:
                        better_options = [better]
                    else:
                        better_options = []
                    vocab_suggestions.append({
                        "weak_word": sug.get("word", ""),
                        "better_options": better_options
                    })
        
        # Collect pronunciation issues
        pron = attempt.get("pronunciation") or {}
        if isinstance(pron, dict):
            for word_issue in pron.get("words_to_practice", []):
                if isinstance(word_issue, dict):
                    pronunciation_issues.append({
                        "word": word_issue.get("word", ""),
                        "issue": word_issue.get("issue", ""),
                        "how_to_say": word_issue.get("how_to_say", "")
                    })
    
    # Build summary of all mistakes
    summary = {
        "grammar": {
            "total_errors": len(grammar_mistakes),
            "errors": grammar_mistakes
        },
        "vocabulary": {
            "total_suggestions": len(vocab_suggestions),
            "suggestions": vocab_suggestions
        },
        "pronunciation": {
            "total_issues": len(pronunciation_issues),
            "issues": pronunciation_issues
        }
    }

    termination_response = {
        "status": "conversation_ended", 
        "session_id": session_id,
        "target_lang": session.get("target_language", "en"),
        "native_lang": session.get("native_language", "hi"),
        "final_scores": final_scores, 
        "overall_score": overall, 
        "passing_score": PASSING_SCORE,
        "average_wpm": average_wpm,
        "wpm_per_turn": wpm_per_turn,
        "wpm_status": "slow" if average_wpm < 110 else "normal" if average_wpm <= 160 else "fast",
        "vocab_overall": vocab_overall,
        "strengths": strengths, 
        "improvement_areas": improvement_areas,
        "total_turns": session.get("turn_number", 0),
        "turn_history": turn_history,  
        "turn_feedback": turn_feedback,
        "summary": summary,
        "overall_assessment": llm_summary.get("overall_assessment", ""),
        "grammar_feedback": llm_summary.get("grammar_feedback", {}),
        "vocabulary_feedback": llm_summary.get("vocabulary_feedback", {}),
        "pronunciation_feedback": llm_summary.get("pronunciation_feedback", {}),
        "fluency_feedback": llm_summary.get("fluency_feedback", {}),
        "interview_skills": llm_summary.get("interview_skills", {}),
        "action_plan": llm_summary.get("action_plan", []),
        "encouragement": llm_summary.get("encouragement", ""),
        "next_practice_topics": llm_summary.get("next_practice_topics", [])
    }
    await db.complete_session(session_id, final_feedback=termination_response)

    return termination_response


@router.post("/practice")
async def practice_interview(
    request: Request,
    name: str = Form(...),
    native_language: str = Form(default="hi"),
    target_language: str = Form(default="en"),
    level: str = Form(default="B1"),
    user_type: Optional[str] = Form(default="student"),
    audio_file: Optional[UploadFile] = File(default=None),
    text_input: Optional[str] = Form(default=None),
    session_id: Optional[str] = Form(default=None),
    action: Optional[str] = Form(default=None),  
    model: Optional[str] = Form(default="gpt"),  
    voice_id: Optional[str] = Form(default=None),
    current_user: User = Depends(get_current_user),

):
    """
    interview practice api - CONVERSATIONAL ONBOARDING
    
    flow:
    1. first call (no audio/text): Clara greets and asks for role
    2. user provides role: Clara asks for interview type
    3. user provides type: interview begins with first question
    4. subsequent calls: normal interview with analysis
    5. action="end" or termination phrase: ends session
    """
    try:
        user_text = ""
        audio_path = None

        if not session_id or session_id.strip() == "" or session_id == "string":
            session_id = str(uuid.uuid4())
        
        
        session = await db.get_user_session(session_id)
        session_exists = session is not None
        native_language = session.get("native_language", native_language) if session else native_language
        target_language = session.get("target_language", target_language) if session else target_language
        stored_user_type = session.get("user_type") if session else None

        native_language = normalize_language_code(native_language, default="en")
        target_language = normalize_language_code(target_language, default="en")
        user_type = normalize_user_type(stored_user_type or user_type)

        if session_exists:
            needs_update = False
            if session.get("native_language") != native_language or session.get("target_language") != target_language:
                session["native_language"] = native_language
                session["target_language"] = target_language
                needs_update = True
            if not session.get("user_type"):
                session["user_type"] = user_type
                needs_update = True
            if needs_update:
                await db.update_session(session_id, session)
        
        
        if session_exists and session.get("status") == "completed":
            error_msg = await translate_text("This session has ended. Please start a new session.", "en", native_language)
            return {"status": "error", "session_id": session_id, "error": error_msg} 
        
        if not session_exists:
            
            session = {
                "state": "welcome",  
                "name": name, 
                "scenario": None,  
                "role": None,      
                "level": level,
                "user_type": user_type,
                "native_language": native_language, 
                "target_language": target_language,
                "chat_history": [],
                "scores": {"grammar": 0, "vocabulary": 0, "pronunciation": 0, "fluency": 0, "total_wpm": 0, "count": 0, "audio_count": 0},
                "current_question": None, "current_hint": None, "turn_number": 0,
                "last_overall_score": None, "retry_count": 0, "attempts": [],
                "turn_history": [],  
                "onboarding_retry": 0  
            }
            await db.create_session(
                session_id=session_id,
                session_type="interview",
                data=session,
                user_id=current_user.id if current_user else None,
                user_name=name
            )
        
        
        current_state = session.get("state", "interviewing") 
        
        
        if current_state == "welcome" and not audio_file and not text_input:
            greeting = f"Hi {name}! I'm {BOT_NAME}, your interview coach ðŸ™‚ So, which role are you ready for?"
            
            greeting_target, greeting_native = await asyncio.gather(
                translate_text(greeting, "en", target_language),
                translate_text(greeting, "en", native_language)
            )
            
            session["state"] = "collecting_role"
            session["chat_history"].append({"role": "assistant", "content": greeting})
            await db.update_session(session_id, session)
            
            greeting_audio = await generate_tts_url(request, greeting_target, target_language, api_type="interview", voice_id=voice_id)
            
            return {
                "status": "onboarding",
                "step": "collecting_role",
                "session_id": session_id,
                "target_lang": target_language,
                "native_lang": native_language,
                "transcription": user_text,
                "message": {"target": greeting_target, "native": greeting_native},
                "audio_url": greeting_audio
            }
        
        
        if current_state == "collecting_role":
            user_text = text_input or ""
            if audio_file:
                
                user_text = await transcribe_audio_file(audio_file, target_language)
            
            if not user_text.strip():
                error_msg = await translate_text("No speech detected. Please tell me which role you're preparing for.", "en", native_language)
                return {"status": "error", "session_id": session_id, "error": error_msg}
            
            session["chat_history"].append({"role": "user", "content": user_text})
            
            
            extraction = await extract_role_from_text(user_text, model=model)
            
            if extraction.get("success") and extraction.get("role"):
                role = extraction["role"]
                session["role"] = role
                session["state"] = "collecting_type"
                session["onboarding_retry"] = 0
                
                
                ask_type = f"Great, {role}! Is this more of an HR interview, or would you prefer something else like behavioral or technical?"
                ask_type_target, ask_type_native = await asyncio.gather(
                    translate_text(ask_type, "en", target_language),
                    translate_text(ask_type, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": ask_type})
                await db.update_session(session_id, session)
                
                ask_type_audio = await generate_tts_url(request, ask_type_target, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "onboarding",
                    "step": "collecting_type", 
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "role": role,
                    "message": {"target": ask_type_target, "native": ask_type_native},
                    "audio_url": ask_type_audio
                }
            else:
                
                session["onboarding_retry"] = session.get("onboarding_retry", 0) + 1
                retry_msg = "Could you be more specific about the role? For example: Software Engineer, Marketing Manager, Business Analyst, etc."
                retry_target, retry_native = await asyncio.gather(
                    translate_text(retry_msg, "en", target_language),
                    translate_text(retry_msg, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": retry_msg})
                await db.update_session(session_id, session)
                
                retry_audio = await generate_tts_url(request, retry_target, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "onboarding",
                    "step": "collecting_role",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "retry": True,
                    "message": {"target": retry_target, "native": retry_native},
                    "audio_url": retry_audio
                }
        
        if current_state == "collecting_type":
            user_text = text_input or ""
            if audio_file:
                
                user_text = await transcribe_audio_file(audio_file, target_language)
            
            if not user_text.strip():
                error_msg = await translate_text("No speech detected. Please tell me the interview type.", "en", native_language)
                return {"status": "error", "session_id": session_id, "error": error_msg}
            
            session["chat_history"].append({"role": "user", "content": user_text})
            
            
            extraction = await extract_interview_type_from_text(user_text, model=model)
            
            if extraction.get("success") and extraction.get("type"):
                interview_type = extraction["type"]
                session["scenario"] = interview_type
                session["state"] = "interviewing"
                session["onboarding_retry"] = 0
                
                
                role = session.get("role", "Professional")
                scenario_name = INTERVIEW_SCENARIOS.get(interview_type, interview_type.title() + " Interview")
                
                question, hint = await generate_interview_question(
                    interview_type, role, level, name, user_type=user_type, model=model, target_language=target_language, turn_number=0
                )
                
                start_msg = f"Perfect! Let's start your {scenario_name} practice for {role}."
                start_target, start_native, q_native, h_native = await asyncio.gather(
                    translate_text(start_msg, "en", target_language),
                    translate_text(start_msg, "en", native_language),
                    translate_text(question, target_language, native_language),
                    translate_text(hint, target_language, native_language)
                )
                
                session["current_question"] = question
                session["current_hint"] = hint
                session["chat_history"].append({"role": "assistant", "content": question})
                await db.update_session(session_id, session)
                
                question_audio = await generate_tts_url(request, question, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "interview_started",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "role": role,
                    "scenario": interview_type,
                    "greeting": {"target": start_target, "native": start_native},
                    "next_question": {"target": question, "native": q_native},
                    "hint": {"target": hint, "native": h_native},
                    "turn_number": 0,
                    "audio_url": question_audio
                }
            else:
                
                session["onboarding_retry"] = session.get("onboarding_retry", 0) + 1
                retry_msg = "What type of interview would you like to practice? For example: HR, Technical, Sales, Marketing, Customer Service, or any other type?"
                retry_target, retry_native = await asyncio.gather(
                    translate_text(retry_msg, "en", target_language),
                    translate_text(retry_msg, "en", native_language)
                )
                
                session["chat_history"].append({"role": "assistant", "content": retry_msg})
                await db.update_session(session_id, session)
                
                retry_audio = await generate_tts_url(request, retry_target, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "onboarding",
                    "step": "collecting_type",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "retry": True,
                    "message": {"target": retry_target, "native": retry_native},
                    "audio_url": retry_audio
                }
        
        
        role = session.get("role", "Professional")
        scenario = session.get("scenario", "general")
        
        if action == "next":
            follow_up, hint = await generate_interactive_follow_up("", session["chat_history"], role, scenario, user_type=user_type, model=model, target_language=target_language)
            session["current_question"] = follow_up
            session["current_hint"] = hint
            session["chat_history"].append({"role": "assistant", "content": follow_up})
            
            session["retry_count"] = 0
            session["waiting_retry_decision"] = False  
            session["retry_clarify_count"] = 0  
            
            
            await db.update_session(session_id, session)
            
            follow_up_audio = await generate_tts_url(request, follow_up, target_language, api_type="interview", voice_id=voice_id)
            
            skipped_msg = await translate_text("Skipped", "en", target_language) if target_language != "en" else "Skipped"
            skipped_next_msg = await translate_text("Skipped. Let's try this question!", "en", target_language) if target_language != "en" else "Skipped. Let's try this question!"

            return {
                "status": "continue", "session_id": session_id,
                "target_lang": target_language, "native_lang": native_language,
                "transcription": "(skipped)",
                "next_question": {"target": follow_up, "native": await translate_text(follow_up, target_language, native_language)},
                "hint": {"target": hint, "native": await translate_text(hint, target_language, native_language)},
                "grammar": {"score": 0, "is_correct": True, "errors": [], "feedback": skipped_msg},
                "vocabulary": {"score": 0, "overall_level": "skipped", "feedback": skipped_msg},
                "pronunciation": {"accuracy": 0, "word_pronunciation_scores": [], "feedback": skipped_msg},
                "fluency": {"score": 0, "wpm": 0, "speed_status": "skipped"},
                "answer_evaluation": {"clarity": "", "structure": "", "relevance": "", "improved_answer": ""},
                "personalized_feedback": {"message": skipped_next_msg, "improvement_areas": [], "strengths": []},
                "overall_score": 0, "passing_score": PASSING_SCORE, "should_retry": False, "turn_number": session["turn_number"],
                "audio_url": follow_up_audio
            }
        
        if action == "end":
            return await handle_session_termination(session, session_id, model)
        
        if not audio_file and not text_input:
            
            current_q = session.get("current_question")
            current_h = session.get("current_hint", "")
            
            if current_q:
                
                q_native = await translate_text(current_q, target_language, native_language)
                h_native = await translate_text(current_h, target_language, native_language)
                
                current_q_audio = await generate_tts_url(request, current_q, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "next_question": {"target": current_q, "native": q_native},
                    "hint": {"target": current_h, "native": h_native},
                    "turn_number": session.get("turn_number", 0),
                    "audio_url": current_q_audio
                }
            else:
                
                question, hint = await generate_interview_question(
                    scenario, role, session.get("level", level), name, user_type=user_type, model=model, target_language=target_language, turn_number=session.get("turn_number", 0)
                )
                session["current_question"] = question
                session["current_hint"] = hint
                session["chat_history"].append({"role": "assistant", "content": question})
                await db.update_session(session_id, session)
                
                q_native = await translate_text(question, target_language, native_language)
                h_native = await translate_text(hint, target_language, native_language)
                
                question_audio = await generate_tts_url(request, question, target_language, api_type="interview", voice_id=voice_id)
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "next_question": {"target": question, "native": q_native},
                    "hint": {"target": hint, "native": h_native},
                    "turn_number": session.get("turn_number", 0),
                    "audio_url": question_audio
                }
        
        user_text = text_input or ""
        audio_path = None
        audio_duration = 5.0
        is_audio_input = audio_file is not None  
        
        if audio_file:
            try:
                audio_file.file.seek(0)
            except Exception:
                pass
            with tempfile.NamedTemporaryFile(delete=False, suffix=".tmp") as tmp:
                shutil.copyfileobj(audio_file.file, tmp)
                temp_upload = tmp.name
            
            try:
                
                def convert_audio():
                    audio = AudioSegment.from_file(temp_upload)
                    audio = audio.set_frame_rate(16000).set_channels(1)
                    converted_path = temp_upload.replace('.tmp', '_converted.wav')
                    audio.export(converted_path, format="wav")
                    return converted_path, len(audio) / 1000
                
                audio_path, audio_duration = await asyncio.to_thread(convert_audio)
                os.unlink(temp_upload)  
            except Exception as e:
                logger.debug(f"Audio conversion fallback: {e}")
                audio_path = temp_upload
                audio_duration = 0
            finally:
                
                
                if audio_path != temp_upload and os.path.exists(temp_upload):
                    try:
                        os.unlink(temp_upload)
                    except Exception:
                        pass
        
        if is_audio_input:
            pronunciation = await analyze_pronunciation_llm(audio_path=audio_path, spoken_text=user_text, level=session.get("level", level), model=model, target_language=target_language)
            
            if pronunciation and pronunciation.get("transcription"):
                user_text = pronunciation["transcription"]
        else:
            pronunciation = None   
        
        if audio_path:
            try:
                os.unlink(audio_path)
            except Exception:
                pass
        
        if not user_text or not user_text.strip():
            error_msg = await translate_text("No speech detected. Please try again.", "en", native_language)
            return {"status": "error", "session_id": session_id, "error": error_msg}
        
        user_text = user_text.strip()
        session["chat_history"].append({"role": "user", "content": user_text})
        
        if session.get("waiting_retry_decision"):
            user_choice = user_text.lower().strip()
            
            
            cleaned_choice = user_choice.rstrip('.,!?')
            if cleaned_choice in TERMINATION_PHRASES:
                
                session["waiting_retry_decision"] = False
                return await handle_session_termination(session, session_id, model)
            
            is_english = target_language.lower() in ["en", "english"]
            if is_english:
                retry_keywords = ["yes", "retry", "practice", "again", "try", "redo", "repeat", "once more", "one more"]
                skip_keywords = ["no", "skip", "next", "move", "forward", "pass", "don't want", "not now", "let's move", "move on", "go ahead"]
                wants_retry = any(keyword in user_choice for keyword in retry_keywords)
                wants_skip = any(keyword in user_choice for keyword in skip_keywords)
            else:
                cleaned_choice = re.sub(r"[\s\W_]+", "", user_choice)
                wants_retry = cleaned_choice == "1"
                wants_skip = cleaned_choice == "2"
            
            if wants_retry:
                
                session["waiting_retry_decision"] = False  
                session["retry_clarify_count"] = 0  
                current_q = session.get("current_question", "")
                current_h = session.get("current_hint", "")
                session["chat_history"].append({"role": "assistant", "content": current_q})
                await db.update_session(session_id, session)
                
                retry_msg = "Let's try this again! Take your time."
                q_native, h_native, retry_msg_target, retry_msg_native = await asyncio.gather(
                    translate_text(current_q, target_language, native_language),
                    translate_text(current_h, target_language, native_language),
                    translate_text(retry_msg, "en", target_language),
                    translate_text(retry_msg, "en", native_language)
                )
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "next_question": {"target": current_q, "native": q_native},
                    "hint": {"target": current_h, "native": h_native},
                    "message": {"target": retry_msg_target, "native": retry_msg_native},
                    "turn_number": session.get("turn_number", 0)
                }
            elif wants_skip:
                
                session["waiting_retry_decision"] = False  
                session["retry_clarify_count"] = 0  
                follow_up, hint = await generate_interactive_follow_up("", session["chat_history"], role, scenario, user_type=user_type, model=model, target_language=target_language)
                session["current_question"] = follow_up
                session["current_hint"] = hint
                session["chat_history"].append({"role": "assistant", "content": follow_up})
                session["retry_count"] = 0
                
                await db.update_session(session_id, session)
                
                follow_up_native, hint_native = await asyncio.gather(
                    translate_text(follow_up, target_language, native_language),
                    translate_text(hint, target_language, native_language)
                )
                
                return {
                    "status": "continue",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "next_question": {"target": follow_up, "native": follow_up_native},
                    "hint": {"target": hint, "native": hint_native},
                    "turn_number": session["turn_number"]
                }
            else:
                
                clarify_count = session.get("retry_clarify_count", 0) + 1
                session["retry_clarify_count"] = clarify_count
                
                
                if clarify_count >= 3:
                    session["waiting_retry_decision"] = False
                    session["retry_clarify_count"] = 0
                    
                    auto_skip_msg = "I see you're having trouble deciding. Let's move on to the next question!"
                    follow_up, hint = await generate_interactive_follow_up("", session["chat_history"], role, scenario, user_type=user_type, model=model, target_language=target_language)
                    session["current_question"] = follow_up
                    session["current_hint"] = hint
                    session["chat_history"].append({"role": "assistant", "content": auto_skip_msg})
                    session["chat_history"].append({"role": "assistant", "content": follow_up})
                    session["retry_count"] = 0
                    
                    await db.update_session(session_id, session)
                    
                    auto_skip_target, auto_skip_native, follow_up_native, hint_native = await asyncio.gather(
                        translate_text(auto_skip_msg, "en", target_language),
                        translate_text(auto_skip_msg, "en", native_language),
                        translate_text(follow_up, target_language, native_language),
                        translate_text(hint, target_language, native_language)
                    )
                    
                    return {
                        "status": "auto_skipped",
                        "session_id": session_id,
                        "target_lang": target_language,
                        "native_lang": native_language,
                        "message": {"target": auto_skip_target, "native": auto_skip_native},
                        "next_question": {"target": follow_up, "native": follow_up_native},
                        "hint": {"target": hint, "native": hint_native},
                        "turn_number": session["turn_number"],
                        
                        "grammar": None,
                        "vocabulary": None,
                        "pronunciation": None,
                        "fluency": None,
                        "answer_evaluation": None,
                        "emotion": None,
                        "personalized_feedback": None,
                        "overall_score": None,
                        "improvement": None
                    }
                else:
                    
                    current_q = session.get("current_question", "")
                    current_h = session.get("current_hint", "")
                    level = session.get("level", "B1")
                    
                    if is_audio_input:
                        grammar, vocabulary, answer_eval, fluency = await asyncio.gather(
                            analyze_grammar_llm(user_text, level=level, model=model, target_language=target_language),
                            analyze_vocab_llm(user_text, level=level, model=model, target_language=target_language),
                            evaluate_answer(current_q, user_text, level, model=model, target_language=target_language),
                            analyze_fluency_metrics(user_text, audio_duration)
                        )
                    else:
                        
                        grammar, vocabulary, answer_eval = await asyncio.gather(
                            analyze_grammar_llm(user_text, level=level, model=model, target_language=target_language),
                            analyze_vocab_llm(user_text, level=level, model=model, target_language=target_language),
                            evaluate_answer(current_q, user_text, level, model=model, target_language=target_language)
                        )
                        pronunciation = None
                        fluency = None
                    
                    
                    if is_audio_input:
                        scores = {
                            "grammar": grammar.get("score", 70),
                            "vocabulary": vocabulary.get("score", 70),
                            "pronunciation": pronunciation.get("score", pronunciation.get("accuracy", 70)) if pronunciation else 0,
                            "fluency": fluency.get("score", 70) if fluency else 0,
                            "answer_evaluation": answer_eval.get("score", 50)
                        }
                        
                        overall_score = int(
                            scores["grammar"] * 0.25 +
                            scores["vocabulary"] * 0.25 +
                            scores["answer_evaluation"] * 0.25 +
                            scores["pronunciation"] * 0.15 +
                            scores["fluency"] * 0.10
                        )
                    else:
                        scores = {
                            "grammar": grammar.get("score", 70),
                            "vocabulary": vocabulary.get("score", 70),
                            "pronunciation": None,
                            "fluency": None,
                            "answer_evaluation": answer_eval.get("score", 50)
                        }
                        
                        overall_score = int(
                            scores["grammar"] * 0.33 +
                            scores["vocabulary"] * 0.33 +
                            scores["answer_evaluation"] * 0.34
                        )

                    
                    
                    emotion = {"emotion": "neutral", "confidence_level": "medium", "explanation": ""}
                    personalized_feedback = await generate_personalized_feedback(
                        overall_score, scores, emotion, session.get("name", "User"),
                        grammar=grammar, vocabulary=vocabulary, 
                        pronunciation=pronunciation, answer_eval=answer_eval, model=model,
                        target_language=target_language
                    )
                    
                    
                    if clarify_count == 1:
                        is_english = target_language.lower() in ["en", "english"]
                        
                        if is_english:
                            clarify_msg = "I heard you say something, but I'm not sure if you want to practice again or move on. Just say 'retry' or 'skip' - or you can try answering the question again!"
                        else:
                            clarify_msg = "I heard you say something, but I'm not sure if you want to practice again or move on. Type 1 to retry, 2 to skip."
                    else:
                        clarify_msg = "Still not quite sure what you'd like to do. Say 'yes' to practice the same question, or 'skip' to get a new one. One more unclear response and I'll move you to the next question."

                    
                    await db.update_session(session_id, session)
                    
                    
                    if is_audio_input and pronunciation and fluency:
                        (clarify_target, clarify_native, q_native, h_native, grammar_t, vocab_t, 
                         pron_t, fluency_t, eval_t, personal_t) = await asyncio.gather(
                            translate_text(clarify_msg, "en", target_language),
                            translate_text(clarify_msg, "en", native_language),
                            translate_text(current_q, target_language, native_language),
                            translate_text(current_h, target_language, native_language),
                            translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                            translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                            translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS),
                            translate_analysis(fluency, target_language, native_language, FLUENCY_FIELDS),
                            translate_analysis(answer_eval, target_language, native_language, EVAL_FIELDS),
                            translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS)
                        )
                    else:
                        (clarify_target, clarify_native, q_native, h_native, grammar_t, vocab_t, 
                         eval_t, personal_t) = await asyncio.gather(
                            translate_text(clarify_msg, "en", target_language),
                            translate_text(clarify_msg, "en", native_language),
                            translate_text(current_q, target_language, native_language),
                            translate_text(current_h, target_language, native_language),
                            translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                            translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                            translate_analysis(answer_eval, target_language, native_language, EVAL_FIELDS),
                            translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS)
                        )
                        pron_t = None
                        fluency_t = None
                    
                    return {
                        "status": "clarify_retry",
                        "session_id": session_id,
                        "target_lang": target_language,
                        "native_lang": native_language,
                        "transcription": user_text,
                        "message": {"target": clarify_target, "native": clarify_native},
                        "next_question": {"target": current_q, "native": q_native},
                        "hint": {"target": current_h, "native": h_native},
                        "grammar": grammar_t,
                        "vocabulary": vocab_t,
                        "pronunciation": pron_t,
                        "fluency": fluency_t,
                        "answer_evaluation": eval_t,
                        "emotion": emotion,
                        "personalized_feedback": personal_t,
                        "overall_score": overall_score,
                        "clarify_count": clarify_count,
                        "turn_number": session.get("turn_number", 0)
                    }

        
        
        cleaned_text = user_text.lower().strip().rstrip('.,!?')
        is_termination = cleaned_text in TERMINATION_PHRASES or action == "end"
        
        grammar, vocabulary, answer_eval = await asyncio.gather(
            analyze_grammar_llm(user_text, level=level, model=model, target_language=target_language),
            analyze_vocab_llm(user_text, level=level, model=model, target_language=target_language),
            evaluate_answer(session.get("current_question", ""), user_text, level, model=model, target_language=target_language)
        )
        
        
        emotion = {"emotion": "neutral", "confidence_level": "medium", "explanation": ""}
        
        
        if is_audio_input:
            word_count = len(user_text.split())
            fluency = calculate_fluency(word_count, audio_duration)
        else:
            fluency = None  

        
        
        
        
        if not is_termination and session.get("current_question"):
            relevance_check = await check_answer_relevance(session["current_question"], user_text, model=model, target_language=target_language)
            
            if not relevance_check.get("relevant", True):
                
                redirect_msg = relevance_check.get("redirect")
                if not redirect_msg:
                    redirect_msg = "Let's stay on track! ????"
                    if target_language != "en":
                        redirect_msg = await translate_text(redirect_msg, "en", target_language)
                current_q = session["current_question"]
                current_h = session.get("current_hint", "")
                
                
                full_response = f"{redirect_msg}\n\n{current_q}"
                session["chat_history"].append({"role": "assistant", "content": full_response})
                await db.update_session(session_id, session)
                
                redirect_native, q_native, h_native, grammar_t, vocab_t, eval_t = await asyncio.gather(
                    translate_text(redirect_msg, target_language, native_language),
                    translate_text(current_q, target_language, native_language),
                    translate_text(current_h, target_language, native_language),
                    translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                    translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                    translate_analysis(answer_eval, target_language, native_language, EVAL_FIELDS)
                )
                
                
                if is_audio_input and pronunciation and fluency:
                    pron_t, fluency_t = await asyncio.gather(
                        translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS),
                        translate_analysis(fluency, target_language, native_language, FLUENCY_FIELDS)
                    )
                    scores = {
                        "grammar": grammar.get("score", 75),
                        "vocabulary": vocabulary.get("score", 75),
                        "pronunciation": pronunciation.get("accuracy", 75),
                        "fluency": fluency.get("score", 75),
                        "answer_evaluation": answer_eval.get("score", 50)
                    }
                    answer_score = answer_eval.get("score", 50)
                    overall_score = int(
                        scores["grammar"] * 0.25 +
                        scores["vocabulary"] * 0.25 +
                        answer_score * 0.25 +
                        scores["pronunciation"] * 0.15 +
                        scores["fluency"] * 0.10
                    )
                else:
                    pron_t = None
                    fluency_t = None
                    scores = {
                        "grammar": grammar.get("score", 75),
                        "vocabulary": vocabulary.get("score", 75),
                        "pronunciation": None,
                        "fluency": None,
                        "answer_evaluation": answer_eval.get("score", 50)
                    }
                    answer_score = answer_eval.get("score", 50)
                    
                    overall_score = int(
                        scores["grammar"] * 0.33 +
                        scores["vocabulary"] * 0.33 +
                        answer_score * 0.34
                    )

                personalized_feedback = await generate_personalized_feedback(overall_score, scores, emotion, session["name"], model=model, target_language=target_language)
                
                
                personal_t = await translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS)
                
                return {
                    "status": "redirect",
                    "session_id": session_id,
                    "target_lang": target_language,
                    "native_lang": native_language,
                    "transcription": user_text,
                    "message": {"target": redirect_msg, "native": redirect_native},
                    "next_question": {"target": current_q, "native": q_native},
                    "hint": {"target": current_h, "native": h_native},
                    
                    "grammar": grammar_t,
                    "vocabulary": vocab_t,
                    "pronunciation": pron_t,
                    "fluency": fluency_t,
                    "answer_evaluation": eval_t,
                    "emotion": emotion,
                    "personalized_feedback": personal_t,
                    "overall_score": overall_score,
                    "passing_score": PASSING_SCORE,
                    "improvement": None,  
                    "turn_number": session.get("turn_number", 0)
                }
        
        
        if is_termination:
            return await handle_session_termination(session, session_id, model)

        
        
        if is_audio_input:
            scores = {
                "grammar": grammar.get("score", 75),
                "vocabulary": vocabulary.get("score", 75),
                "pronunciation": pronunciation.get("accuracy", 75) if pronunciation else 0,
                "fluency": fluency.get("score", 75) if fluency else 0
            }
        else:
            scores = {
                "grammar": grammar.get("score", 75),
                "vocabulary": vocabulary.get("score", 75),
                "pronunciation": None,  
                "fluency": None
            }
        
        
        answer_score = answer_eval.get("score", 50)
        feedback_scores = {**scores, "answer_evaluation": answer_score}
        if is_audio_input:
            
            overall_score = int(
                scores["grammar"] * 0.25 +
                scores["vocabulary"] * 0.25 +
                answer_score * 0.25 +
                scores["pronunciation"] * 0.15 +
                scores["fluency"] * 0.10
            )
        else:
            
            overall_score = int(
                scores["grammar"] * 0.33 +
                scores["vocabulary"] * 0.33 +
                answer_score * 0.34
            )
        
        
        session["scores"]["grammar"] += scores["grammar"]
        session["scores"]["vocabulary"] += scores["vocabulary"]
        if is_audio_input:
            session["scores"]["pronunciation"] += scores["pronunciation"]
            session["scores"]["fluency"] += scores["fluency"]
            session["scores"]["total_wpm"] += fluency.get("wpm", 100) if fluency else 100
            session["scores"]["audio_count"] = session["scores"].get("audio_count", 0) + 1  
        session["scores"]["answer"] = session["scores"].get("answer", 0) + answer_score  
        session["scores"]["count"] += 1

        session["turn_number"] += 1
        

        
        
        personalized_feedback, (follow_up_question, follow_up_hint) = await asyncio.gather(
            generate_personalized_feedback(
                overall_score, feedback_scores, emotion, session["name"],
                grammar=grammar, vocabulary=vocabulary, 
                pronunciation=pronunciation, answer_eval=answer_eval, model=model,
                target_language=target_language
            ),
            generate_interactive_follow_up(user_text, session["chat_history"], role, scenario, user_type=user_type, model=model, target_language=target_language)
        )
        
        
        improvement = {}
        is_retrying = session.get("retry_count", 0) > 0
        prev_overall = session.get("last_overall_score")
        
        
        if is_retrying and prev_overall is not None:
            
            current_attempt = {
                "transcription": user_text,
                "grammar": grammar,
                "vocabulary": vocabulary,
                "pronunciation": pronunciation,
                "fluency": fluency,
                "answer_evaluation": answer_eval,
                "overall_score": overall_score
            }
            session.setdefault("attempts", []).append(current_attempt)
            
            
            improvement = await compare_attempts(
                session["attempts"], 
                level="B1",  
                user_type=user_type, 
                model=model,
                target_language=target_language
            )
        else:
            
            current_attempt = {
                "transcription": user_text,
                "grammar": grammar,
                "vocabulary": vocabulary,
                "pronunciation": pronunciation,
                "fluency": fluency,
                "answer_evaluation": answer_eval,
                "overall_score": overall_score
            }
            session.setdefault("attempts", []).append(current_attempt)
        
        
        
        session["last_scores"] = scores.copy()
        session["last_overall_score"] = overall_score
        
        
        if "turn_history" not in session:
            session["turn_history"] = []
        
        turn_data = {
            "turn_number": session["turn_number"],
            "turn": session["turn_number"],  
            "transcription": user_text,
            "question": session.get("current_question", ""),
            "scores": scores.copy(),
            "overall_score": overall_score,
            "wpm": fluency.get("wpm", 0) if fluency else 0,  
            "grammar": grammar,
            "vocabulary": vocabulary,
            "pronunciation": pronunciation,
            "fluency": fluency,
            "answer_evaluation": answer_eval,
            "emotion": emotion,
            "personalized_feedback": personalized_feedback,
            "improvement": improvement
        }
        session["turn_history"].append(turn_data)
        
        
        should_retry = (overall_score < PASSING_SCORE or action == "practice")
        
        if should_retry:
            session["retry_count"] = session.get("retry_count", 0) + 1
            session["waiting_retry_decision"] = True  
            current_q = session.get("current_question", "")
            current_h = session.get("current_hint", "")
            
            
            retry_ask = "I see your answer, but it could be stronger. Type 1 to retry, 2 to skip."
            
            
            base_tasks = [
                translate_text(retry_ask, "en", target_language),
                translate_text(retry_ask, "en", native_language),
                translate_text(current_q, target_language, native_language),
                translate_text(current_h, target_language, native_language),
                translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                translate_analysis(answer_eval, target_language, native_language, EVAL_FIELDS)
            ]
            base_results = await asyncio.gather(*base_tasks)
            retry_ask_target, retry_ask_native, q_native, h_native, grammar_t, vocab_t, eval_t = base_results
            
            
            pron_t = await translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS) if pronunciation else None
            fluency_t = await translate_analysis(fluency, target_language, native_language, FLUENCY_FIELDS) if fluency else None
            
            await db.update_session(session_id, session, overall_score=overall_score)
            
            retry_ask_audio = await generate_tts_url(request, retry_ask_target, target_language, api_type="interview")
            
            return {
                "status": "feedback",
                "session_id": session_id,
                "target_lang": target_language,
                "native_lang": native_language,
                "transcription": user_text,
                "message": {"target": retry_ask_target, "native": retry_ask_native},
                "next_question": {"target": current_q, "native": q_native},
                "hint": {"target": current_h, "native": h_native},
                "grammar": grammar_t,
                "vocabulary": vocab_t,
                "pronunciation": pron_t,
                "fluency": fluency_t,
                "answer_evaluation": eval_t,
                "emotion": emotion,
                "personalized_feedback": personalized_feedback,
                "overall_score": overall_score,
                "passing_score": PASSING_SCORE,
                "should_retry": True,
                "retry_count": session.get("retry_count", 1),
                "improvement": improvement,
                "turn_number": session["turn_number"],
                "audio_url": retry_ask_audio
            }
        else:
            
            session["current_question"] = follow_up_question
            session["current_hint"] = follow_up_hint
            session["chat_history"].append({"role": "assistant", "content": follow_up_question})
            session["retry_count"] = 0
            
            
            base_tasks = [
                translate_text(follow_up_question, target_language, native_language),
                translate_text(follow_up_hint, target_language, native_language),
                translate_analysis(grammar, target_language, native_language, GRAMMAR_FIELDS),
                translate_analysis(vocabulary, target_language, native_language, VOCAB_FIELDS),
                translate_analysis(personalized_feedback, target_language, native_language, PERSONAL_FIELDS),
                translate_analysis(answer_eval, target_language, native_language, EVAL_FIELDS)
            ]
            base_results = await asyncio.gather(*base_tasks)
            follow_up_native, hint_native, grammar_t, vocab_t, personal_t, eval_t = base_results
            
            
            pron_t = await translate_analysis(pronunciation, target_language, native_language, PRON_FIELDS) if pronunciation else None
            fluency_t = await translate_analysis(fluency, target_language, native_language, FLUENCY_FIELDS) if fluency else None
            
            await db.update_session(session_id, session, overall_score=overall_score)
            
            follow_up_audio = await generate_tts_url(request, follow_up_question, target_language, api_type="interview")
            
            return {
                "status": "continue", "session_id": session_id, 
                "target_lang": target_language, "native_lang": native_language,
                "transcription": user_text,
                "next_question": {"target": follow_up_question, "native": follow_up_native},
                "hint": {"target": follow_up_hint, "native": hint_native},
                "grammar": grammar_t, "vocabulary": vocab_t, "pronunciation": pron_t, "fluency": fluency_t,
                "answer_evaluation": eval_t, "emotion": emotion,
                "personalized_feedback": personal_t,
                "overall_score": overall_score, "passing_score": PASSING_SCORE,
                "improvement": improvement,  
                "should_retry": False, "turn_number": session["turn_number"],
                "audio_url": follow_up_audio
            }
    
    except Exception as e:
        logger.exception(f"Error in practice_interview: {e}")
        raise HTTPException(status_code=500, detail=str(e))



@router.get("/sessions/{session_id}")
async def get_session_data(session_id: str):
    """get complete session history including all responses, feedback, and analysis"""
    session_data = await db.get_user_session(session_id)
    if session_data:
        
        count = max(1, session_data.get("scores", {}).get("count", 1))
        raw_scores = session_data.get("scores", {})
        audio_count = raw_scores.get("audio_count", 0)
        if not audio_count and (raw_scores.get("pronunciation", 0) > 0 or raw_scores.get("fluency", 0) > 0):
            audio_count = count
        
        average_scores = {
            "grammar": int(raw_scores.get("grammar", 0) / count),
            "vocabulary": int(raw_scores.get("vocabulary", 0) / count),
            "pronunciation": int(raw_scores.get("pronunciation", 0) / audio_count) if audio_count > 0 else None,
            "fluency": int(raw_scores.get("fluency", 0) / audio_count) if audio_count > 0 else None,
        }
        avg_answer_score = int(raw_scores.get("answer", 50 * count) / count)
        
        if audio_count > 0:
            overall_average = int(
                average_scores["grammar"] * 0.25 +
                average_scores["vocabulary"] * 0.25 +
                avg_answer_score * 0.25 +
                (average_scores["pronunciation"] or 0) * 0.15 +
                (average_scores["fluency"] or 0) * 0.10
            )
        else:
            overall_average = int(
                average_scores["grammar"] * 0.33 +
                average_scores["vocabulary"] * 0.33 +
                avg_answer_score * 0.34
            )
        average_wpm = int(raw_scores.get("total_wpm", 0) / audio_count) if audio_count > 0 else 0
        
        
        session_status = session_data.get("status", "active")
        is_completed = session_status == "completed"
        
        response = {
            "status": "success",
            "session_id": session_id,
            "session_status": session_status,  
            "can_continue": not is_completed,  
            "user_name": session_data.get("name", ""),
            "scenario": session_data.get("scenario", ""),
            "role": session_data.get("role", ""),
            "level": session_data.get("level", ""),
            "current_state": session_data.get("state", "interviewing"),
            "turns_completed": session_data.get("turn_number", 0),
            "average_scores": average_scores,
            "overall_score": overall_average,
            "average_wpm": average_wpm,
            "last_score": session_data.get("last_overall_score"),
            "last_scores": session_data.get("last_scores", {}),

            "chat_history": session_data.get("chat_history", []),
            
            "turn_history": session_data.get("turn_history", []),
        }
        
        
        if is_completed and session_data.get("final_feedback"):
            response["final_feedback"] = session_data["final_feedback"]
        
        return response
    
    raise HTTPException(status_code=404, detail="Session not found")




# COMMENTED OUT - Use /final_feedback/sessions/{session_id} instead (returns exact same data)
# @router.get("/final_feedback/{session_id}")
# async def get_interview_feedback(session_id: str):
#     """
#     Get the exact same response as session termination.
#     Returns the stored final_feedback from DB with keys in the same order as termination response.
#     """
#     session = await db.get_user_session(session_id)
#     if not session:
#         raise HTTPException(status_code=404, detail="Session not found")
#     if session.get("status") != "completed":
#         raise HTTPException(status_code=400, detail="Session not completed yet")
#     final_feedback = session.get("final_feedback")
#     if not final_feedback:
#         raise HTTPException(status_code=404, detail="Final feedback not found")
#     
#     ordered_response = {
#         "status": final_feedback.get("status", "conversation_ended"),
#         "session_id": final_feedback.get("session_id", session_id),
#         "target_lang": final_feedback.get("target_lang", session.get("target_language", "en")),
#         "native_lang": final_feedback.get("native_lang", session.get("native_language", "hi")),
#         "final_scores": final_feedback.get("final_scores", {}),
#         "overall_score": final_feedback.get("overall_score", 0),
#         "passing_score": final_feedback.get("passing_score", PASSING_SCORE),
#         "average_wpm": final_feedback.get("average_wpm", 0),
#         "wpm_per_turn": final_feedback.get("wpm_per_turn", []),
#         "wpm_status": final_feedback.get("wpm_status", "normal"),
#         "vocab_overall": final_feedback.get("vocab_overall", {} 
#     }


@router.get("/completed_sessions")
async def get_completed_interview_sessions(current_user: User = Depends(get_current_user)):
    """
    Get only completed interview sessions for the authenticated user.
    Returns session_ids and session metadata for completed sessions.
    """
    user_id = current_user.id
    sessions = await db.get_sessions_by_user_id(user_id, session_type="interview")
    completed_sessions = []
    for s in sessions:
        session_data = await db.get_user_session(s.get("session_id"))
        if not session_data:
            continue
        if session_data.get("status") != "completed":
            continue
        if not session_data.get("final_feedback"):
            continue
        completed_sessions.append({
            "session_id": s.get("session_id"),
            "created_at": s.get("created_at"),
            "role": session_data.get("role", ""),
            "scenario": session_data.get("scenario", ""),
            "target_lang": session_data.get("target_language", "en"),
            "native_lang": session_data.get("native_language", "hi")
        })
    return {
        "status": "success",
        "total_sessions": len(completed_sessions),
        "session_ids": [s.get("session_id") for s in completed_sessions],
        "sessions": completed_sessions
    }

     

@router.get("/roles")
async def get_user_roles_from_db(current_user: User = Depends(get_current_user)):
    """
    Get distinct job roles practiced by the current user from DB session data.
    """
    user_id = current_user.id if current_user else None
    roles = await db.get_distinct_roles_by_user(user_id, session_type="interview")
    return {
        "status": "success",
        "user_id": user_id,
        "total_roles": len(roles),
        "roles": roles
    }

@router.get("/roles_with_session_ids")
async def get_roles_and_session_ids(current_user: User = Depends(get_current_user)):
    """
    Get all roles, their corresponding session IDs, and the total session counts for each role for the current user.
    """
    user_id = current_user.id if current_user else None

    # Get distinct roles
    roles = await db.get_distinct_roles_by_user(user_id, session_type="interview")

    # List to hold roles with session info
    roles_with_session_ids = []

    # Get all sessions for the user once
    sessions = await db.get_sessions_by_user_id(user_id, session_type="interview")

    for role in roles:
        session_ids_for_role = []

        for s in sessions:
            session_data = await db.get_user_session(s.get("session_id"))
            if session_data and session_data.get("role") == role and session_data.get("status") == "completed":
                session_ids_for_role.append(s.get("session_id"))

        if session_ids_for_role:
            roles_with_session_ids.append({
                "role": role,
                "session_ids": session_ids_for_role,
                "total_sessions": len(session_ids_for_role)
            })

    return {
        "status": "success",
        "user_id": user_id,
        "total_roles": len(roles_with_session_ids),
        "roles_with_session_ids": roles_with_session_ids
    }




@router.get("/final_feedback/sessions/{session_id}")
async def get_interview_feedback_sessions(session_id: str):
    """
    Get the exact same response as session termination.
    Simply returns the stored final_feedback from DB - exactly as it was when session ended.
    """
    session = await db.get_user_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    if session.get("status") != "completed":
        raise HTTPException(status_code=400, detail="Session not completed yet")
    final_feedback = session.get("final_feedback")
    if not final_feedback:
        raise HTTPException(status_code=404, detail="Final feedback not found")
     
    return final_feedback


